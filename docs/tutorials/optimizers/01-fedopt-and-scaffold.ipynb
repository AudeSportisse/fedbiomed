{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b098b814",
   "metadata": {},
   "source": [
    "# Advanced optimizers in Fed-BioMed\n",
    "\n",
    "\n",
    "**Difficulty level**: **advanced**\n",
    "    \n",
    "## Introduction\n",
    "\n",
    "This tutorial presents on how  to deal with heterogeneous dataset by changing its `Optimizer`. \n",
    "In `Fed-BioMed`, one can specify two sort of `Optimizer`s:\n",
    "\n",
    "1. a `Optimizer` on the `Node` side, defined on the `Training Plan`\n",
    "2. a `Optimizer` on the `Researcher` side, configured in the `Experiment`\n",
    "\n",
    "Advanced `Optimizer` are backed by [`declearn` package](), a python package focused on `Optimization` for Federated Learning. Advanced `Optimizer` can be used regardless of the machine learning framework (compatible with both sklearn and PyTorch)\n",
    "\n",
    "\n",
    "In this tutorial you will learn:\n",
    "- how to use and chain one or several `Optimizers` on `Node` and `Researcher` side\n",
    "- how to use fedopt\n",
    "- how to use `Optimizers` that exchange auxiliary variables such as `Scaffold`\n",
    "\n",
    "For further details you can refer to the [`Optimizer` section in the User Guide]()\n",
    "\n",
    "# 1. Configuring `Nodes`\n",
    "\n",
    "Before starting, we need to configure several `Nodes` and add MedNist dataset to it. Node configuration steps require `fedbiomed-node` conda environment. Please make sure that you have the necessary conda environment: this is explained in the [installation tutorial](../../installation/0-basic-software-installation). \n",
    "\n",
    "\n",
    "Please open a terminal, `cd` to the base directory of the cloned fedbiomed project and follow the steps below.    \n",
    "\n",
    "* **Configuration Steps:**\n",
    "    * Run `${FEDBIOMED_DIR}/scripts/fedbiomed_run node add` in the terminal\n",
    "    * It will ask you to select the data type that you want to add. The third option has been configured to add the MedNIST dataset. Please type `3` and continue. \n",
    "    * Please use default tags which are `#MNIST` and `#dataset`.\n",
    "    * For the next step, please select the directory that you want to download the MNIST dataset.\n",
    "    * After the download is completed you will see the details of the MNIST dataset on the screen.\n",
    " \n",
    "Please run the command below in the same terminal to make sure the MNIST dataset is successfully added to the Node. \n",
    "\n",
    "```\n",
    "$ ${FEDBIOMED_DIR}/scripts/fedbiomed_run node config conf1.ini add\n",
    "```\n",
    "\n",
    "Before starting the node, please make sure that you have already launched the network using command `scripts/fedbiomed_run network`. Afterward, all you need to do is to start the node.\n",
    "\n",
    "\n",
    "```\n",
    "$ ${FEDBIOMED_DIR}/scripts/fedbiomed_run node config conf1.ini start\n",
    "```\n",
    "\n",
    "In another terminal, you may proceed by launching a second `Node`\n",
    "\n",
    "# 2. Defining an `Optimizer` on `Node` side\n",
    "\n",
    "`Optimizers` are defined through the `init_optimizer` method of the `training plan`. They must be set using `Fed-BioMed` `Optimizer` object (ie from `fedbiomed.common.optimizers.optimizer.Optimizer`)\n",
    "\n",
    "## 2.1 With PyTorch framework\n",
    "\n",
    "In [this tutorial]() we have showcased the use of a PyTorch model with [PyTorch native optimizers](), such as `torch.optim.SGD`. In the present tutorial, we will see how to use `declearn` cross frameworks optimizers\n",
    "\n",
    "\n",
    "### PyTorch Training Plan\n",
    "Below is a simple implementation of a `declearn` SGD `Optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import densenet121\n",
    "from fedbiomed.common.optimizers.optimizer import Optimizer\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# we will use the densnet121 model\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "                \"from torchvision.models import densenet121\"]\n",
    "\n",
    "        return deps\n",
    "    \n",
    "    def init_model(self):\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        model = densenet121(pretrained=True)\n",
    "        model.classifier =nn.Sequential(nn.Linear(1024,512), nn.Softmax())\n",
    "        return model \n",
    "    \n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        # Defines and return a declearn optimizer\n",
    "        return Optimizer(lr=optimizer_args['lr'])\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MedNIST data\n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "        preprocess = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(\n",
    "                                            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                                        )])\n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = self.loss_function(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb6e0a",
   "metadata": {},
   "source": [
    "### Sklearn `Training Plan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe7093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fb5ea3f",
   "metadata": {},
   "source": [
    "# 3. Defining an `Optimizer` on `Researcher` side: `FedOpt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05decc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6b343f",
   "metadata": {},
   "source": [
    "# 4. Defining `Scaffold` through `Optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046225b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5bacc7",
   "metadata": {},
   "source": [
    "# 5. Explore `declearn` and the Fed-BioMed user guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
