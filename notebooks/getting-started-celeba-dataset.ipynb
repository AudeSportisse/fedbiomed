{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fedbiomed Researcher"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting the client up\n",
    "It is necessary to previously configure at least a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 3 (images) to add an image dataset to the node\n",
    "  * Add a name and the tag for the dataset (tag should be '#celeba') and finaly add the description\n",
    "  * Download Celeba dataset from [here](https://drive.google.com/drive/folders/0B7EVK8r0v71pWEZsZE9oNnFzTm8?resourcekey=0-5BR16BdXnb8hVj6CNHKzLg), files needed are : 'img/img_align_celeba.zip and the Anno folder. extract the zip and put the  \n",
    "  * Run the create_node_data.py script inside data/Celeba\n",
    "  * Pick the folder of the data from the 3 generated inside data/Celeba/celeba_preprocessed\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Connected with result code 0`. it means you are online.\n",
    "\n",
    "4. for the sake of testing the resulting model, only nodes 1 and 2 were started during training, datas from node 3 is used to test the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create an experiment to train a model on the data found"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declare a torch.nn Net class to send for training on the node"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from fedbiomed.researcher.environ import TMP_DIR\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=TMP_DIR+'/')\n",
    "model_file = tmp_dir_model.name + '/CelebaClass.py'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note : write **only** the code to export in the following cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from   fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# you can use any class name eg:\n",
    "# class NetAlter(Torchnn):\n",
    "class Net(TorchTrainingPlan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(3168, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        deps = [\"from torch.utils.data import Dataset, DataLoader\",\n",
    "                \"from torchvision import datasets, transforms\",\n",
    "                \"import pandas as pd\",\n",
    "               \"from PIL import Image\",\n",
    "               \"import os\",\n",
    "               \"import numpy as np\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "    def training_data(self,  batch_size = 48):\n",
    "    # The training_data creates the Dataloader to be used for training in the general class Torchnn of fedbiomed\n",
    "        dataset = self.CelebaDataset(self.dataset_path + \"/target.csv\", self.dataset_path + \"/data/\")\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = DataLoader(dataset, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing /home/administrator/fedbiomed/fedbiomed/var/tmp/tmpn8m2ht05/CelebaClass.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the client side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the client side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "training_args = {\n",
    "    'batch_size': 32, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 200 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the federated model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of client ID with `clients`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `client_selection_strategy` between the rounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#celeba']\n",
    "rounds = 5\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_path=model_file,\n",
    "                 model_class='Net',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 client_selection_strategy=None)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Messaging researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931 connected with result code 0\n",
      "Searching for clients with data tags: ['#celeba'] ...\n",
      "2021-08-18 11:54:40.817997 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'success': True, 'databases': [{'name': 'celeba', 'data_type': 'images', 'tags': ['#celeba'], 'description': 'celeba', 'shape': [67533, 3, 218, 178], 'dataset_id': 'dataset_5eae6966-ae48-455e-aa0c-77a508cc6768'}], 'count': 1, 'client_id': 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'command': 'search'}\n",
      "2021-08-18 11:54:40.818678 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'success': True, 'databases': [{'name': 'celeba', 'data_type': 'images', 'tags': ['#celeba'], 'description': 'celabe', 'shape': [67533, 3, 218, 178], 'dataset_id': 'dataset_871790bf-8e77-4e80-8050-a019760a40be'}], 'count': 1, 'client_id': 'client_884ff1fa-2457-4372-ac17-ab365ef22788', 'command': 'search'}\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "exp.run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sampled clients in round  0   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "[ RESEARCHER ] Send message to client  client_884ff1fa-2457-4372-ac17-ab365ef22788 {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_xWQ1sUw.pt', 'model_class': 'Net', 'training_data': {'client_884ff1fa-2457-4372-ac17-ab365ef22788': ['dataset_871790bf-8e77-4e80-8050-a019760a40be']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "[ RESEARCHER ] Send message to client  client_815db1f8-9696-41c4-83fc-846ddfee9c9a {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_xWQ1sUw.pt', 'model_class': 'Net', 'training_data': {'client_815db1f8-9696-41c4-83fc-846ddfee9c9a': ['dataset_5eae6966-ae48-455e-aa0c-77a508cc6768']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "2021-08-18 11:56:42.224567 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_884ff1fa-2457-4372-ac17-ab365ef22788', 'dataset_id': 'dataset_871790bf-8e77-4e80-8050-a019760a40be', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_b1483fdd-d536-43a4-8b77-d88866cd43a3.pt', 'timing': {'rtime_training': 102.09951778400136, 'ptime_training': 593.85637545}, 'msg': '', 'command': 'train'}\n",
      "2021-08-18 11:56:44.455131 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'dataset_id': 'dataset_5eae6966-ae48-455e-aa0c-77a508cc6768', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_69287e2e-e02c-4f24-b932-c850e3c066d3.pt', 'timing': {'rtime_training': 102.31291633899673, 'ptime_training': 595.566939331}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_884ff1fa-2457-4372-ac17-ab365ef22788 \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_b1483fdd-d536-43a4-8b77-d88866cd43a3.pt\n",
      "Downloading model params after training on  client_815db1f8-9696-41c4-83fc-846ddfee9c9a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_69287e2e-e02c-4f24-b932-c850e3c066d3.pt\n",
      "Clients that successfully reply in round  0   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "Sampled clients in round  1   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "[ RESEARCHER ] Send message to client  client_884ff1fa-2457-4372-ac17-ab365ef22788 {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_6c0dec9c-fab6-4c28-85a6-445bb26a9cfd.pt', 'model_class': 'Net', 'training_data': {'client_884ff1fa-2457-4372-ac17-ab365ef22788': ['dataset_871790bf-8e77-4e80-8050-a019760a40be']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "[ RESEARCHER ] Send message to client  client_815db1f8-9696-41c4-83fc-846ddfee9c9a {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_6c0dec9c-fab6-4c28-85a6-445bb26a9cfd.pt', 'model_class': 'Net', 'training_data': {'client_815db1f8-9696-41c4-83fc-846ddfee9c9a': ['dataset_5eae6966-ae48-455e-aa0c-77a508cc6768']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "2021-08-18 11:58:56.591938 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'dataset_id': 'dataset_5eae6966-ae48-455e-aa0c-77a508cc6768', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_1a35b2ba-d508-4226-ba52-8caf3a2d2617.pt', 'timing': {'rtime_training': 104.20218932700664, 'ptime_training': 606.9930974540001}, 'msg': '', 'command': 'train'}\n",
      "2021-08-18 11:58:57.482963 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_884ff1fa-2457-4372-ac17-ab365ef22788', 'dataset_id': 'dataset_871790bf-8e77-4e80-8050-a019760a40be', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_f4922ed8-5a13-47ca-a4c8-b0f8eb74c628.pt', 'timing': {'rtime_training': 104.16175124700385, 'ptime_training': 607.0914432779999}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_815db1f8-9696-41c4-83fc-846ddfee9c9a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_1a35b2ba-d508-4226-ba52-8caf3a2d2617.pt\n",
      "Downloading model params after training on  client_884ff1fa-2457-4372-ac17-ab365ef22788 \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_f4922ed8-5a13-47ca-a4c8-b0f8eb74c628.pt\n",
      "Clients that successfully reply in round  1   ['client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'client_884ff1fa-2457-4372-ac17-ab365ef22788']\n",
      "Sampled clients in round  2   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "[ RESEARCHER ] Send message to client  client_884ff1fa-2457-4372-ac17-ab365ef22788 {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_950b1d85-8b1c-4c1d-9a2f-215a65e4b155.pt', 'model_class': 'Net', 'training_data': {'client_884ff1fa-2457-4372-ac17-ab365ef22788': ['dataset_871790bf-8e77-4e80-8050-a019760a40be']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "[ RESEARCHER ] Send message to client  client_815db1f8-9696-41c4-83fc-846ddfee9c9a {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_950b1d85-8b1c-4c1d-9a2f-215a65e4b155.pt', 'model_class': 'Net', 'training_data': {'client_815db1f8-9696-41c4-83fc-846ddfee9c9a': ['dataset_5eae6966-ae48-455e-aa0c-77a508cc6768']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "2021-08-18 12:01:04.705364 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_884ff1fa-2457-4372-ac17-ab365ef22788', 'dataset_id': 'dataset_871790bf-8e77-4e80-8050-a019760a40be', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_062f1cfa-50e7-4626-b63d-94772e1ce425.pt', 'timing': {'rtime_training': 103.15267284300353, 'ptime_training': 599.6409095930001}, 'msg': '', 'command': 'train'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-08-18 12:01:08.835106 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'dataset_id': 'dataset_5eae6966-ae48-455e-aa0c-77a508cc6768', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_bf31b54a-9114-42fe-badc-ab1d83536213.pt', 'timing': {'rtime_training': 103.27803893399687, 'ptime_training': 600.2810264049999}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_884ff1fa-2457-4372-ac17-ab365ef22788 \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_062f1cfa-50e7-4626-b63d-94772e1ce425.pt\n",
      "Downloading model params after training on  client_815db1f8-9696-41c4-83fc-846ddfee9c9a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_bf31b54a-9114-42fe-badc-ab1d83536213.pt\n",
      "Clients that successfully reply in round  2   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "Sampled clients in round  3   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "[ RESEARCHER ] Send message to client  client_884ff1fa-2457-4372-ac17-ab365ef22788 {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_1f745a0b-3de7-467f-b668-48179ee39047.pt', 'model_class': 'Net', 'training_data': {'client_884ff1fa-2457-4372-ac17-ab365ef22788': ['dataset_871790bf-8e77-4e80-8050-a019760a40be']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "[ RESEARCHER ] Send message to client  client_815db1f8-9696-41c4-83fc-846ddfee9c9a {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_1f745a0b-3de7-467f-b668-48179ee39047.pt', 'model_class': 'Net', 'training_data': {'client_815db1f8-9696-41c4-83fc-846ddfee9c9a': ['dataset_5eae6966-ae48-455e-aa0c-77a508cc6768']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "2021-08-18 12:03:20.792025 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_884ff1fa-2457-4372-ac17-ab365ef22788', 'dataset_id': 'dataset_871790bf-8e77-4e80-8050-a019760a40be', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_196e1c1e-eb17-4c2d-b95e-8ba75fcb269b.pt', 'timing': {'rtime_training': 107.02812714599713, 'ptime_training': 619.4154099430002}, 'msg': '', 'command': 'train'}\n",
      "2021-08-18 12:03:21.723447 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'dataset_id': 'dataset_5eae6966-ae48-455e-aa0c-77a508cc6768', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_09f71c93-22f3-4e01-a7a5-1300db88702a.pt', 'timing': {'rtime_training': 105.91722035899875, 'ptime_training': 614.1890904269999}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_884ff1fa-2457-4372-ac17-ab365ef22788 \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_196e1c1e-eb17-4c2d-b95e-8ba75fcb269b.pt\n",
      "Downloading model params after training on  client_815db1f8-9696-41c4-83fc-846ddfee9c9a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_09f71c93-22f3-4e01-a7a5-1300db88702a.pt\n",
      "Clients that successfully reply in round  3   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "Sampled clients in round  4   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n",
      "[ RESEARCHER ] Send message to client  client_884ff1fa-2457-4372-ac17-ab365ef22788 {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_cf39900d-a34e-4f1b-8936-e8c39f025047.pt', 'model_class': 'Net', 'training_data': {'client_884ff1fa-2457-4372-ac17-ab365ef22788': ['dataset_871790bf-8e77-4e80-8050-a019760a40be']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "[ RESEARCHER ] Send message to client  client_815db1f8-9696-41c4-83fc-846ddfee9c9a {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/18/my_model_Up04dp1.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/researcher_params_cf39900d-a34e-4f1b-8936-e8c39f025047.pt', 'model_class': 'Net', 'training_data': {'client_815db1f8-9696-41c4-83fc-846ddfee9c9a': ['dataset_5eae6966-ae48-455e-aa0c-77a508cc6768']}}\n",
      "researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931\n",
      "2021-08-18 12:05:36.192031 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_884ff1fa-2457-4372-ac17-ab365ef22788', 'dataset_id': 'dataset_871790bf-8e77-4e80-8050-a019760a40be', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_0ca009eb-3f23-4bf5-a0bb-8bd9d3621f3a.pt', 'timing': {'rtime_training': 106.21848745999887, 'ptime_training': 618.2522921679997}, 'msg': '', 'command': 'train'}\n",
      "2021-08-18 12:05:36.816943 [ RESEARCHER ] message received. {'researcher_id': 'researcher_02af5973-b9e7-4a83-91b1-64b0e3a46931', 'job_id': 'bf695091-e5db-4d8c-baaf-9bf0dbe204c3', 'success': True, 'client_id': 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a', 'dataset_id': 'dataset_5eae6966-ae48-455e-aa0c-77a508cc6768', 'params_url': 'http://localhost:8844/media/uploads/2021/08/18/node_params_8a1ffc17-f6dc-415c-9669-6b3af3e33bf8.pt', 'timing': {'rtime_training': 105.84928814000159, 'ptime_training': 615.6736388189997}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_884ff1fa-2457-4372-ac17-ab365ef22788 \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_0ca009eb-3f23-4bf5-a0bb-8bd9d3621f3a.pt\n",
      "Downloading model params after training on  client_815db1f8-9696-41c4-83fc-846ddfee9c9a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/18/node_params_8a1ffc17-f6dc-415c-9669-6b3af3e33bf8.pt\n",
      "Clients that successfully reply in round  4   ['client_884ff1fa-2457-4372-ac17-ab365ef22788', 'client_815db1f8-9696-41c4-83fc-846ddfee9c9a']\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve the federated model parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "fed_model = exp.model_instance\n",
    "fed_model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "fed_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=3168, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define a little testing routine to extract the accuracy metrics on the testing dataset\n",
    "## Important\n",
    "this is done to test the model because it is an devellopement environement\n",
    "in production, the data wont be accessible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    device = 'cpu'\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/len(data_loader.dataset)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "the test dataset is the data from the third node"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "test_dataset_path = \"../data/Celeba/celeba_preprocessed/data_node_3\"\n",
    "\n",
    "class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "\n",
    "dataset = CelebaDataset(test_dataset_path + \"/target.csv\", test_dataset_path + \"/data/\")\n",
    "train_kwargs = {'batch_size': 64, 'shuffle': True}\n",
    "data_loader = DataLoader(dataset, **train_kwargs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "celeba dataset finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the testing dataset and computing accuracy metrics for local and federated models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "acc_federated = testing_Accuracy(fed_model, data_loader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "acc_federated"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.2642568576013405, 89.11791272414968)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e89561e616b27d96972869796636c18d9df047835da4fde0d47d1d63cf19e486"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}