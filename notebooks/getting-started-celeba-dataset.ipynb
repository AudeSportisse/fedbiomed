{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the client up\n",
    "\n",
    "Install the celeba dataset with the help of the readme.md file inside `notebooks/data_for_examples/Celeba`  \n",
    "For the sake of testing the resulting model, this file uses the data from node 1 and 2 for training and the data from node 3 to test.\n",
    "you can create multiple nodes by adding a config parameter to the command contriling nodes, for example :  \n",
    "creating 2 nodes for training :  \n",
    " - `./scripts/fedbiomed_run node start config node1.ini`\n",
    " - `./scripts/fedbiomed_run node start config node2.ini`  \n",
    " \n",
    "adding data for each node :  \n",
    " - `./scripts/fedbiomed_run node add config node1.ini`\n",
    " - `./scripts/fedbiomed_run node add config node2.ini`\n",
    "\n",
    "It is necessary to previously configure at least a node:\n",
    "1. `./scripts/fedbiomed_run node add config (ini file)`\n",
    "  * Select option 3 (images) to add an image dataset to the node\n",
    "  * Add a name and the tag for the dataset (tag should contain '#celeba' as it is the tag used for this training) and finaly add the description\n",
    "  * Pick a data folder from the 3 generated inside data/Celeba/celeba_preprocessed\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node start`. Wait until you get `Connected with result code 0`. it means you are online.\n",
    "\n",
    "for the sake of testing the resulting model, only nodes 1 and 2 were started during training, datas from node 3 is used to test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn Net class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import TMP_DIR\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=TMP_DIR+'/')\n",
    "model_file = tmp_dir_model.name + '/CelebaClass.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : write **only** the code to export in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/administrator/fedbiomed/fedbiomed/var/tmp/tmp6oqnzgqv/CelebaClass.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from   fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class Net(TorchTrainingPlan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #convolution layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        # classifier\n",
    "        self.fc1 = nn.Linear(3168, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        deps = [\"from torch.utils.data import Dataset, DataLoader\",\n",
    "                \"from torchvision import transforms\",\n",
    "                \"import pandas as pd\",\n",
    "               \"from PIL import Image\",\n",
    "               \"import os\",\n",
    "               \"import numpy as np\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "        \n",
    "        # we dont load the full data of the images, we retrieve the image with the get item. \n",
    "        # in our case, each image is 218*178 * 3colors. there is 67533 images. this take at leas 7G of ram\n",
    "        # loading images when needed takes more time during training but it wont impact the ram usage as much as loading everything\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "    def training_data(self,  batch_size = 48):\n",
    "    # The training_data creates the Dataloader to be used for training in the general class Torchnn of fedbiomed\n",
    "        dataset = self.CelebaDataset(self.dataset_path + \"/target.csv\", self.dataset_path + \"/data/\")\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = DataLoader(dataset, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        #this function must return the loss to backward it \n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the client side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the client side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': 32, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 200 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messaging researcher_b85a3870-ab99-43f0-b35f-40af022c3525 connected with result code 0\n",
      "Searching for clients with data tags: ['#celeba'] ...\n",
      "2021-08-27 14:03:51.018583 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'success': True, 'databases': [{'name': 'celeba', 'data_type': 'images', 'tags': ['#celeba'], 'description': 'celeba node 2', 'shape': [67533, 3, 218, 178], 'dataset_id': 'dataset_63034967-a24e-41d3-b3f6-52d066dd679b'}], 'count': 1, 'client_id': 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'command': 'search'}\n",
      "2021-08-27 14:03:51.019528 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'success': True, 'databases': [{'name': 'celeba', 'data_type': 'images', 'tags': ['#celeba'], 'description': 'celeba node 1', 'shape': [67533, 3, 218, 178], 'dataset_id': 'dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6'}], 'count': 1, 'client_id': 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'command': 'search'}\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#celeba']\n",
    "rounds = 5\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_path=model_file,\n",
    "                 model_class='Net',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 client_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of client ID with `clients`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `client_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled clients in round  0   ['client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae']\n",
      "[ RESEARCHER ] Send message to client  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_zglhY27.pt', 'model_class': 'Net', 'training_data': {'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a': ['dataset_63034967-a24e-41d3-b3f6-52d066dd679b']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "[ RESEARCHER ] Send message to client  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_zglhY27.pt', 'model_class': 'Net', 'training_data': {'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae': ['dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "2021-08-27 14:06:05.756732 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'dataset_id': 'dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_d0660f52-8d75-49f5-aef1-a0f06ae916e8.pt', 'timing': {'rtime_training': 106.0148240540002, 'ptime_training': 596.3488664}, 'msg': '', 'command': 'train'}\n",
      "2021-08-27 14:06:09.540831 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'dataset_id': 'dataset_63034967-a24e-41d3-b3f6-52d066dd679b', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_9d5ec3e5-eb88-42b3-bffd-d9a5c02a37f6.pt', 'timing': {'rtime_training': 106.72848391201114, 'ptime_training': 599.710017232}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_d0660f52-8d75-49f5-aef1-a0f06ae916e8.pt\n",
      "Downloading model params after training on  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_9d5ec3e5-eb88-42b3-bffd-d9a5c02a37f6.pt\n",
      "Clients that successfully reply in round  0   ['client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a']\n",
      "Sampled clients in round  1   ['client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae']\n",
      "[ RESEARCHER ] Send message to client  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_ac16980c-2ae0-46f9-8cab-dc5c74870c30.pt', 'model_class': 'Net', 'training_data': {'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a': ['dataset_63034967-a24e-41d3-b3f6-52d066dd679b']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "[ RESEARCHER ] Send message to client  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_ac16980c-2ae0-46f9-8cab-dc5c74870c30.pt', 'model_class': 'Net', 'training_data': {'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae': ['dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "2021-08-27 14:08:14.615411 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'dataset_id': 'dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_a310ba15-1a82-4787-b806-4f44711856f8.pt', 'timing': {'rtime_training': 102.69501223201223, 'ptime_training': 586.9343268429999}, 'msg': '', 'command': 'train'}\n",
      "2021-08-27 14:08:18.106335 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'dataset_id': 'dataset_63034967-a24e-41d3-b3f6-52d066dd679b', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_ef1fb2a6-2213-4618-ab2f-9a67459dbb9b.pt', 'timing': {'rtime_training': 102.24259858699224, 'ptime_training': 583.9368129970001}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_a310ba15-1a82-4787-b806-4f44711856f8.pt\n",
      "Downloading model params after training on  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_ef1fb2a6-2213-4618-ab2f-9a67459dbb9b.pt\n",
      "Clients that successfully reply in round  1   ['client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a']\n",
      "Sampled clients in round  2   ['client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae']\n",
      "[ RESEARCHER ] Send message to client  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_20ff3e22-0c34-4672-aa1e-89a568660f19.pt', 'model_class': 'Net', 'training_data': {'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a': ['dataset_63034967-a24e-41d3-b3f6-52d066dd679b']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "[ RESEARCHER ] Send message to client  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_20ff3e22-0c34-4672-aa1e-89a568660f19.pt', 'model_class': 'Net', 'training_data': {'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae': ['dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "2021-08-27 14:10:21.312651 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'dataset_id': 'dataset_63034967-a24e-41d3-b3f6-52d066dd679b', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_df46511c-5fc1-4579-a04c-8d6f183a39ea.pt', 'timing': {'rtime_training': 98.21972392300086, 'ptime_training': 568.9329777260002}, 'msg': '', 'command': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-27 14:10:21.760170 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'dataset_id': 'dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_c9bbe5a7-fe86-4121-8717-2156965a6f4d.pt', 'timing': {'rtime_training': 99.65200744199683, 'ptime_training': 573.8139453859999}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_df46511c-5fc1-4579-a04c-8d6f183a39ea.pt\n",
      "Downloading model params after training on  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_c9bbe5a7-fe86-4121-8717-2156965a6f4d.pt\n",
      "Clients that successfully reply in round  2   ['client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae']\n",
      "Sampled clients in round  3   ['client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae']\n",
      "[ RESEARCHER ] Send message to client  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_28a739f7-91f8-4bd0-82c2-0e5bf0e5d47e.pt', 'model_class': 'Net', 'training_data': {'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a': ['dataset_63034967-a24e-41d3-b3f6-52d066dd679b']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "[ RESEARCHER ] Send message to client  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_28a739f7-91f8-4bd0-82c2-0e5bf0e5d47e.pt', 'model_class': 'Net', 'training_data': {'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae': ['dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "2021-08-27 14:12:28.952983 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'dataset_id': 'dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_9ee8bc60-586b-4df1-b69d-8d31ba54e0ae.pt', 'timing': {'rtime_training': 100.58580305799842, 'ptime_training': 579.1418011009998}, 'msg': '', 'command': 'train'}\n",
      "2021-08-27 14:12:32.105788 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'dataset_id': 'dataset_63034967-a24e-41d3-b3f6-52d066dd679b', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_73fad030-2d10-4c7a-b70c-1443e00817e3.pt', 'timing': {'rtime_training': 99.7526747439988, 'ptime_training': 574.2059914470001}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_9ee8bc60-586b-4df1-b69d-8d31ba54e0ae.pt\n",
      "Downloading model params after training on  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_73fad030-2d10-4c7a-b70c-1443e00817e3.pt\n",
      "Clients that successfully reply in round  3   ['client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a']\n",
      "Sampled clients in round  4   ['client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae']\n",
      "[ RESEARCHER ] Send message to client  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_4aba5e90-adba-4197-8787-61b89622f242.pt', 'model_class': 'Net', 'training_data': {'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a': ['dataset_63034967-a24e-41d3-b3f6-52d066dd679b']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "[ RESEARCHER ] Send message to client  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'training_args': {'batch_size': 32, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 200}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/08/27/my_model_ZZL7kcZ.py', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/researcher_params_4aba5e90-adba-4197-8787-61b89622f242.pt', 'model_class': 'Net', 'training_data': {'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae': ['dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6']}}\n",
      "researcher_b85a3870-ab99-43f0-b35f-40af022c3525\n",
      "2021-08-27 14:14:36.494561 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'dataset_id': 'dataset_1f2d7ae1-4e17-4e23-be80-58d60d0c6aa6', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_8d03f354-d887-40f4-82bc-89f79b450ac0.pt', 'timing': {'rtime_training': 98.95208543300396, 'ptime_training': 572.2711564169999}, 'msg': '', 'command': 'train'}\n",
      "2021-08-27 14:14:39.423462 [ RESEARCHER ] message received. {'researcher_id': 'researcher_b85a3870-ab99-43f0-b35f-40af022c3525', 'job_id': 'a9378749-ac37-4923-a8b5-1a625c04bd0a', 'success': True, 'client_id': 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a', 'dataset_id': 'dataset_63034967-a24e-41d3-b3f6-52d066dd679b', 'params_url': 'http://localhost:8844/media/uploads/2021/08/27/node_params_2666dfcc-544c-4366-93ee-ac542c7abe97.pt', 'timing': {'rtime_training': 97.85282325198932, 'ptime_training': 564.590459992}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_cb657f6d-86d5-46b3-8c0b-aa90552631ae \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_8d03f354-d887-40f4-82bc-89f79b450ac0.pt\n",
      "Downloading model params after training on  client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a \n",
      "\t- from http://localhost:8844/media/uploads/2021/08/27/node_params_2666dfcc-544c-4366-93ee-ac542c7abe97.pt\n",
      "Clients that successfully reply in round  4   ['client_cb657f6d-86d5-46b3-8c0b-aa90552631ae', 'client_9434ffdf-1bd5-49bf-8d47-5bc86602ee2a']\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_model = exp.model_instance\n",
    "fed_model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=3168, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a little testing routine to extract the accuracy metrics on the testing dataset\n",
    "## Important\n",
    "this is done to test the model because it is a devellopement environement  \n",
    "in production, the data wont be accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    device = 'cpu'\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/len(data_loader.dataset)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the test dataset is the data from the third node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeba dataset finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset_path = \"./data_for_examples/Celeba/celeba_preprocessed/data_node_3\"\n",
    "\n",
    "class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "\n",
    "dataset = CelebaDataset(test_dataset_path + \"/target.csv\", test_dataset_path + \"/data/\")\n",
    "train_kwargs = {'batch_size': 64, 'shuffle': True}\n",
    "data_loader = DataLoader(dataset, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the testing dataset and computing accuracy metrics for local and federated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_federated = testing_Accuracy(fed_model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.6050819599307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_federated[1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e89561e616b27d96972869796636c18d9df047835da4fde0d47d1d63cf19e486"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
