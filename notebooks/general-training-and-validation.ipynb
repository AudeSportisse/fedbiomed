{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Validation at Each Round of Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node start`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Validating Pytorch Model Using Predefined Evalution Metrics at each Round of Federeated Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch training plan MyTrainingPlan class to send for training on the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Declare and run the experiment\n",
    "The model is trained on the **MNIST dataset** for classification. For validation, we will be using the **F1-Score**  as a metric. Validation will be performed on both **local updates and global updates**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:41:39,023 fedbiomed INFO - Searching dataset with data tags: ['#MNIST', '#dataset'] for all nodes\n",
      "2023-09-05 14:41:39,039 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:41:39,042 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:41:39,044 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:41:39,062 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:41:39,065 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:41:39,067 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:41:49,038 fedbiomed INFO - Node selected for training -> node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:41:49,041 fedbiomed INFO - Node selected for training -> node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:41:49,046 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "2023-09-05 14:41:49,108 fedbiomed INFO - Removing tensorboard logs from previous experiment\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "\n",
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, }, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None,\n",
    "                tensorboard=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring Validation Arguments \n",
    "\n",
    "- **test_ratio:** The ratio for validation partition \n",
    "- **test_metric:** The metric that is going to be used for validation\n",
    "- **Validation on local updates:** Means that validation is going to be perform after training is performed over aggreated paramaters  \n",
    "- **Validation on global updates**: Means that validation will be perform on aggregated parameters before performing the training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display all the default metrics that are supported in Fed-BioMed. They are all based on sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCURACY',\n",
       " 'F1_SCORE',\n",
       " 'PRECISION',\n",
       " 'RECALL',\n",
       " 'MEAN_SQUARE_ERROR',\n",
       " 'MEAN_ABSOLUTE_ERROR',\n",
       " 'EXPLAINED_VARIANCE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.common.metrics import MetricTypes\n",
    "MetricTypes.get_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<MetricTypes.F1_SCORE: (1, <_MetricCategory.CLASSIFICATION_LABELS: 0>)>, {})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_test_ratio(0.1)\n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_on_global_updates(True)\n",
    "exp.set_test_metric(MetricTypes.F1_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d10eb44d0ef861fd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d10eb44d0ef861fd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:42:06,403 fedbiomed INFO - Sampled nodes in round 0 ['node_415010f8-df19-4a90-8059-cf76a759d3f5', 'node_41533df5-d07b-4027-a826-d1f67410d627']\n",
      "2023-09-05 14:42:06,418 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
      " -----------------------------------------------------------------\n",
      "2023-09-05 14:42:06,434 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
      " -----------------------------------------------------------------\n",
      "2023-09-05 14:42:06,526 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:42:06,529 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:42:06,534 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:42:06,614 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:42:06,616 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:42:06,617 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:42:12,442 fedbiomed INFO - \u001b[1mVALIDATION ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.043286\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:12,733 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 1/100 (1%) | Samples: 48/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m2.326588\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:13,263 fedbiomed INFO - \u001b[1mVALIDATION ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.042039\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:13,887 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 1/100 (1%) | Samples: 48/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m2.290880\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:15,355 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 10/100 (10%) | Samples: 480/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m1.055279\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:17,256 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 10/100 (10%) | Samples: 480/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m1.196635\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:18,312 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 20/100 (20%) | Samples: 960/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.669063\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:20,967 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 20/100 (20%) | Samples: 960/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.826601\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:20,979 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 30/100 (30%) | Samples: 1440/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.860950\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:23,774 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 30/100 (30%) | Samples: 1440/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.725196\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:24,299 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 40/100 (40%) | Samples: 1920/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.456822\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:26,508 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 40/100 (40%) | Samples: 1920/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.345631\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:27,080 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 50/100 (50%) | Samples: 2400/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.602380\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:28,815 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 50/100 (50%) | Samples: 2400/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.350794\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:29,913 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 60/100 (60%) | Samples: 2880/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.360282\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:31,279 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 60/100 (60%) | Samples: 2880/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.436207\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:32,191 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 70/100 (70%) | Samples: 3360/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.296095\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:33,022 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 70/100 (70%) | Samples: 3360/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.322338\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:34,048 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 80/100 (80%) | Samples: 3840/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.152170\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:34,662 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 80/100 (80%) | Samples: 3840/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.298941\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:35,469 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 90/100 (90%) | Samples: 4320/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.521920\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:36,202 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 90/100 (90%) | Samples: 4320/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.386940\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:36,889 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 100/100 (100%) | Samples: 4800/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.229953\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:37,657 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 100/100 (100%) | Samples: 4800/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.412975\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:44,470 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.945189\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:44,847 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.946247\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:51,584 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_415010f8-df19-4a90-8059-cf76a759d3f5', 'node_41533df5-d07b-4027-a826-d1f67410d627']\n",
      "2023-09-05 14:42:51,645 fedbiomed INFO - Saved aggregated params for round 0 in /user/scansiz/home/projects/fedbiomed-dev/fedbiomed/var/experiments/Experiment_0097/aggregated_params_b2970851-20c2-485a-a081-dc54db8d98b7.mpk\n",
      "2023-09-05 14:42:51,647 fedbiomed INFO - Sampled nodes in round 1 ['node_415010f8-df19-4a90-8059-cf76a759d3f5', 'node_41533df5-d07b-4027-a826-d1f67410d627']\n",
      "2023-09-05 14:42:51,655 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
      " -----------------------------------------------------------------\n",
      "2023-09-05 14:42:51,657 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
      " -----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:42:51,816 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:42:51,820 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:42:51,823 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:42:51,828 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:42:51,832 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:42:51,835 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:42:58,007 fedbiomed INFO - \u001b[1mVALIDATION ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.940365\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:58,220 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 1/100 (1%) | Samples: 48/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.237068\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:58,370 fedbiomed INFO - \u001b[1mVALIDATION ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.946523\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:58,553 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 1/100 (1%) | Samples: 48/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.374230\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:59,497 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 10/100 (10%) | Samples: 480/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.286742\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:42:59,782 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 10/100 (10%) | Samples: 480/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.261581\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:01,462 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 20/100 (20%) | Samples: 960/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.387011\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:01,683 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 20/100 (20%) | Samples: 960/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.158092\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:03,608 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 30/100 (30%) | Samples: 1440/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.277920\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:04,721 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 30/100 (30%) | Samples: 1440/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.267070\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:06,123 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 40/100 (40%) | Samples: 1920/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.282585\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:06,677 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 40/100 (40%) | Samples: 1920/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.210931\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:08,261 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 50/100 (50%) | Samples: 2400/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.101017\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:08,301 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 50/100 (50%) | Samples: 2400/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.183985\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:10,014 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 60/100 (60%) | Samples: 2880/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.212251\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:10,355 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 60/100 (60%) | Samples: 2880/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.055770\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:11,169 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 70/100 (70%) | Samples: 3360/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.429530\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:11,514 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 70/100 (70%) | Samples: 3360/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.293854\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:12,342 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 80/100 (80%) | Samples: 3840/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.181929\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:12,649 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 80/100 (80%) | Samples: 3840/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.229648\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:13,513 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 90/100 (90%) | Samples: 4320/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.399374\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:13,846 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 90/100 (90%) | Samples: 4320/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.206724\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:14,640 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 100/100 (100%) | Samples: 4800/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.137746\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:14,992 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 100/100 (100%) | Samples: 4800/4800\n",
      " \t\t\t\t\t Loss: \u001b[1m0.178683\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:20,724 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_41533df5-d07b-4027-a826-d1f67410d627 \n",
      "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.966289\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:20,971 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_415010f8-df19-4a90-8059-cf76a759d3f5 \n",
      "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 6000/6000\n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.968324\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2023-09-05 14:43:26,771 fedbiomed INFO - Nodes that successfully reply in round 1 ['node_41533df5-d07b-4027-a826-d1f67410d627', 'node_415010f8-df19-4a90-8059-cf76a759d3f5']\n",
      "2023-09-05 14:43:26,796 fedbiomed INFO - Saved aggregated params for round 1 in /user/scansiz/home/projects/fedbiomed-dev/fedbiomed/var/experiments/Experiment_0097/aggregated_params_c3860e14-5a7e-4126-94ac-b7023bfcc313.mpk\n",
      "2023-09-05 14:43:26,797 fedbiomed CRITICAL - Fed-BioMed stopped due to unknown error:\n",
      "not enough values to unpack (expected 2, got 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Fed-BioMed researcher stopped due to unknown error:\n",
      "not enough values to unpack (expected 2, got 0)\n",
      "More details in the backtrace extract below\n",
      "--------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/user/scansiz/home/projects/fedbiomed-dev/fedbiomed/fedbiomed/researcher/experiment.py\", line 72, in payload\n",
      "    ret = function(*args, **kwargs)\n",
      "  File \"/user/scansiz/home/projects/fedbiomed-dev/fedbiomed/fedbiomed/researcher/experiment.py\", line 1653, in run_once\n",
      "    aggr_args_thr_msg, aggr_args_thr_file = self._aggregator.create_aggregator_args(self._global_model,\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "FedbiomedSilentTerminationError",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:43:51,807 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:43:51,809 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:43:51,811 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:43:51,815 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:43:51,816 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:43:51,817 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:43:55,859 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:43:55,863 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:43:55,869 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:44:51,812 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:44:51,814 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:44:51,816 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:44:55,832 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:44:55,834 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:44:55,836 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:45:53,822 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:45:53,825 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:45:53,827 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:45:55,836 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:45:55,838 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:45:55,840 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:46:53,825 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:46:53,827 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:46:53,830 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:46:55,839 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:46:55,842 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:46:55,845 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:47:53,829 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:47:53,832 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:47:53,836 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:47:55,844 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:47:55,846 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:47:55,848 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:48:53,833 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:48:53,835 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:48:53,838 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:48:55,847 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:48:55,850 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:48:55,853 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:49:53,839 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:49:53,843 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:49:53,847 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:49:55,852 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:49:55,854 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:49:55,859 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:50:53,842 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:50:53,845 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:50:53,847 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:50:55,856 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:50:55,860 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:50:55,863 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:51:53,847 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:51:53,850 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:51:53,852 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:51:55,860 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:51:55,863 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:51:55,865 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:52:53,853 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:52:53,855 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:52:53,856 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:52:55,864 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:52:55,867 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:52:55,869 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:53:53,862 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:53:53,865 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:53:53,873 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:53:55,867 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:53:55,868 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:53:55,871 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:54:53,863 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:54:53,865 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:54:53,868 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:54:55,874 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:54:55,875 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:54:55,878 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:55:53,868 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:55:53,871 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:55:53,873 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:55:55,876 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:55:55,879 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:55:55,881 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:56:53,874 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:56:53,877 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:56:53,880 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:56:55,883 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:56:55,888 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:56:55,892 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:57:53,879 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:57:53,882 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:57:53,884 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:57:55,888 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:57:55,890 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:57:55,892 fedbiomed INFO - Waiting for tasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:58:53,884 fedbiomed INFO - Received request form node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:58:53,886 fedbiomed INFO - Node agent created node_415010f8-df19-4a90-8059-cf76a759d3f5\n",
      "2023-09-05 14:58:53,889 fedbiomed INFO - Waiting for tasks\n",
      "2023-09-05 14:58:55,895 fedbiomed INFO - Received request form node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:58:55,898 fedbiomed INFO - Node agent created node_41533df5-d07b-4027-a826-d1f67410d627\n",
      "2023-09-05 14:58:55,901 fedbiomed INFO - Waiting for tasks\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Training and Validation with sklearn Perceptron model\n",
    "\n",
    "\n",
    "Now we will use the validation facility on Skelearn training plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedPerceptron\n",
    "\n",
    "\n",
    "class SkLearnClassifierTrainingPlan(FedPerceptron):\n",
    "    def init_dependencies(self):\n",
    "        return [\"from torchvision import datasets, transforms\",]\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data: np.ndarray\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        \n",
    "        X_train = dataset.data.numpy()\n",
    "        X_train = X_train.reshape(-1, 28*28)\n",
    "        Y_train = dataset.targets.numpy()\n",
    "        \n",
    "        return DataManager(dataset=X_train,target=Y_train,  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to define validation option in the training arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = { 'max_iter':1000,\n",
    "              'tol': 1e-4 ,\n",
    "              'model': 'Perceptron' ,\n",
    "              'n_features': 28*28,\n",
    "              'n_classes' : 10,\n",
    "              'eta0':1e-6,\n",
    "              'random_state':1234,\n",
    "              'alpha':0.1 }\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 5, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 10\n",
    "\n",
    "# select nodes participing to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SkLearnClassifierTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None, \n",
    "                 tensorboard=True)\n",
    "\n",
    "\n",
    "exp.set_test_ratio(.2)\n",
    "#exp.set_test_metric(MetricTypes.PRECISION, average='macro')\n",
    "exp.set_test_on_global_updates(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feel free to run other sample notebooks or try your own models :D\n",
    "\n",
    "# 3. Validation facility using your own testing metric\n",
    "\n",
    "If the user wants to define its own testing metric, he can do so by defining the `testing_step` method in the Training plan. \n",
    "\n",
    "`testing_step` is defined the same way as `training_step`:\n",
    "\n",
    "When defining a `testing_step` method in the TrainingPlan, user has to:\n",
    "- predict classes or probabilities from model\n",
    "- compute a scalar or a list of scalars\n",
    "\n",
    "Method `testing_step` can return either a scalar or a list of scalars: in Tensorboard, list of scalars will be seen as the output of several metrics\n",
    "\n",
    "\n",
    "## 3.1 PyTorch Training Plan\n",
    "\n",
    "Below we showcase an example of a TorchTrainingPlan with a `testing_step` computing 3 metrics: log likelihood loss, a cross entropy loss, and a custom accuracy metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlanCM(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n",
    "\n",
    "    def testing_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "\n",
    "        #negative log likelihood loss\n",
    "        loss1 = torch.nn.functional.nll_loss(output, target)\n",
    "\n",
    "        #cross entropy\n",
    "        loss2 = torch.nn.functional.cross_entropy(output,target)\n",
    "\n",
    "        # accuracy\n",
    "        _,predicted = torch.max(output.data,1)\n",
    "        acc = torch.sum(predicted==target)\n",
    "        loss3 = acc/len(target)\n",
    "\n",
    "        # Returning results as list\n",
    "        return [loss1,loss2,loss3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, }, \n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3,   \n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "    'test_ratio': .3,\n",
    "    'test_on_local_updates': True, \n",
    "    'test_on_global_updates': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlanCM,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None, \n",
    "                 tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sklearn Training Plan\n",
    "\n",
    "Below we showcase an example of a SklearnTrainingPlan with a `testing_step` computing several metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedPerceptron\n",
    "from fedbiomed.common.data import DataManager\n",
    "import numpy as np\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "\n",
    "class SkLearnClassifierTrainingPlan(FedPerceptron):\n",
    "    def init_dependencies(self):\n",
    "        return [\"from torchvision import datasets, transforms\",\n",
    "                \"from torch.utils.data import DataLoader\",\n",
    "                \"from sklearn.metrics import hinge_loss\"]\n",
    "\n",
    "    def compute_accuracy_for_specific_digit(self, data, target, digit: int):\n",
    "        idx_data_equal_to_digit = (target.squeeze() == digit)\n",
    "        \n",
    "        predicted = self.model().predict(data[idx_data_equal_to_digit])\n",
    "        well_predicted_label = np.sum(predicted == digit) / np.sum(idx_data_equal_to_digit)\n",
    "        return well_predicted_label\n",
    "    \n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        \n",
    "        train_kwargs = { 'shuffle': True}  # number of data passed to classifier\n",
    "        X_train = dataset.data.numpy()\n",
    "        X_train = X_train.reshape(-1, 28*28)\n",
    "        Y_train = dataset.targets.numpy()\n",
    "        \n",
    "        return DataManager(dataset=X_train, target=Y_train)\n",
    "    \n",
    "    def testing_step(self, data, target):\n",
    "        # hinge loss\n",
    "        distance_from_hyperplan = self.model().decision_function(data)\n",
    "        loss = hinge_loss(target, distance_from_hyperplan)\n",
    "        \n",
    "        # get the accuracy only on images representing digit 1\n",
    "        well_predicted_label_1 = self.compute_accuracy_for_specific_digit(data, target, 1)\n",
    "        \n",
    "        # Returning results as dict\n",
    "        return {'Hinge Loss': loss, 'Well Predicted Label 1' : well_predicted_label_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = { 'max_iter':1000,\n",
    "              'tol': 1e-4 ,\n",
    "              'model': 'Perceptron' ,\n",
    "              'n_features': 28*28,\n",
    "              'n_classes' : 10,\n",
    "              'eta0':1e-6,\n",
    "              'random_state':1234,\n",
    "              'alpha':0.1 }\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 5, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 10\n",
    "\n",
    "# select nodes participing to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SkLearnClassifierTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None, \n",
    "                 tensorboard=True)\n",
    "\n",
    "\n",
    "exp.set_test_ratio(.2)\n",
    "#exp.set_test_metric(MetricTypes.PRECISION, average='macro')\n",
    "exp.set_test_on_global_updates(True)\n",
    "exp.set_test_on_local_updates(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
