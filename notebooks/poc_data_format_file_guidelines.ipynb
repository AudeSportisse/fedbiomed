{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee99bdb4",
   "metadata": {},
   "source": [
    "Related to user story: [SP11-Item04: General Data Wrapper PoC](https://gitlab.inria.fr/fedbiomed/fedbiomed/-/issues/164)\n",
    "\n",
    "## Tabular dataset\n",
    "\n",
    "Workflow of data pre processing:\n",
    "\n",
    "1. Columns name should be shared with the researcher\n",
    "2. Data format file to be filled by clinicians.\n",
    "3. Specify if missing data are allowed for a given columns (Exception). The file will be used for data verification during FL pre-processing,\n",
    "4. Outlier verification for quantitative data, continuous and discrete, and for dates (Critical warning),\n",
    "5. Missing data imputation by local mean (or optional NN), or majority voting for discrete labels. Give warnings when missing data are found (for verification a posteriori).\n",
    "6. Give critical warning when too many missing are found (>50%),\n",
    "7. Verify that number of available data is greater then minimum required (Error)\n",
    "\n",
    "Critical warnings have different levels of disclosure to the researcher (1) only the warning, 2) type of warning, 3) type of warning and column affected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aeb287",
   "metadata": {},
   "source": [
    "# 1. What is a `data_format_ref` file\n",
    "\n",
    "\n",
    "A `data_format_ref_file` is a JSON file containing all the skeleton of the data. \n",
    "It should be created by a clinician and sent to nodes, in order to check nodes dataset integrity.\n",
    "In case there is a mismatch between nodes dataset and `data_format_ref_file` \n",
    "\n",
    "Structure of a `data_format_file_ref`:\n",
    "\n",
    "\n",
    "\n",
    "# 2. Creating a `data_format_ref` file using an existing dataset\n",
    "\n",
    "In this notebook, we provide a way to create `data_fromat_ref_file` using an existing dataset. \n",
    "Then, user can edit it (ie change `data_format_file_ref` file, and complete information already contained into the file)\n",
    "\n",
    "## 2.1 Loading tabular dataset\n",
    "\n",
    "For that, we provide a `load_tabular_datasets` function able to load every kind of tabular dataset `*.csv`, `.xls`, folder of `*.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c51343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.data_tool.utils import load_tabular_datasets, save_format_file_ref\n",
    "from fedbiomed.common.data_tool.data_format_ref_cli import get_from_user_multi_view_dataset_fromat_file, edit_format_file_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9e63f",
   "metadata": {},
   "source": [
    "**load_tabular_datasets** method can export several files type (excel file, csv file, and folder containing csv files) \n",
    "\n",
    "## Caution! all data are stored in a folder named `/data/` in `fedbiomed/notebooks` \n",
    "\n",
    "### 2.1.1 Export Excel File\n",
    "\n",
    "You can export Excel files as shown in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca36ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: aenum in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (3.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl #(for opening excel files)\n",
    "!pip install aenum  # needed to create custom data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6750dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found\n",
      "err 'utf-8' codec can't decode byte 0x8c in position 15: invalid start byte in file ./data/excel/Exceltest.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Exceltest.xlsx':    ID   Age Eligibility\n",
       " 0    1   45           Y\n",
       " 1    2   45           Y\n",
       " 2    3   33           N\n",
       " 3    4   54           Y\n",
       " 4    5   45           Y\n",
       " 5    6   54         NaN\n",
       " 6    7   34           N\n",
       " 7    8   54         NaN\n",
       " 8    9   45         NaN\n",
       " 9   10   44           Y}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can load excel files\n",
    "load_tabular_datasets(r'./data/excel/Exceltest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6f2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found\n",
      "err 'utf-8' codec can't decode byte 0x87 in position 11: invalid start byte in file ./data/excel/test_excel.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_excel.xlsx':      a  b     val\n",
       " 0    1  a  10.000\n",
       " 1    2  b   3.000\n",
       " 2    3  c   3.900\n",
       " 3    4  d   8.000\n",
       " 4    5  a   9.009\n",
       " 5    6  b  11.000\n",
       " 6    7  c   4.000\n",
       " 7    8  d   4.900\n",
       " 8    9  a   9.000\n",
       " 9   10  b  10.009\n",
       " 10  11  c  12.000\n",
       " 11  12  d   5.000\n",
       " 12  13  a   5.900\n",
       " 13  14  b  10.000\n",
       " 14  15  c  11.009\n",
       " 15  16  d  13.000\n",
       " 16  17  a   6.000\n",
       " 17  18  b   6.900\n",
       " 18  19  c  11.000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_tabular_datasets(r'./data/excel/test_excel.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f3d3e",
   "metadata": {},
   "source": [
    "### 2.1.2 Export CSV file\n",
    "\n",
    "\n",
    "It is a modified version of `pseudo_adni_mod` csv dataset with the first column (`CDRSB.bl`) being converted into a column of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470a1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found\n"
     ]
    }
   ],
   "source": [
    "# simple csv dataset\n",
    "pseudo_adni = load_tabular_datasets(r'data/pseudo_adni/pseudo_adni_mod_2.csv')\n",
    "#single_view_dataset = load_tabular_datasets(r'/user/ybouilla/home/Documents/data/pseudo_adni_mod/pseudo_adni_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2107a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "448e80b5",
   "metadata": {},
   "source": [
    "### 2.1.3 Export a folder containing csv files\n",
    "\n",
    "for loading a folder (multi view dataset, one has to load the path of the directory (instead of a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4fb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/csv_folder\u001b[0m\r\n",
      "├── contatct\r\n",
      "├── file1\r\n",
      "└── file2\r\n",
      "\r\n",
      "0 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree data/csv_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed673dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory found\n"
     ]
    }
   ],
   "source": [
    "# folder of dataset\n",
    "multi_view_dataframe =  load_tabular_datasets('data/csv_folder')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81839f87",
   "metadata": {},
   "source": [
    "## 2.2 create the `data_format_ref` file from the loaded dataset\n",
    "\n",
    "Let's assume the loaded dataset is a reference dataset, and we want to create from this  dataset a `data_format_ref`. \n",
    "\n",
    "\n",
    "### workflow logic:\n",
    "\n",
    "```\n",
    "for each view:\n",
    "    for each feature whithin view:\n",
    "        ask user to select one type within all type present in `Enum` class `DataType` (if user wants to add this feature inside`data_format_ref`)\n",
    "        ask user to indicate if variable can have missing data or not\n",
    "        ask user to indicate which data imputation method he wants to select\n",
    "        (imputation methods are given from the one specified in `Enum` class `ImputationMethods`\n",
    "        \n",
    "```\n",
    "\n",
    "**Default DataType**:\n",
    "\n",
    "1) KEY \n",
    "2) QUANTITATIVE \n",
    "3) CATEGORICAL \n",
    "4) DATETIME \n",
    "5) UNKNOWN (when user doesnot want to specify a variable type: it will downgrade the data sanity check)\n",
    "\n",
    "\n",
    "**Data Imputation Methods**\n",
    "\n",
    "1) MEAN_IMPUTATION\n",
    "2) MODE_IMPUTATION\n",
    "3) KNN_IMPUTATION\n",
    "4) LINEAR_INTERPOLATION_IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6816302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++ Editing Global Thresholds +++++++++++\n",
      "Do you want to add a threshold for the minimum number of samples each dataset should contain?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Do you want to add a threshold for the minimum number of missing data each feature should contain?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++ Now parsing view: pseudo_adni_mod_2.csv +++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "displaying first 10 values of feature CDRSB.bl in view: pseudo_adni_mod_2.csv (n_feature: 1/16)\n",
      "0    b\n",
      "1    a\n",
      "2    a\n",
      "3    a\n",
      "4    a\n",
      "5    b\n",
      "6    e\n",
      "7    a\n",
      "8    d\n",
      "9    c\n",
      "Name: CDRSB.bl, dtype: object\n",
      "number of differents samples: 8 / total of samples: 1000\n",
      "specify data type for CDRSB.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "1\n",
      "data_type DataType.KEY KEY\n",
      "CATEGORICAL KEY\n",
      "Datetime ambiguity: Please specify if variable CDRSB.bl is a date or not\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "displaying first 10 values of feature ADAS11.bl in view: pseudo_adni_mod_2.csv (n_feature: 2/16)\n",
      "0     8\n",
      "1     0\n",
      "2     8\n",
      "3     3\n",
      "4     0\n",
      "5    10\n",
      "6    12\n",
      "7     2\n",
      "8     8\n",
      "9    11\n",
      "Name: ADAS11.bl, dtype: int64\n",
      "number of differents samples: 28 / total of samples: 1000\n",
      "specify data type for ADAS11.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature ADAS11.bl\n",
      "displaying first 10 values of feature MMSE.bl in view: pseudo_adni_mod_2.csv (n_feature: 3/16)\n",
      "0    27.0\n",
      "1    30.0\n",
      "2    24.0\n",
      "3    29.0\n",
      "4    30.0\n",
      "5    27.0\n",
      "6    24.0\n",
      "7    30.0\n",
      "8    28.0\n",
      "9    27.0\n",
      "Name: MMSE.bl, dtype: float64\n",
      "number of differents samples: 11 / total of samples: 1000\n",
      "specify data type for MMSE.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature MMSE.bl\n",
      "displaying first 10 values of feature RAVLT.immediate.bl in view: pseudo_adni_mod_2.csv (n_feature: 4/16)\n",
      "0    23.739439\n",
      "1    64.933800\n",
      "2    36.987722\n",
      "3    50.314425\n",
      "4    57.217830\n",
      "5    37.209473\n",
      "6    37.216348\n",
      "7    46.391300\n",
      "8    34.576231\n",
      "9    19.897128\n",
      "Name: RAVLT.immediate.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for RAVLT.immediate.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature RAVLT.immediate.bl\n",
      "displaying first 10 values of feature RAVLT.learning.bl in view: pseudo_adni_mod_2.csv (n_feature: 5/16)\n",
      "0    4.0\n",
      "1    9.0\n",
      "2    3.0\n",
      "3    5.0\n",
      "4    9.0\n",
      "5    2.0\n",
      "6    6.0\n",
      "7    6.0\n",
      "8    3.0\n",
      "9    1.0\n",
      "Name: RAVLT.learning.bl, dtype: float64\n",
      "number of differents samples: 13 / total of samples: 1000\n",
      "specify data type for RAVLT.learning.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature RAVLT.learning.bl\n",
      "displaying first 10 values of feature RAVLT.forgetting.bl in view: pseudo_adni_mod_2.csv (n_feature: 6/16)\n",
      "0    5.821573\n",
      "1    4.001653\n",
      "2    6.876316\n",
      "3    4.733481\n",
      "4    7.225401\n",
      "5    8.421522\n",
      "6    6.137385\n",
      "7    5.128675\n",
      "8    4.023993\n",
      "9    4.142775\n",
      "Name: RAVLT.forgetting.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for RAVLT.forgetting.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature RAVLT.forgetting.bl\n",
      "displaying first 10 values of feature FAQ.bl in view: pseudo_adni_mod_2.csv (n_feature: 7/16)\n",
      "0     3\n",
      "1     0\n",
      "2     0\n",
      "3     3\n",
      "4     0\n",
      "5     4\n",
      "6    12\n",
      "7     0\n",
      "8    10\n",
      "9     6\n",
      "Name: FAQ.bl, dtype: int64\n",
      "number of differents samples: 20 / total of samples: 1000\n",
      "specify data type for FAQ.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature FAQ.bl\n",
      "displaying first 10 values of feature WholeBrain.bl in view: pseudo_adni_mod_2.csv (n_feature: 8/16)\n",
      "0    0.684331\n",
      "1    0.735892\n",
      "2    0.738731\n",
      "3    0.696179\n",
      "4    0.841806\n",
      "5    0.708125\n",
      "6    0.649689\n",
      "7    0.759112\n",
      "8    0.773193\n",
      "9    0.654161\n",
      "Name: WholeBrain.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for WholeBrain.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature WholeBrain.bl\n",
      "displaying first 10 values of feature Ventricles.bl in view: pseudo_adni_mod_2.csv (n_feature: 9/16)\n",
      "0    0.012699\n",
      "1    0.012803\n",
      "2    0.030492\n",
      "3    0.032797\n",
      "4    0.004030\n",
      "5    0.026286\n",
      "6    0.026068\n",
      "7    0.018997\n",
      "8    0.005643\n",
      "9    0.038188\n",
      "Name: Ventricles.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for Ventricles.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature Ventricles.bl\n",
      "displaying first 10 values of feature Hippocampus.bl in view: pseudo_adni_mod_2.csv (n_feature: 10/16)\n",
      "0    0.003786\n",
      "1    0.004866\n",
      "2    0.004300\n",
      "3    0.004720\n",
      "4    0.006820\n",
      "5    0.005262\n",
      "6    0.004314\n",
      "7    0.006479\n",
      "8    0.005609\n",
      "9    0.003478\n",
      "Name: Hippocampus.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for Hippocampus.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature Hippocampus.bl\n",
      "displaying first 10 values of feature MidTemp.bl in view: pseudo_adni_mod_2.csv (n_feature: 11/16)\n",
      "0    0.012678\n",
      "1    0.015071\n",
      "2    0.012419\n",
      "3    0.012312\n",
      "4    0.016948\n",
      "5    0.013632\n",
      "6    0.012296\n",
      "7    0.014903\n",
      "8    0.011644\n",
      "9    0.012776\n",
      "Name: MidTemp.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for MidTemp.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature MidTemp.bl\n",
      "displaying first 10 values of feature Entorhinal.bl in view: pseudo_adni_mod_2.csv (n_feature: 12/16)\n",
      "0    0.002214\n",
      "1    0.003041\n",
      "2    0.002316\n",
      "3    0.002593\n",
      "4    0.002896\n",
      "5    0.002358\n",
      "6    0.001747\n",
      "7    0.002881\n",
      "8    0.002748\n",
      "9    0.001833\n",
      "Name: Entorhinal.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for Entorhinal.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature Entorhinal.bl\n",
      "displaying first 10 values of feature ABETA.MEDIAN.bl in view: pseudo_adni_mod_2.csv (n_feature: 13/16)\n",
      "0    154.016065\n",
      "1    211.573206\n",
      "2    163.637668\n",
      "3    182.256297\n",
      "4    247.997479\n",
      "5    174.159343\n",
      "6    200.303050\n",
      "7    219.381922\n",
      "8    195.466999\n",
      "9    147.780038\n",
      "Name: ABETA.MEDIAN.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for ABETA.MEDIAN.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature ABETA.MEDIAN.bl\n",
      "displaying first 10 values of feature PTAU.MEDIAN.bl in view: pseudo_adni_mod_2.csv (n_feature: 14/16)\n",
      "0     67.970509\n",
      "1      5.451168\n",
      "2     66.704378\n",
      "3     47.091893\n",
      "4     -5.997140\n",
      "5     39.930517\n",
      "6     30.004188\n",
      "7     39.929520\n",
      "8    103.082202\n",
      "9     50.473814\n",
      "Name: PTAU.MEDIAN.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for PTAU.MEDIAN.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature PTAU.MEDIAN.bl\n",
      "displaying first 10 values of feature TAU.MEDIAN.bl in view: pseudo_adni_mod_2.csv (n_feature: 15/16)\n",
      "0    132.571916\n",
      "1     33.787719\n",
      "2    110.049924\n",
      "3    138.690457\n",
      "4    -61.573234\n",
      "5    109.317598\n",
      "6     -0.372409\n",
      "7    114.830917\n",
      "8    138.734948\n",
      "9     57.337968\n",
      "Name: TAU.MEDIAN.bl, dtype: float64\n",
      "number of differents samples: 1000 / total of samples: 1000\n",
      "specify data type for TAU.MEDIAN.bl:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature TAU.MEDIAN.bl\n",
      "displaying first 10 values of feature AGE in view: pseudo_adni_mod_2.csv (n_feature: 16/16)\n",
      "0    75.0\n",
      "1    67.0\n",
      "2    63.0\n",
      "3    75.0\n",
      "4    65.0\n",
      "5    66.0\n",
      "6    69.0\n",
      "7    68.0\n",
      "8    76.0\n",
      "9    73.0\n",
      "Name: AGE, dtype: float64\n",
      "number of differents samples: 44 / total of samples: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specify data type for AGE:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature AGE\n"
     ]
    }
   ],
   "source": [
    "single_data_format_file_test = get_from_user_multi_view_dataset_fromat_file(pseudo_adni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26016d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': 1000, 'min_nb_missing_samples': 10},\n",
       " 'pseudo_adni_mod_2.csv': {'CDRSB.bl': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'ADAS11.bl': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': [\"<class 'numpy.datetime64'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'MMSE.bl': {'data_format': 'UNKNOWN',\n",
       "   'data_type': 'UNKNOWN',\n",
       "   'values': None,\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_data_format_file_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cf729",
   "metadata": {},
   "source": [
    "## single_data_format_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6380f157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++ Editing Global Thresholds +++++++++++\n",
      "Do you want to add a threshold for the minimum number of samples each dataset should contain?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "enter threshold minimal number of samples per dataset\n",
      "10000\n",
      "Do you want to add a threshold for the minimum number of missing data each feature should contain?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "enter threshold minimal number of missing sample per variable\n",
      "10\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++ Now parsing view: file1 +++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "displaying first 10 values of feature a in view: file1 (n_feature: 1/18)\n",
      "0    48\n",
      "1    87\n",
      "2    46\n",
      "3    84\n",
      "4    94\n",
      "5    18\n",
      "6    15\n",
      "7    30\n",
      "8    54\n",
      "9    46\n",
      "Name: a, dtype: int64\n",
      "number of differents samples: 57 / total of samples: 100\n",
      "specify data type for a:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "6\n",
      "data_type DataType.UNKNOWN UNKNOWN\n",
      "CATEGORICAL UNKNOWN\n",
      "Allow a to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature e in view: file1 (n_feature: 2/18)\n",
      "0    98\n",
      "1    83\n",
      "2    73\n",
      "3    45\n",
      "4    84\n",
      "5     5\n",
      "6    44\n",
      "7    55\n",
      "8    37\n",
      "9     8\n",
      "Name: e, dtype: int64\n",
      "number of differents samples: 65 / total of samples: 100\n",
      "specify data type for e:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "4\n",
      "data_type DataType.DATETIME DATETIME\n",
      "CATEGORICAL DATETIME\n",
      "displaying first 10 values of feature i in view: file1 (n_feature: 3/18)\n",
      "0    65\n",
      "1    13\n",
      "2    81\n",
      "3    81\n",
      "4     0\n",
      "5    57\n",
      "6    14\n",
      "7    98\n",
      "8    13\n",
      "9    89\n",
      "Name: i, dtype: int64\n",
      "number of differents samples: 61 / total of samples: 100\n",
      "specify data type for i:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "6\n",
      "data_type DataType.UNKNOWN UNKNOWN\n",
      "CATEGORICAL UNKNOWN\n",
      "Allow i to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      " d_type int64\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      "4\n",
      "get msg []\n",
      "get msg (selected) []\n",
      "Please select view that contained desired feature:\n",
      "1) file1 \n",
      "2) contatct \n",
      "3) file2 \n",
      "4) select all views\n",
      "4\n",
      "end ['file1', 'file2', 'contatct'] False False\n",
      "get msg ['file1', 'file2', 'contatct']\n",
      "get msg (selected) ['file1', 'file2', 'contatct']\n",
      "Please select view that contained desired feature:\n",
      "1) file1 (selected)\n",
      "2) contatct (selected)\n",
      "3) file2 (selected)\n",
      "4) select all views\n",
      "5) Finish feature selection\n",
      "5\n",
      "Do you want to add more variable to apply to data imputation method ?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature o in view: file1 (n_feature: 4/18)\n",
      "0     5\n",
      "1    70\n",
      "2    96\n",
      "3    39\n",
      "4    15\n",
      "5    28\n",
      "6    29\n",
      "7    82\n",
      "8    19\n",
      "9    21\n",
      "Name: o, dtype: int64\n",
      "number of differents samples: 61 / total of samples: 100\n",
      "specify data type for o:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'int'>\n",
      "found  <class 'numpy.int64'>\n",
      "int64 <class 'numpy.int64'> [dtype('int64')]\n",
      "Allow o to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature 0 in view: file1 (n_feature: 5/18)\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7     True\n",
      "8     True\n",
      "9    False\n",
      "Name: 0, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 0:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'bool'>\n",
      "bool <class 'bool'> [dtype('bool')]\n",
      "Allow 0 to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature 1 in view: file1 (n_feature: 6/18)\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "6    False\n",
      "7     True\n",
      "8     True\n",
      "9     True\n",
      "Name: 1, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 1\n",
      "displaying first 10 values of feature 2 in view: file1 (n_feature: 7/18)\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: 2, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 2:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 2\n",
      "displaying first 10 values of feature 3 in view: file1 (n_feature: 8/18)\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: 3, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 3:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 3\n",
      "displaying first 10 values of feature time in view: file1 (n_feature: 9/18)\n",
      "0    2018-01-01 00:00:00\n",
      "1    2018-01-01 01:00:00\n",
      "2    2018-01-01 02:00:00\n",
      "3    2018-01-01 03:00:00\n",
      "4    2018-01-01 04:00:00\n",
      "5    2018-01-01 05:00:00\n",
      "6    2018-01-01 06:00:00\n",
      "7    2018-01-01 07:00:00\n",
      "8    2018-01-01 08:00:00\n",
      "9    2018-01-01 09:00:00\n",
      "Name: time, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for time:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "4\n",
      "data_type DataType.DATETIME DATETIME\n",
      "CATEGORICAL DATETIME\n",
      "displaying first 10 values of feature pressure in view: file1 (n_feature: 10/18)\n",
      "0    0.088082\n",
      "1    0.774788\n",
      "2    0.514092\n",
      "3    0.832881\n",
      "4    0.696152\n",
      "5    0.166896\n",
      "6    0.740141\n",
      "7    0.067837\n",
      "8    0.342615\n",
      "9    0.777026\n",
      "Name: pressure, dtype: float64\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for pressure:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'float'>\n",
      "found  <class 'numpy.float64'>\n",
      "float64 <class 'numpy.float64'> [dtype('float64')]\n",
      "Allow pressure to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature sp02 in view: file1 (n_feature: 11/18)\n",
      "0    0.360430\n",
      "1    0.072426\n",
      "2    0.538551\n",
      "3    0.761962\n",
      "4    0.389385\n",
      "5    0.200984\n",
      "6    0.765184\n",
      "7    0.258049\n",
      "8    0.736926\n",
      "9    0.253232\n",
      "Name: sp02, dtype: float64\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for sp02:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'float'>\n",
      "found  <class 'numpy.float64'>\n",
      "float64 <class 'numpy.float64'> [dtype('float64')]\n",
      "Allow sp02 to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature a.1 in view: file1 (n_feature: 12/18)\n",
      "0    90\n",
      "1    15\n",
      "2    30\n",
      "3    42\n",
      "4    65\n",
      "5    21\n",
      "6    60\n",
      "7     0\n",
      "8    33\n",
      "9    64\n",
      "Name: a.1, dtype: int64\n",
      "number of differents samples: 62 / total of samples: 100\n",
      "specify data type for a.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'int'>\n",
      "found  <class 'numpy.int64'>\n",
      "int64 <class 'numpy.int64'> [dtype('int64')]\n",
      "Allow a.1 to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature e.1 in view: file1 (n_feature: 13/18)\n",
      "0    63\n",
      "1    20\n",
      "2     2\n",
      "3    70\n",
      "4    90\n",
      "5    94\n",
      "6    33\n",
      "7    94\n",
      "8    71\n",
      "9    65\n",
      "Name: e.1, dtype: int64\n",
      "number of differents samples: 61 / total of samples: 100\n",
      "specify data type for e.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature e.1\n",
      "displaying first 10 values of feature i.1 in view: file1 (n_feature: 14/18)\n",
      "0    60\n",
      "1    45\n",
      "2     6\n",
      "3     7\n",
      "4    12\n",
      "5    77\n",
      "6    75\n",
      "7    50\n",
      "8    94\n",
      "9    15\n",
      "Name: i.1, dtype: int64\n",
      "number of differents samples: 67 / total of samples: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specify data type for i.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature i.1\n",
      "displaying first 10 values of feature o.1 in view: file1 (n_feature: 15/18)\n",
      "0     8\n",
      "1    10\n",
      "2    22\n",
      "3    79\n",
      "4    90\n",
      "5     2\n",
      "6    85\n",
      "7    64\n",
      "8    47\n",
      "9    30\n",
      "Name: o.1, dtype: int64\n",
      "number of differents samples: 69 / total of samples: 100\n",
      "specify data type for o.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature o.1\n",
      "displaying first 10 values of feature gender in view: file1 (n_feature: 16/18)\n",
      "0      MAN\n",
      "1      MAN\n",
      "2    WOMAN\n",
      "3    WOMAN\n",
      "4      MAN\n",
      "5      MAN\n",
      "6    WOMAN\n",
      "7    WOMAN\n",
      "8    WOMAN\n",
      "9      MAN\n",
      "Name: gender, dtype: object\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for gender:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "Allow gender to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature blood type in view: file1 (n_feature: 17/18)\n",
      "0      A\n",
      "1      O\n",
      "2      A\n",
      "3     AB\n",
      "4      B\n",
      "5     AB\n",
      "6      O\n",
      "7      B\n",
      "8    NaN\n",
      "9      A\n",
      "Name: blood type, dtype: object\n",
      "number of differents samples: 5 / total of samples: 100\n",
      "specify data type for blood type:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "Allow blood type to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature pkey in view: file1 (n_feature: 18/18)\n",
      "0    zmixzrgvxrjqxoe sluk\n",
      "1    vrzahnpfluspdcbfnaqt\n",
      "2    pnrepvmrxqabdlvisclv\n",
      "3    gwj luzejwdxzsiljxzd\n",
      "4    jjdvcnofivbqhirxzdyo\n",
      "5    e fshtkhnlimpczypnoe\n",
      "6    qe nlikallf znokwdhk\n",
      "7    kgenxxkftoeqtrnoteaq\n",
      "8    abghippigyxzaxtejumu\n",
      "9    ezfasuuycdda foisjte\n",
      "Name: pkey, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for pkey:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "1\n",
      "data_type DataType.KEY KEY\n",
      "CATEGORICAL KEY\n",
      "Datetime ambiguity: Please specify if variable pkey is a date or not\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++ Now parsing view: contatct +++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "displaying first 10 values of feature discrete in view: contatct (n_feature: 1/3)\n",
      "0    64.0\n",
      "1    26.0\n",
      "2    61.0\n",
      "3    29.0\n",
      "4    99.0\n",
      "5     5.0\n",
      "6    71.0\n",
      "7    99.0\n",
      "8    90.0\n",
      "9    36.0\n",
      "Name: discrete, dtype: float64\n",
      "number of differents samples: 70 / total of samples: 100\n",
      "specify data type for discrete:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'float'>\n",
      "found  <class 'numpy.float64'>\n",
      "float64 <class 'numpy.float64'> [dtype('float64')]\n",
      "Allow discrete to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      " d_type float64\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      "3\n",
      "Method imputation selected: KNN_IMPUTATION\n",
      "\n",
      "please specify k value:\n",
      "3\n",
      "imput param {'k': '3'}\n",
      "get msg []\n",
      "get msg (selected) []\n",
      "Please select view that contained desired feature:\n",
      "1) file1 \n",
      "2) contatct \n",
      "3) file2 \n",
      "4) select all views\n",
      "2\n",
      "Please select a feature in contatct\n",
      "get msg (selected) []\n",
      "Please select feature from view : contatct\n",
      "1) city \n",
      "2) pkey \n",
      "3) select all features\n",
      "4) return to view\n",
      "3\n",
      "end [] False False\n",
      "get msg []\n",
      "get msg (selected) []\n",
      "Please select view that contained desired feature:\n",
      "1) file1 \n",
      "2) contatct \n",
      "3) file2 \n",
      "4) select all views\n",
      "5) Finish feature selection\n",
      "5\n",
      "Do you want to add more variable to apply to data imputation method ?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature city in view: contatct (n_feature: 2/3)\n",
      "0        Lille\n",
      "1        Lille\n",
      "2        Paris\n",
      "3        Paris\n",
      "4        Lille\n",
      "5        Lille\n",
      "6        Paris\n",
      "7        Paris\n",
      "8    Marseille\n",
      "9        Lille\n",
      "Name: city, dtype: object\n",
      "number of differents samples: 3 / total of samples: 100\n",
      "specify data type for city:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "Allow city to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature pkey in view: contatct (n_feature: 3/3)\n",
      "0    qpqorfhylu gmfjy bdj\n",
      "1    kkmjozalfyirgsire ui\n",
      "2    ezfasuuycdda foisjte\n",
      "3    faxiqkt xggzmwzoidbg\n",
      "4    znwhlj rwzdutnagwasy\n",
      "5    ki vn mtcclzwskgaewy\n",
      "6    exrmjfolirbtkgjswcin\n",
      "7    jsgohdb eieenvdwjopr\n",
      "8    kzrybjgjxm rde xqmra\n",
      "9    ruchbfa zwgenxslegrl\n",
      "Name: pkey, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for pkey:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "1\n",
      "data_type DataType.KEY KEY\n",
      "CATEGORICAL KEY\n",
      "Datetime ambiguity: Please specify if variable pkey is a date or not\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++ Now parsing view: file2 +++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "displaying first 10 values of feature 0 in view: file2 (n_feature: 1/7)\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: 0, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 0:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 0\n",
      "displaying first 10 values of feature 1 in view: file2 (n_feature: 2/7)\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "8     True\n",
      "9     True\n",
      "Name: 1, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'bool'>\n",
      "bool <class 'bool'> [dtype('bool')]\n",
      "Allow 1 to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature 2 in view: file2 (n_feature: 3/7)\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "6    False\n",
      "7    False\n",
      "8     True\n",
      "9    False\n",
      "Name: 2, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 2:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 2\n",
      "displaying first 10 values of feature 3 in view: file2 (n_feature: 4/7)\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8     True\n",
      "9     True\n",
      "Name: 3, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 3:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 3\n",
      "displaying first 10 values of feature time in view: file2 (n_feature: 5/7)\n",
      "0    2018-01-01 00:00:00\n",
      "1    2018-01-01 01:00:00\n",
      "2    2018-01-01 02:00:00\n",
      "3    2018-01-01 03:00:00\n",
      "4    2018-01-01 04:00:00\n",
      "5    2018-01-01 05:00:00\n",
      "6    2018-01-01 06:00:00\n",
      "7    2018-01-01 07:00:00\n",
      "8    2018-01-01 08:00:00\n",
      "9    2018-01-01 09:00:00\n",
      "Name: time, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for time:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "4\n",
      "data_type DataType.DATETIME DATETIME\n",
      "CATEGORICAL DATETIME\n",
      "displaying first 10 values of feature pH in view: file2 (n_feature: 6/7)\n",
      "0    0.023107\n",
      "1         NaN\n",
      "2    0.407279\n",
      "3    0.536301\n",
      "4    0.749443\n",
      "5    0.203130\n",
      "6    0.524939\n",
      "7    0.518098\n",
      "8    0.760008\n",
      "9    0.998239\n",
      "Name: pH, dtype: float64\n",
      "number of differents samples: 100 / total of samples: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specify data type for pH:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'float'>\n",
      "found  <class 'numpy.float64'>\n",
      "float64 <class 'numpy.float64'> [dtype('float64')]\n",
      "Allow pH to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature pkey in view: file2 (n_feature: 7/7)\n",
      "0    kkmjozalfyirgsire ui\n",
      "1    xkdawggpnuulcewuoyzz\n",
      "2    khuulhwgwnjggrfoefce\n",
      "3    xxysdmwwmjsmyhaswfdb\n",
      "4    ldejfuij mnbnf wwmms\n",
      "5    pvhkafscqfwzofgqziko\n",
      "6    rgggl wzpfkfbftmtjoo\n",
      "7    stjrqcvljprtvralmnil\n",
      "8    kms wptwzta nzdbkncc\n",
      "9    kzrybjgjxm rde xqmra\n",
      "Name: pkey, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for pkey:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "1\n",
      "data_type DataType.KEY KEY\n",
      "CATEGORICAL KEY\n",
      "Datetime ambiguity: Please specify if variable pkey is a date or not\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n"
     ]
    }
   ],
   "source": [
    "multi_data_format_file_test = get_from_user_multi_view_dataset_fromat_file(multi_view_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1268c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': 10000, 'min_nb_missing_samples': 10},\n",
       " 'file1': {'a': {'data_format': 'UNKNOWN',\n",
       "   'data_type': 'UNKNOWN',\n",
       "   'values': None,\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'e': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': [\"<class 'numpy.datetime64'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'i': {'data_format': 'UNKNOWN',\n",
       "   'data_type': 'UNKNOWN',\n",
       "   'values': None,\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'LINEAR_INTERPOLATION_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': {'file1': ['a',\n",
       "     'e',\n",
       "     'i',\n",
       "     'o',\n",
       "     '0',\n",
       "     '1',\n",
       "     '2',\n",
       "     '3',\n",
       "     'time',\n",
       "     'pressure',\n",
       "     'sp02',\n",
       "     'a.1',\n",
       "     'e.1',\n",
       "     'i.1',\n",
       "     'o.1',\n",
       "     'gender',\n",
       "     'blood type',\n",
       "     'pkey'],\n",
       "    'contatct': ['discrete', 'city', 'pkey'],\n",
       "    'file2': ['0', '1', '2', '3', 'time', 'pH', 'pkey']}},\n",
       "  'o': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': ['int64'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  '0': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': ['bool'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': [\"<class 'numpy.datetime64'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pressure': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': ['float64'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'sp02': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': ['float64'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'a.1': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': ['int64'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'gender': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'blood type': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}},\n",
       " 'contatct': {'discrete': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': ['float64'],\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'KNN_IMPUTATION',\n",
       "   'data_imputation_parameters': {'k': '3'},\n",
       "   'data_imputation_variables': {'file1': [],\n",
       "    'contatct': ['city', 'pkey'],\n",
       "    'file2': []}},\n",
       "  'city': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}},\n",
       " 'file2': {'1': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': ['bool'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': [\"<class 'numpy.datetime64'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pH': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': ['float64'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_data_format_file_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d533e99",
   "metadata": {},
   "source": [
    "Data format file to be filled by clinicians (step 2 int he workflow):\n",
    "\n",
    "Data format file will be a dictionary specifying the type: \n",
    "\n",
    "\n",
    "```\n",
    "{<view_name>: {<feature_name>: {'data_format' : <data_fomat>,\n",
    "                                   'data_type': <data_type>,\n",
    "                                   'type':<values_taken>,\n",
    "                                   'is_missing_values': <True/False>,\n",
    "                                   'data_imputation_method': <name_of_dta_imputation_method> ,\n",
    "                                   'data_imputation_parameters': <parameter_of_iputation_method>,\n",
    "                                   'lower_bound': <float>,\n",
    "                                   'upper_bound': <float>,\n",
    "                                   'categorical_value': <List[values]>}\n",
    "                                   }\n",
    "                   }\n",
    "    }\n",
    "```\n",
    "\n",
    "where\n",
    "* `<view_name>` is the name of the view\n",
    "* `<feature_name>` is the name of the feature\n",
    "* `<data_type>` can be categorical or continuous or missing_data or datetime\n",
    "* `<value_taken>` is the type of the value (eg int, str, float, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee23c1",
   "metadata": {},
   "source": [
    "Saving `format_file_ref` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0a2e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Reference File successfully saved at single_format_file_ref_test2\n"
     ]
    }
   ],
   "source": [
    "save_format_file_ref(single_data_format_file_test, 'single_format_file_ref_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aaac0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Reference File successfully saved at int_multi_view_format_test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_format_file_ref(multi_data_format_file_test, 'int_multi_view_format_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b173a3",
   "metadata": {},
   "source": [
    "## 2.3 edit   `data_format_ref` file from an existing  `data_format_ref` file\n",
    "\n",
    "CLI `edit_format_file_ref` allows to specify additional information on variable when performing data sanity checking, including:\n",
    " - lower and upper bounds\n",
    " - catgorical_value (eg MALE, FEMALE)\n",
    " - data_type (not inferred anymore)\n",
    " - data imputation method (not inferred anymore)\n",
    " - date format (DO NOT WORK YET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369dd636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++ Now editing format file ref ++++++++++\n",
      "Edit file: pseudo_adni_mod_2.csv?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Edit variable: CDRSB.bl? (type: CATEGORICAL)\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "4\n",
      "action 4 4 {'1': <function ask_for_data_type at 0x7f2592f2f3a0>, '2': <function ask_for_categorical_values at 0x7f2592f2f4c0>, '3': <function ask_for_data_imputation_method at 0x7f2592f2f430>, '4': <function cancel_operation at 0x7f2592f2f160>}\n",
      "Edit variable: ADAS11.bl? (type: DATETIME)\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Date format\n",
      "5) Cancel Operation\n",
      "2\n",
      "action 2 5 {'1': <function ask_for_data_type at 0x7f2592f2f3a0>, '2': <function ask_for_lower_bound at 0x7f2592f2f1f0>, '3': <function ask_for_upper_bound at 0x7f2592f2f280>, '4': <function ask_for_date_format at 0x7f2592f2f550>, '5': <function cancel_operation at 0x7f2592f2f160>}\n",
      "enter lower bound0\n",
      "Continue Editing variable: ADAS11.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Date format\n",
      "5) Cancel Operation\n",
      "5\n",
      "action 5 5 {'1': <function ask_for_data_type at 0x7f2592f2f3a0>, '2': <function ask_for_lower_bound at 0x7f2592f2f1f0>, '3': <function ask_for_upper_bound at 0x7f2592f2f280>, '4': <function ask_for_date_format at 0x7f2592f2f550>, '5': <function cancel_operation at 0x7f2592f2f160>}\n",
      "Edit variable: MMSE.bl? (type: UNKNOWN)\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Data Value imputation method\n",
      "3) Cancel Operation\n",
      "3\n",
      "action 3 3 {'1': <function ask_for_data_type at 0x7f2592f2f3a0>, '2': <function ask_for_data_imputation_method at 0x7f2592f2f430>, '3': <function cancel_operation at 0x7f2592f2f160>}\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.common.data_tool.data_format_ref_cli import edit_format_file_ref\n",
    "from  fedbiomed.common.data_tool import utils\n",
    "\n",
    "single_data_format_file_test = edit_format_file_ref(single_data_format_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843461ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': 1000, 'min_nb_missing_samples': 10},\n",
       " 'pseudo_adni_mod_2.csv': {'CDRSB.bl': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': [\"<class 'str'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'categorical_values': ['1']},\n",
       "  'ADAS11.bl': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': [\"<class 'numpy.datetime64'>\"],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'lower_bound': 0.0},\n",
       "  'MMSE.bl': {'data_format': 'UNKNOWN',\n",
       "   'data_type': 'UNKNOWN',\n",
       "   'values': None,\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_data_format_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a064594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Reference File successfully saved at single_format_file_ref_test3\n"
     ]
    }
   ],
   "source": [
    "save_format_file_ref(single_data_format_file_test, 'single_format_file_ref_test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1afd4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++ Now editing format file ref ++++++++++\n",
      "Edit file: file1?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_193542/3017717444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmulti_data_format_file_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_format_file_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int_multi_view_format_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0medit_multi_view_format_file_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medit_format_file_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_data_format_file_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ybouilla/fedbiomed/fedbiomed/common/data_tool/data_format_ref_cli.py\u001b[0m in \u001b[0;36medit_format_file_ref\u001b[0;34m(format_file_ref)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_features_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mfeature_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_file_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 feature_content = edit_feature_format_file_ref(feature_content,\n\u001b[0m\u001b[1;32m    493\u001b[0m                                                                \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                                                                \u001b[0mview_feature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ybouilla/fedbiomed/fedbiomed/common/data_tool/data_format_ref_cli.py\u001b[0m in \u001b[0;36medit_feature_format_file_ref\u001b[0;34m(feature_content, feature_name, view_feature_name, messages)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0m_f_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0m_f_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Edit variable: {feature_name}? (type: {data_format})\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yes_or_no'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;31m# ask if user wants to edit feature variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0m_f_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_yes_no_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_f_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ybouilla/fedbiomed/fedbiomed/common/data_tool/data_format_ref_cli.py\u001b[0m in \u001b[0;36mget_user_input\u001b[0;34m(msg, n_answers)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_column_parsed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_answers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# check if value passed by user is correct (if it is integer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from fedbiomed.common.data_tool.data_format_ref_cli import get_from_user_multi_view_dataset_fromat_file, edit_format_file_ref\n",
    "from  fedbiomed.common.data_tool import utils\n",
    "\n",
    "multi_data_format_file_test = utils.load_format_file_ref('int_multi_view_format_test')\n",
    "\n",
    "edit_multi_view_format_file_test = edit_format_file_ref(multi_data_format_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4376757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Reference File successfully saved at edit_multi_view_format_file_test3\n"
     ]
    }
   ],
   "source": [
    "save_format_file_ref(edit_multi_view_format_file_test, 'edit_multi_view_format_file_test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9aac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': 40, 'min_nb_missing_samples': 20},\n",
       " 'file1': {'a': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'LINEAR_INTERPOLATION_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': {'file1': ['e',\n",
       "     'i',\n",
       "     'o',\n",
       "     '0',\n",
       "     '1',\n",
       "     '2',\n",
       "     '3',\n",
       "     'time',\n",
       "     'pressure',\n",
       "     'sp02',\n",
       "     'a.1',\n",
       "     'e.1',\n",
       "     'i.1',\n",
       "     'o.1',\n",
       "     'gender',\n",
       "     'blood type',\n",
       "     'pkey'],\n",
       "    'contatct': [],\n",
       "    'file2': []}},\n",
       "  'e': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'i': {'data_format': 'UNKNOWN',\n",
       "   'data_type': 'UNKNOWN',\n",
       "   'values': ['U', 'N', 'K', 'N', 'O', 'W', 'N'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  '0': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': 'bool',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'KNN_IMPUTATION',\n",
       "   'data_imputation_parameters': {'k': '5'},\n",
       "   'data_imputation_variables': {'file1': [],\n",
       "    'contatct': ['discrete', 'city', 'pkey'],\n",
       "    'file2': []},\n",
       "   'categorical_values': ['False', 'True']},\n",
       "  '1': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': 'bool',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pressure': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'lower_bound': 10.0},\n",
       "  'sp02': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'MEAN_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'upper_bound': 0.0},\n",
       "  'a.1': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'gender': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'MODE_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'categorical_values': ['WOMAN', 'MAN']},\n",
       "  'blood type': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'categorical_values': ['A', 'B', 'AB']},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}},\n",
       " 'contatct': {'discrete': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'city': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}},\n",
       " 'file2': {'2': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': 'bool',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'MODE_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pH': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'LINEAR_INTERPOLATION_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': {'file1': ['e',\n",
       "     'i',\n",
       "     'o',\n",
       "     '0',\n",
       "     '1',\n",
       "     '2',\n",
       "     '3',\n",
       "     'time',\n",
       "     'pressure',\n",
       "     'sp02',\n",
       "     'a.1',\n",
       "     'e.1',\n",
       "     'i.1',\n",
       "     'o.1',\n",
       "     'gender',\n",
       "     'blood type',\n",
       "     'pkey'],\n",
       "    'contatct': ['discrete', 'city', 'pkey'],\n",
       "    'file2': []}},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_multi_view_format_file_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955447d2",
   "metadata": {},
   "source": [
    "## 2.4 create custom DataType\n",
    "\n",
    "This may be re work because depends on a third party package `aenum`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
