{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee99bdb4",
   "metadata": {},
   "source": [
    "Related to user story: [SP11-Item04: General Data Wrapper PoC](https://gitlab.inria.fr/fedbiomed/fedbiomed/-/issues/164)\n",
    "\n",
    "## Tabular dataset\n",
    "\n",
    "Workflow of data pre processing:\n",
    "\n",
    "1. Columns name should be shared with the researcher\n",
    "2. Data format file to be filled by clinicians.\n",
    "3. Specify if missing data are allowed for a given columns (Exception). The file will be used for data verification during FL pre-processing,\n",
    "4. Outlier verification for quantitative data, continuous and discrete, and for dates (Critical warning),\n",
    "5. Missing data imputation by local mean (or optional NN), or majority voting for discrete labels. Give warnings when missing data are found (for verification a posteriori).\n",
    "6. Give critical warning when too many missing are found (>50%),\n",
    "7. Verify that number of available data is greater then minimum required (Error)\n",
    "\n",
    "Critical warnings have different levels of disclosure to the researcher (1) only the warning, 2) type of warning, 3) type of warning and column affected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aeb287",
   "metadata": {},
   "source": [
    "# 1. What is a `data_format_ref` file\n",
    "\n",
    "\n",
    "A `data_format_ref_file` is a JSON file containing all the skeleton of the data. \n",
    "It should be created by a clinician and sent to nodes, in order to check nodes dataset integrity.\n",
    "In case there is a mismatch between nodes dataset and `data_format_ref_file` \n",
    "\n",
    "Structure of a `data_format_file_ref`:\n",
    "\n",
    "\n",
    "\n",
    "# 2. Creating a `data_format_ref` file using an existing dataset\n",
    "\n",
    "In this notebook, we provide a way to create `data_fromat_ref_file` using an existing dataset. \n",
    "Then, user can edit it (ie change `data_format_file_ref` file, and complete information already contained into the file)\n",
    "\n",
    "## 2.1 Loading tabular dataset\n",
    "\n",
    "For that, we provide a `load_tabular_datasets` function able to load every kind of tabular dataset `*.csv`, `.xls`, folder of `*.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c51343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.data_tool.utils import load_tabular_datasets, save_format_file_ref\n",
    "from fedbiomed.common.data_tool.data_format_ref_cli import get_from_user_multi_view_dataset_fromat_file, edit_format_file_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9e63f",
   "metadata": {},
   "source": [
    "**load_tabular_datasets** method can export several files type (excel file, csv file, and folder containing csv files) \n",
    "\n",
    "## Caution! all data are stored in a folder named `/data/` in `fedbiomed/notebooks` \n",
    "\n",
    "### 2.1.1 Export Excel File\n",
    "\n",
    "You can export Excel files as shown in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl #(for opening excel files)\n",
    "!pip install aenum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6750dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found\n",
      "err 'utf-8' codec can't decode byte 0x8c in position 15: invalid start byte in file ./data/excel/Exceltest.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Exceltest.xlsx':    ID   Age Eligibility\n",
       " 0    1   45           Y\n",
       " 1    2   45           Y\n",
       " 2    3   33           N\n",
       " 3    4   54           Y\n",
       " 4    5   45           Y\n",
       " 5    6   54         NaN\n",
       " 6    7   34           N\n",
       " 7    8   54         NaN\n",
       " 8    9   45         NaN\n",
       " 9   10   44           Y}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can load excel files\n",
    "load_tabular_datasets(r'./data/excel/Exceltest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6f2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found\n",
      "err 'utf-8' codec can't decode byte 0x87 in position 11: invalid start byte in file ./data/excel/test_excel.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_excel.xlsx':      a  b     val\n",
       " 0    1  a  10.000\n",
       " 1    2  b   3.000\n",
       " 2    3  c   3.900\n",
       " 3    4  d   8.000\n",
       " 4    5  a   9.009\n",
       " 5    6  b  11.000\n",
       " 6    7  c   4.000\n",
       " 7    8  d   4.900\n",
       " 8    9  a   9.000\n",
       " 9   10  b  10.009\n",
       " 10  11  c  12.000\n",
       " 11  12  d   5.000\n",
       " 12  13  a   5.900\n",
       " 13  14  b  10.000\n",
       " 14  15  c  11.009\n",
       " 15  16  d  13.000\n",
       " 16  17  a   6.000\n",
       " 17  18  b   6.900\n",
       " 18  19  c  11.000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_tabular_datasets(r'./data/excel/test_excel.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f3d3e",
   "metadata": {},
   "source": [
    "### 2.1.2 Export CSV file\n",
    "\n",
    "\n",
    "It is a modified version of `pseudo_adni_mod` csv dataset with the first column (`CDRSB.bl`) being converted into a column of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470a1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found\n"
     ]
    }
   ],
   "source": [
    "# simple csv dataset\n",
    "pseudo_adni = load_tabular_datasets(r'data/pseudo_adni/pseudo_adni_mod_2.csv')\n",
    "#single_view_dataset = load_tabular_datasets(r'/user/ybouilla/home/Documents/data/pseudo_adni_mod/pseudo_adni_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2107a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "448e80b5",
   "metadata": {},
   "source": [
    "### 2.1.3 Export a folder containing csv files\n",
    "\n",
    "for loading a folder (multi view dataset, one has to load the path of the directory (instead of a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4fb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/csv_folder\u001b[0m\r\n",
      "├── contatct\r\n",
      "├── file1\r\n",
      "└── file2\r\n",
      "\r\n",
      "0 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree data/csv_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed673dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory found\n"
     ]
    }
   ],
   "source": [
    "# folder of dataset\n",
    "multi_view_dataframe =  load_tabular_datasets('data/csv_folder')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81839f87",
   "metadata": {},
   "source": [
    "## 2.2 create the `data_format_ref` file from the loaded dataset\n",
    "\n",
    "Let's assume the loaded dataset is a reference dataset, and we want to create from this  dataset a `data_format_ref`. \n",
    "\n",
    "\n",
    "### workflow logic:\n",
    "\n",
    "```\n",
    "for each view:\n",
    "    for each feature whithin view:\n",
    "        ask user to select one type within all type present in `Enum` class `DataType` (if user wants to add this feature inside`data_format_ref`)\n",
    "        ask user to indicate if variable can have missing data or not\n",
    "        ask user to indicate which data imputation method he wants to select\n",
    "        (imputation methods are given from the one specified in `Enum` class `ImputationMethods`\n",
    "        \n",
    "```\n",
    "\n",
    "**Default DataType**:\n",
    "\n",
    "1) KEY \n",
    "2) QUANTITATIVE \n",
    "3) CATEGORICAL \n",
    "4) DATETIME \n",
    "5) UNKNOWN (when user doesnot want to specify a variable type)\n",
    "\n",
    "\n",
    "**Data Imputation Methods**\n",
    "\n",
    "1) MEAN_IMPUTATION\n",
    "2) MODE_IMPUTATION\n",
    "3) KNN_IMPUTATION\n",
    "4) LINEAR_INTERPOLATION_IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data_format_file_test = get_from_user_multi_view_dataset_fromat_file(pseudo_adni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6b057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': None, 'min_nb_missing_samples': None},\n",
       " 'pseudo_adni_mod_2.csv': {'CDRSB.bl': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': \"<class 'str'>\",\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_data_format_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6380f157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++ Editing Global Thresholds +++++++++++\n",
      "Do you want to add a threshold for the minimum number of samples each dataset should contain?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Do you want to add a threshold for the minimum number of missing data each feature should contain?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++ Now parsing view: file1 +++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "displaying first 10 values of feature a in view: file1 (n_feature: 1/18)\n",
      "0    48\n",
      "1    87\n",
      "2    46\n",
      "3    84\n",
      "4    94\n",
      "5    18\n",
      "6    15\n",
      "7    30\n",
      "8    54\n",
      "9    46\n",
      "Name: a, dtype: int64\n",
      "number of differents samples: 57 / total of samples: 100\n",
      "specify data type for a:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "2\n",
      "data_type DataType.QUANTITATIVE QUANTITATIVE\n",
      "CATEGORICAL QUANTITATIVE\n",
      "found  <class 'int'>\n",
      "found  <class 'numpy.int64'>\n",
      "int64 <class 'numpy.int64'> [dtype('int64')]\n",
      "Allow a to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature e in view: file1 (n_feature: 2/18)\n",
      "0    98\n",
      "1    83\n",
      "2    73\n",
      "3    45\n",
      "4    84\n",
      "5     5\n",
      "6    44\n",
      "7    55\n",
      "8    37\n",
      "9     8\n",
      "Name: e, dtype: int64\n",
      "number of differents samples: 65 / total of samples: 100\n",
      "specify data type for e:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature e\n",
      "displaying first 10 values of feature i in view: file1 (n_feature: 3/18)\n",
      "0    65\n",
      "1    13\n",
      "2    81\n",
      "3    81\n",
      "4     0\n",
      "5    57\n",
      "6    14\n",
      "7    98\n",
      "8    13\n",
      "9    89\n",
      "Name: i, dtype: int64\n",
      "number of differents samples: 61 / total of samples: 100\n",
      "specify data type for i:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature i\n",
      "displaying first 10 values of feature o in view: file1 (n_feature: 4/18)\n",
      "0     5\n",
      "1    70\n",
      "2    96\n",
      "3    39\n",
      "4    15\n",
      "5    28\n",
      "6    29\n",
      "7    82\n",
      "8    19\n",
      "9    21\n",
      "Name: o, dtype: int64\n",
      "number of differents samples: 61 / total of samples: 100\n",
      "specify data type for o:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature o\n",
      "displaying first 10 values of feature 0 in view: file1 (n_feature: 5/18)\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7     True\n",
      "8     True\n",
      "9    False\n",
      "Name: 0, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 0:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 0\n",
      "displaying first 10 values of feature 1 in view: file1 (n_feature: 6/18)\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "6    False\n",
      "7     True\n",
      "8     True\n",
      "9     True\n",
      "Name: 1, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 1\n",
      "displaying first 10 values of feature 2 in view: file1 (n_feature: 7/18)\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: 2, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 2:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 2\n",
      "displaying first 10 values of feature 3 in view: file1 (n_feature: 8/18)\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: 3, dtype: bool\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for 3:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature 3\n",
      "displaying first 10 values of feature time in view: file1 (n_feature: 9/18)\n",
      "0    2018-01-01 00:00:00\n",
      "1    2018-01-01 01:00:00\n",
      "2    2018-01-01 02:00:00\n",
      "3    2018-01-01 03:00:00\n",
      "4    2018-01-01 04:00:00\n",
      "5    2018-01-01 05:00:00\n",
      "6    2018-01-01 06:00:00\n",
      "7    2018-01-01 07:00:00\n",
      "8    2018-01-01 08:00:00\n",
      "9    2018-01-01 09:00:00\n",
      "Name: time, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for time:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature time\n",
      "displaying first 10 values of feature pressure in view: file1 (n_feature: 10/18)\n",
      "0    0.088082\n",
      "1    0.774788\n",
      "2    0.514092\n",
      "3    0.832881\n",
      "4    0.696152\n",
      "5    0.166896\n",
      "6    0.740141\n",
      "7    0.067837\n",
      "8    0.342615\n",
      "9    0.777026\n",
      "Name: pressure, dtype: float64\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for pressure:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature pressure\n",
      "displaying first 10 values of feature sp02 in view: file1 (n_feature: 11/18)\n",
      "0    0.360430\n",
      "1    0.072426\n",
      "2    0.538551\n",
      "3    0.761962\n",
      "4    0.389385\n",
      "5    0.200984\n",
      "6    0.765184\n",
      "7    0.258049\n",
      "8    0.736926\n",
      "9    0.253232\n",
      "Name: sp02, dtype: float64\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for sp02:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature sp02\n",
      "displaying first 10 values of feature a.1 in view: file1 (n_feature: 12/18)\n",
      "0    90\n",
      "1    15\n",
      "2    30\n",
      "3    42\n",
      "4    65\n",
      "5    21\n",
      "6    60\n",
      "7     0\n",
      "8    33\n",
      "9    64\n",
      "Name: a.1, dtype: int64\n",
      "number of differents samples: 62 / total of samples: 100\n",
      "specify data type for a.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature a.1\n",
      "displaying first 10 values of feature e.1 in view: file1 (n_feature: 13/18)\n",
      "0    63\n",
      "1    20\n",
      "2     2\n",
      "3    70\n",
      "4    90\n",
      "5    94\n",
      "6    33\n",
      "7    94\n",
      "8    71\n",
      "9    65\n",
      "Name: e.1, dtype: int64\n",
      "number of differents samples: 61 / total of samples: 100\n",
      "specify data type for e.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature e.1\n",
      "displaying first 10 values of feature i.1 in view: file1 (n_feature: 14/18)\n",
      "0    60\n",
      "1    45\n",
      "2     6\n",
      "3     7\n",
      "4    12\n",
      "5    77\n",
      "6    75\n",
      "7    50\n",
      "8    94\n",
      "9    15\n",
      "Name: i.1, dtype: int64\n",
      "number of differents samples: 67 / total of samples: 100\n",
      "specify data type for i.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature i.1\n",
      "displaying first 10 values of feature o.1 in view: file1 (n_feature: 15/18)\n",
      "0     8\n",
      "1    10\n",
      "2    22\n",
      "3    79\n",
      "4    90\n",
      "5     2\n",
      "6    85\n",
      "7    64\n",
      "8    47\n",
      "9    30\n",
      "Name: o.1, dtype: int64\n",
      "number of differents samples: 69 / total of samples: 100\n",
      "specify data type for o.1:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "7\n",
      "Ignoring feature o.1\n",
      "displaying first 10 values of feature gender in view: file1 (n_feature: 16/18)\n",
      "0      MAN\n",
      "1      MAN\n",
      "2    WOMAN\n",
      "3    WOMAN\n",
      "4      MAN\n",
      "5      MAN\n",
      "6    WOMAN\n",
      "7    WOMAN\n",
      "8    WOMAN\n",
      "9      MAN\n",
      "Name: gender, dtype: object\n",
      "number of differents samples: 2 / total of samples: 100\n",
      "specify data type for gender:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "Allow gender to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature blood type in view: file1 (n_feature: 17/18)\n",
      "0      A\n",
      "1      O\n",
      "2      A\n",
      "3     AB\n",
      "4      B\n",
      "5     AB\n",
      "6      O\n",
      "7      B\n",
      "8    NaN\n",
      "9      A\n",
      "Name: blood type, dtype: object\n",
      "number of differents samples: 5 / total of samples: 100\n",
      "specify data type for blood type:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "3\n",
      "data_type DataType.CATEGORICAL CATEGORICAL\n",
      "CATEGORICAL CATEGORICAL\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "Allow blood type to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MODE_IMPUTATION\n",
      "2) KNN_IMPUTATION\n",
      "3) No method\n",
      " d_type <class 'str'>\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MODE_IMPUTATION\n",
      "2) KNN_IMPUTATION\n",
      "3) No method\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method imputation selected: KNN_IMPUTATION\n",
      "\n",
      "please specify k value:\n",
      "4\n",
      "imput param {'k': '4'}\n",
      "get msg []\n",
      "get msg (selected) []\n",
      "Please select view that contained desired feature:\n",
      "1) file1 \n",
      "2) contatct \n",
      "3) file2 \n",
      "4) select all views\n",
      "4\n",
      "end ['file1', 'contatct', 'file2'] False False\n",
      "get msg ['file1', 'contatct', 'file2']\n",
      "get msg (selected) ['file1', 'contatct', 'file2']\n",
      "Please select view that contained desired feature:\n",
      "1) file1 (selected)\n",
      "2) contatct (selected)\n",
      "3) file2 (selected)\n",
      "4) select all views\n",
      "5) Finish feature selection\n",
      "5\n",
      "Do you want to add more variable to apply to data imputation method ?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "displaying first 10 values of feature pkey in view: file1 (n_feature: 18/18)\n",
      "0    zmixzrgvxrjqxoe sluk\n",
      "1    vrzahnpfluspdcbfnaqt\n",
      "2    pnrepvmrxqabdlvisclv\n",
      "3    gwj luzejwdxzsiljxzd\n",
      "4    jjdvcnofivbqhirxzdyo\n",
      "5    e fshtkhnlimpczypnoe\n",
      "6    qe nlikallf znokwdhk\n",
      "7    kgenxxkftoeqtrnoteaq\n",
      "8    abghippigyxzaxtejumu\n",
      "9    ezfasuuycdda foisjte\n",
      "Name: pkey, dtype: object\n",
      "number of differents samples: 100 / total of samples: 100\n",
      "specify data type for pkey:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) ignore this column\n",
      "1\n",
      "data_type DataType.KEY KEY\n",
      "CATEGORICAL KEY\n",
      "Datetime ambiguity: Please specify if variable pkey is a date or not\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "found  <class 'str'>\n",
      "<class 'str'> <class 'str'> [<class 'str'>]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++ Now parsing view: contatct +++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "displaying first 10 values of feature discrete in view: contatct (n_feature: 1/3)\n",
      "0    64.0\n",
      "1    26.0\n",
      "2    61.0\n",
      "3    29.0\n",
      "4    99.0\n",
      "5     5.0\n",
      "6    71.0\n",
      "7    99.0\n",
      "8    90.0\n",
      "9    36.0\n",
      "Name: discrete, dtype: float64\n",
      "number of differents samples: 70 / total of samples: 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8996/3598209826.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmulti_data_format_file_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_from_user_multi_view_dataset_fromat_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_view_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ybouilla/fedbiomed/fedbiomed/common/data_tool/data_format_ref_cli.py\u001b[0m in \u001b[0;36mget_from_user_multi_view_dataset_fromat_file\u001b[0;34m(datasets)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"+++++++ Now parsing view: {tabular_data_file} +++++++\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         data_format_file = get_from_user_dataframe_format_file(datasets[tabular_data_file],\n\u001b[0m\u001b[1;32m    429\u001b[0m                                                                \u001b[0mtabular_data_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                                                view_feature_name)\n",
      "\u001b[0;32m/home/ybouilla/fedbiomed/fedbiomed/common/data_tool/data_format_ref_cli.py\u001b[0m in \u001b[0;36mget_from_user_dataframe_format_file\u001b[0;34m(dataset, view, view_feature_names)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# ask user about data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         data_format_id = get_user_input(msg_data_type_selection,\n\u001b[0m\u001b[1;32m    313\u001b[0m                                         n_answers=ignoring_id)\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ybouilla/fedbiomed/fedbiomed/common/data_tool/data_format_ref_cli.py\u001b[0m in \u001b[0;36mget_user_input\u001b[0;34m(msg, n_answers)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_column_parsed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_answers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# check if value passed by user is correct (if it is integer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "multi_data_format_file_test = get_from_user_multi_view_dataset_fromat_file(multi_view_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1268c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': None, 'min_nb_missing_samples': None},\n",
       " 'file1': {'a': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': \"<class 'numpy.datetime64'>\",\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'e': {'data_format': 'KEY',\n",
       "   'data_type': 'NUMERICAL',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': \"<class 'numpy.datetime64'>\",\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_data_format_file_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d533e99",
   "metadata": {},
   "source": [
    "Data format file to be filled by clinicians (step 2 int he workflow):\n",
    "\n",
    "Data format file will be a dictionary specifying the type: \n",
    "\n",
    "\n",
    "```\n",
    "{<view_name>: {<feature_name>: {'data_format' : <data_fomat>,\n",
    "                                   'data_type': <data_type>,\n",
    "                                   'type':<values_taken>,\n",
    "                                   'is_missing_values': <True/False>,\n",
    "                                   'data_imputation_method': <name_of_dta_imputation_method> ,\n",
    "                                   'data_imputation_parameters': <parameter_of_iputation_method>,\n",
    "                                   'lower_bound': <float>,\n",
    "                                   'upper_bound': <float>,\n",
    "                                   'categorical_value': <List[values]>}\n",
    "                                   }\n",
    "                   }\n",
    "    }\n",
    "```\n",
    "\n",
    "where\n",
    "* `<view_name>` is the name of the view\n",
    "* `<feature_name>` is the name of the feature\n",
    "* `<data_type>` can be categorical or continuous or missing_data or datetime\n",
    "* `<value_taken>` is the type of the value (eg int, str, float, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee23c1",
   "metadata": {},
   "source": [
    "Saving `format_file_ref` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a2e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Format Ref File successfully saved at single_format_file_ref_test2\n"
     ]
    }
   ],
   "source": [
    "save_format_file_ref(single_data_format_file_test, 'single_format_file_ref_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aaac0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Reference File successfully saved at int_multi_view_format_test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_format_file_ref(multi_data_format_file_test, 'int_multi_view_format_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b173a3",
   "metadata": {},
   "source": [
    "## 2.3 edit   `data_format_ref` file from an existing  `data_format_ref` file\n",
    "\n",
    "CLI `edit_format_file_ref` allows to specify additional information for checking, including:\n",
    " - lower and upper bounds\n",
    " - catgorical_value (eg MALE, FEMALE)\n",
    " - data_type (not inferred anymore)\n",
    " - data imputation method (not inferred anymore)\n",
    " - date format (DO NOT WORK YET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369dd636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now editing format file ref\n",
      "Edit file: pseudo_adni_mod_2.csv?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Edit variable: CDRSB.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "2\n",
      "action 2 4 {'1': <function ask_for_data_type at 0x7fc559190a60>, '2': <function ask_for_categorical_values at 0x7fc559190b80>, '3': <function ask_for_data_imputation_method at 0x7fc559190af0>, '4': <function cancel_operation at 0x7fc559190820>}\n",
      "enter possible values (separated by \",\")a,b,c,d,e,f,g,h,i,j,k\n",
      "Continue Editing variable: CDRSB.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: ADAS11.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "2\n",
      "action 2 5 {'1': <function ask_for_data_type at 0x7fc559190a60>, '2': <function ask_for_lower_bound at 0x7fc5591908b0>, '3': <function ask_for_upper_bound at 0x7fc559190940>, '4': <function ask_for_data_imputation_method at 0x7fc559190af0>, '5': <function cancel_operation at 0x7fc559190820>}\n",
      "enter lower bound0\n",
      "Continue Editing variable: ADAS11.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "10\n",
      "error ! 10 value not understood\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "3\n",
      "action 3 5 {'1': <function ask_for_data_type at 0x7fc559190a60>, '2': <function ask_for_lower_bound at 0x7fc5591908b0>, '3': <function ask_for_upper_bound at 0x7fc559190940>, '4': <function ask_for_data_imputation_method at 0x7fc559190af0>, '5': <function cancel_operation at 0x7fc559190820>}\n",
      "enter upper bound10\n",
      "Continue Editing variable: ADAS11.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: MMSE.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "3\n",
      "action 3 4 {'1': <function ask_for_data_type at 0x7fc559190a60>, '2': <function ask_for_categorical_values at 0x7fc559190b80>, '3': <function ask_for_data_imputation_method at 0x7fc559190af0>, '4': <function cancel_operation at 0x7fc559190820>}\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      " d_type None\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      "4\n",
      "get msg []\n",
      "get msg (selected) []\n",
      "Please select view that contained desired feature:\n",
      "1) pseudo_adni_mod_2.csv \n",
      "2) select all views\n",
      "1\n",
      "Please select a feature in pseudo_adni_mod_2.csv\n",
      "get msg (selected) []\n",
      "Please select feature from view : pseudo_adni_mod_2.csv\n",
      "1) CDRSB.bl \n",
      "2) ADAS11.bl \n",
      "3) MMSE.bl \n",
      "4) RAVLT.immediate.bl \n",
      "5) RAVLT.learning.bl \n",
      "6) RAVLT.forgetting.bl \n",
      "7) Ventricles.bl \n",
      "8) Hippocampus.bl \n",
      "9) ABETA.MEDIAN.bl \n",
      "10) PTAU.MEDIAN.bl \n",
      "11) AGE \n",
      "12) select all features\n",
      "13) return to view\n",
      "12\n",
      "end [] False False\n",
      "get msg []\n",
      "get msg (selected) []\n",
      "Please select view that contained desired feature:\n",
      "1) pseudo_adni_mod_2.csv \n",
      "2) select all views\n",
      "3) Finish feature selection\n",
      "3\n",
      "Do you want to add more variable to apply to data imputation method ?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Continue Editing variable: MMSE.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: RAVLT.immediate.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "4\n",
      "action 4 5 {'1': <function ask_for_data_type at 0x7fc559190a60>, '2': <function ask_for_lower_bound at 0x7fc5591908b0>, '3': <function ask_for_upper_bound at 0x7fc559190940>, '4': <function ask_for_data_imputation_method at 0x7fc559190af0>, '5': <function cancel_operation at 0x7fc559190820>}\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      " d_type None\n",
      "Please select the following method for filling missing values (if some are found)\n",
      "1) MEAN_IMPUTATION\n",
      "2) MODE_IMPUTATION\n",
      "3) KNN_IMPUTATION\n",
      "4) LINEAR_INTERPOLATION_IMPUTATION\n",
      "5) No method\n",
      "5\n",
      "Continue Editing variable: RAVLT.immediate.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "3\n",
      "action 3 5 {'1': <function ask_for_data_type at 0x7fc559190a60>, '2': <function ask_for_lower_bound at 0x7fc5591908b0>, '3': <function ask_for_upper_bound at 0x7fc559190940>, '4': <function ask_for_data_imputation_method at 0x7fc559190af0>, '5': <function cancel_operation at 0x7fc559190820>}\n",
      "enter upper bound-1\n",
      "Continue Editing variable: RAVLT.immediate.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: RAVLT.learning.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: RAVLT.forgetting.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: Ventricles.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: Hippocampus.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: ABETA.MEDIAN.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: PTAU.MEDIAN.bl?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: AGE?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.common.data_tool.data_format_ref_cli import edit_format_file_ref\n",
    "from  fedbiomed.common.data_tool import utils\n",
    "\n",
    "single_data_format_file_test = edit_format_file_ref(single_data_format_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843461ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a064594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Format Ref File successfully saved at single_format_file_ref_test3\n"
     ]
    }
   ],
   "source": [
    "save_format_file_ref(single_data_format_file_test, 'single_format_file_ref_test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afd4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++ Now editing format file ref ++++++++++\n",
      "Edit file: file1?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Edit variable: a?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: e?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: i?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Data Value imputation method\n",
      "3) Cancel Operation\n",
      "1\n",
      "action 1 3 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '3': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) CUSTOM \n",
      "6) UNKNOWN \n",
      "7) cancel operation\n",
      "6\n",
      "Continue Editing variable: i?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: 0?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "2\n",
      "action 2 4 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_categorical_values at 0x7f316c3cfe50>, '3': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '4': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter possible values (separated by \",\")False, True\n",
      "Continue Editing variable: 0?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "2\n",
      "action 2 4 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_categorical_values at 0x7f316c3cfe50>, '3': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '4': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter possible values (separated by \",\")False,True\n",
      "Continue Editing variable: 0?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: 1?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "4\n",
      "action 4 4 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_categorical_values at 0x7f316c3cfe50>, '3': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '4': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "Edit variable: time?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: pressure?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "2\n",
      "action 2 5 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_lower_bound at 0x7f316c3cfb80>, '3': <function ask_for_upper_bound at 0x7f316c3cfc10>, '4': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '5': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter lower bound10\n",
      "Continue Editing variable: pressure?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: sp02?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) lower bound\n",
      "3)upper bound\n",
      "4) Data Value imputation method\n",
      "5) Cancel Operation\n",
      "3\n",
      "action 3 5 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_lower_bound at 0x7f316c3cfb80>, '3': <function ask_for_upper_bound at 0x7f316c3cfc10>, '4': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '5': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter upper bound0\n",
      "Continue Editing variable: sp02?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: a.1?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: gender?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "2\n",
      "action 2 4 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_categorical_values at 0x7f316c3cfe50>, '3': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '4': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter possible values (separated by \",\")WOMAN,MAN\n",
      "Continue Editing variable: gender?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: blood type?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "2\n",
      "action 2 4 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_categorical_values at 0x7f316c3cfe50>, '3': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '4': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter possible values (separated by \",\")A, B, AB\n",
      "Continue Editing variable: blood type?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "Which field should be modified?\n",
      "1) data_type\n",
      "2) Values taken\n",
      "3) Data Value imputation method\n",
      "4) Cancel Operation\n",
      "2\n",
      "action 2 4 {'1': <function ask_for_data_type at 0x7f316c3cfd30>, '2': <function ask_for_categorical_values at 0x7f316c3cfe50>, '3': <function ask_for_data_imputation_method at 0x7f316c3cfdc0>, '4': <function cancel_operation at 0x7f316c3cfaf0>}\n",
      "enter possible values (separated by \",\")A,B,AB\n",
      "Continue Editing variable: blood type?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit variable: pkey?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit file: contatct?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "Edit file: file2?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.common.data_tool.data_format_ref_cli import get_from_user_multi_view_dataset_fromat_file, edit_format_file_ref\n",
    "from  fedbiomed.common.data_tool import utils\n",
    "\n",
    "multi_data_format_file_test = utils.load_format_file_ref('int_multi_view_format_test')\n",
    "\n",
    "edit_multi_view_format_file_test = edit_format_file_ref(multi_data_format_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4376757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Reference File successfully saved at edit_multi_view_format_file_test3\n"
     ]
    }
   ],
   "source": [
    "save_format_file_ref(edit_multi_view_format_file_test, 'edit_multi_view_format_file_test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9aac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_thresholds': {'min_nb_samples': 40, 'min_nb_missing_samples': 20},\n",
       " 'file1': {'a': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'LINEAR_INTERPOLATION_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': {'file1': ['e',\n",
       "     'i',\n",
       "     'o',\n",
       "     '0',\n",
       "     '1',\n",
       "     '2',\n",
       "     '3',\n",
       "     'time',\n",
       "     'pressure',\n",
       "     'sp02',\n",
       "     'a.1',\n",
       "     'e.1',\n",
       "     'i.1',\n",
       "     'o.1',\n",
       "     'gender',\n",
       "     'blood type',\n",
       "     'pkey'],\n",
       "    'contatct': [],\n",
       "    'file2': []}},\n",
       "  'e': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'i': {'data_format': 'UNKNOWN',\n",
       "   'data_type': 'UNKNOWN',\n",
       "   'values': ['U', 'N', 'K', 'N', 'O', 'W', 'N'],\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  '0': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': 'bool',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'KNN_IMPUTATION',\n",
       "   'data_imputation_parameters': {'k': '5'},\n",
       "   'data_imputation_variables': {'file1': [],\n",
       "    'contatct': ['discrete', 'city', 'pkey'],\n",
       "    'file2': []},\n",
       "   'categorical_values': ['False', 'True']},\n",
       "  '1': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': 'bool',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pressure': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'lower_bound': 10.0},\n",
       "  'sp02': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'MEAN_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'upper_bound': 0.0},\n",
       "  'a.1': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'DISCRETE',\n",
       "   'values': 'int64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'gender': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'MODE_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'categorical_values': ['WOMAN', 'MAN']},\n",
       "  'blood type': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None,\n",
       "   'categorical_values': ['A', 'B', 'AB']},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}},\n",
       " 'contatct': {'discrete': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'city': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'CHARACTER',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}},\n",
       " 'file2': {'2': {'data_format': 'CATEGORICAL',\n",
       "   'data_type': 'BOOLEAN',\n",
       "   'values': 'bool',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'MODE_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'time': {'data_format': 'DATETIME',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None},\n",
       "  'pH': {'data_format': 'QUANTITATIVE',\n",
       "   'data_type': 'CONTINUOUS',\n",
       "   'values': 'float64',\n",
       "   'is_missing_values': True,\n",
       "   'data_imputation_method': 'LINEAR_INTERPOLATION_IMPUTATION',\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': {'file1': ['e',\n",
       "     'i',\n",
       "     'o',\n",
       "     '0',\n",
       "     '1',\n",
       "     '2',\n",
       "     '3',\n",
       "     'time',\n",
       "     'pressure',\n",
       "     'sp02',\n",
       "     'a.1',\n",
       "     'e.1',\n",
       "     'i.1',\n",
       "     'o.1',\n",
       "     'gender',\n",
       "     'blood type',\n",
       "     'pkey'],\n",
       "    'contatct': ['discrete', 'city', 'pkey'],\n",
       "    'file2': []}},\n",
       "  'pkey': {'data_format': 'KEY',\n",
       "   'data_type': 'DATETIME',\n",
       "   'values': 'object',\n",
       "   'is_missing_values': False,\n",
       "   'data_imputation_method': None,\n",
       "   'data_imputation_parameters': None,\n",
       "   'data_imputation_variables': None}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_multi_view_format_file_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955447d2",
   "metadata": {},
   "source": [
    "## 2.4 create custom DataType\n",
    "\n",
    "This may be re work because depends on a third party package `aenum`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
