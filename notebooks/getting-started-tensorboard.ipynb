{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the client up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the client\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Connected with result code 0`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import TMP_DIR\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=TMP_DIR+'/')\n",
    "model_file = tmp_dir_model.name + '/class_export_mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : write **only** the code to export in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/scansiz/Desktop/Inria/development/fedbiomed/var/tmp/tmpkcye708v/class_export_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "               \"from torch.utils.data import DataLoader\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the client side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the client side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of client ID with `clients`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `client_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-08 14:28:33,698 fedbiomed INFO - Searching for clients with data tags: ['#MNIST', '#dataset']\n",
      "2021-10-08 14:28:33,702 fedbiomed INFO - message received:{'researcher_id': 'researcher_110678ac-6a6d-4c79-83c6-4d12b7d826f5', 'success': True, 'databases': [{'name': 'MNIST', 'data_type': 'default', 'tags': ['#MNIST', '#dataset'], 'description': 'MNIST database', 'shape': [60000, 1, 28, 28], 'dataset_id': 'dataset_62923c06-71fa-4ae8-9da8-006c15ca8282'}], 'count': 1, 'client_id': 'client_d229b7f8-bae0-451b-9be1-647f2de8b5da', 'command': 'search'}\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 1\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #clients=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='MyTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 client_selection_strategy=None,\n",
    "                 tensorboard=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start tensorboard to see loss value after every iteration during training. It is normal to see empty screen. After you run the experiment you will be able to see the changes on the dashboard. Notebook will refresh results in every 30 seconds. You can also click refresh button to see current training steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fc6e29b63ddf331c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fc6e29b63ddf331c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir '../runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-08 14:28:56,081 fedbiomed INFO - Sampled clients in round 0 ['client_d229b7f8-bae0-451b-9be1-647f2de8b5da']\n",
      "2021-10-08 14:28:56,081 fedbiomed INFO - Send message to client client_d229b7f8-bae0-451b-9be1-647f2de8b5da - {'researcher_id': 'researcher_110678ac-6a6d-4c79-83c6-4d12b7d826f5', 'job_id': 'bc22ff57-c522-40fe-9ded-8037c34d6ad9', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 2, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/10/08/my_model_0348aabb-ca59-4e22-b233-7d99665ce670.py', 'params_url': 'http://localhost:8844/media/uploads/2021/10/08/my_model_5a3ee78b-781f-4a01-a2fb-3460c266889b.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_d229b7f8-bae0-451b-9be1-647f2de8b5da': ['dataset_62923c06-71fa-4ae8-9da8-006c15ca8282']}}\n",
      "2021-10-08 14:28:56,082 fedbiomed DEBUG - researcher_110678ac-6a6d-4c79-83c6-4d12b7d826f5\n",
      "2021-10-08 14:28:56,245 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 0 ]\tLoss: 2.306286\n",
      "2021-10-08 14:28:56,766 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 10 ]\tLoss: 1.457766\n",
      "2021-10-08 14:28:57,536 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 20 ]\tLoss: 0.986098\n",
      "2021-10-08 14:28:58,651 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 30 ]\tLoss: 0.693920\n",
      "2021-10-08 14:28:59,299 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 40 ]\tLoss: 0.501207\n",
      "2021-10-08 14:28:59,833 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 50 ]\tLoss: 0.577433\n",
      "2021-10-08 14:29:01,001 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 60 ]\tLoss: 0.620278\n",
      "2021-10-08 14:29:01,916 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 70 ]\tLoss: 0.327419\n",
      "2021-10-08 14:29:02,620 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 80 ]\tLoss: 0.534947\n",
      "2021-10-08 14:29:03,090 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 1 [Batch 90 ]\tLoss: 0.419489\n",
      "2021-10-08 14:29:03,982 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 0 ]\tLoss: 0.326860\n",
      "2021-10-08 14:29:04,474 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 10 ]\tLoss: 0.338537\n",
      "2021-10-08 14:29:05,321 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 20 ]\tLoss: 0.213492\n",
      "2021-10-08 14:29:06,014 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 30 ]\tLoss: 0.369424\n",
      "2021-10-08 14:29:06,642 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 40 ]\tLoss: 0.474431\n",
      "2021-10-08 14:29:07,309 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 50 ]\tLoss: 0.188560\n",
      "2021-10-08 14:29:07,794 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 60 ]\tLoss: 0.154417\n",
      "2021-10-08 14:29:08,454 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 70 ]\tLoss: 0.391946\n",
      "2021-10-08 14:29:09,087 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 80 ]\tLoss: 0.220382\n",
      "2021-10-08 14:29:09,582 fedbiomed INFO - Round: 0 Node: client_d229b7f8-bae0-451b-9be1-647f2de8b5da - Train Epoch: 2 [Batch 90 ]\tLoss: 0.146511\n",
      "2021-10-08 14:29:10,762 fedbiomed INFO - message received:{'researcher_id': 'researcher_110678ac-6a6d-4c79-83c6-4d12b7d826f5', 'job_id': 'bc22ff57-c522-40fe-9ded-8037c34d6ad9', 'success': True, 'client_id': 'client_d229b7f8-bae0-451b-9be1-647f2de8b5da', 'dataset_id': 'dataset_62923c06-71fa-4ae8-9da8-006c15ca8282', 'params_url': 'http://localhost:8844/media/uploads/2021/10/08/node_params_ff122a0f-ff39-4c22-8ad8-3656cea77775.pt', 'timing': {'rtime_training': 14.43053224599862, 'ptime_training': 56.890792345999984}, 'msg': '', 'command': 'train'}\n",
      "2021-10-08 14:29:16,105 fedbiomed INFO - Downloading model params after training on client_d229b7f8-bae0-451b-9be1-647f2de8b5da - from http://localhost:8844/media/uploads/2021/10/08/node_params_ff122a0f-ff39-4c22-8ad8-3656cea77775.pt\n",
      "2021-10-08 14:29:16,139 fedbiomed INFO - Clients that successfully reply in round 0 ['client_d229b7f8-bae0-451b-9be1-647f2de8b5da']\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display current values please click refresh button on the TensorBoard screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available in `exp.training_replies` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies.keys())\n",
    "\n",
    "print(\"\\nList the clients for the last training round and their timings : \")\n",
    "round_data = exp.training_replies[rounds - 1].data\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['client_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies[rounds - 1].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available in `exp.aggregated_params` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params.keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params[rounds - 1]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional : searching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "\n",
    "r = Requests()\n",
    "data = r.search(tags)\n",
    "\n",
    "import pandas as pd\n",
    "for client_id in data.keys():\n",
    "    print('\\n','Data for ', client_id, '\\n\\n', pd.DataFrame(data[client_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optional : clean file repository (do not run unless necessary)\n",
    "Clean all the files in the repo via the rest API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from fedbiomed.researcher.environ import UPLOADS_URL\n",
    "\n",
    "# uploaded_models = requests.get(UPLOADS_URL).json()\n",
    "# for m in uploaded_models:\n",
    "#   requests.delete(m['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Feel free to try your own models :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
