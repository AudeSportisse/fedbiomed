{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Differential Privacy with OPACUS on Fed-BioMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how `opacus` (https://opacus.ai/) can be used in Fed-BioMed. Opacus is a library which allows to train PyTorch models with differential privacy. We will train the basic MNIST example using two nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Fed-BioMed Environment\n",
    "\n",
    "### Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default)\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model and parameters\n",
    "\n",
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we are going to define the model using opacus for differential privacy. For this example, we are going to use the function `make_private` from `opacus.privacy_engine`. Two hyperparameters should be defined:\n",
    "* `noise_multiplier`: The ratio of the standard deviation of the Gaussian noise to the L2-sensitivity of the function to which the noise is added (How much noise to add)\n",
    "* `max_grad_norm`: The maximum norm of the per-sample gradients. Any gradient with norm higher than this will be clipped to this value.\n",
    "\n",
    "It is worth noting that in order to use the opacus `PrivacyEngine` class we need to properly define as training plan attributes a `model`, a `dataloader` and an `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 14:51:31,828 fedbiomed INFO - Component environment:\n",
      "2022-03-31 14:51:31,829 fedbiomed INFO - type = ComponentType.RESEARCHER\n",
      "2022-03-31 14:51:32,405 fedbiomed INFO - Messaging researcher_2a29744e-4430-4e85-9661-1c02afbdd825 successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x1116e54c0>\n",
      "2022-03-31 14:51:32,425 fedbiomed INFO - Listing available datasets in all nodes... \n",
      "2022-03-31 14:51:32,442 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'command': 'list'}\n",
      "2022-03-31 14:51:32,443 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'command': 'list'}\n",
      "2022-03-31 14:51:32,451 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'command': 'list'}\n",
      "2022-03-31 14:51:33,372 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [1000/16954 (6%)]\tLoss: 1.479798\n",
      "2022-03-31 14:51:41,833 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [1200/16954 (7%)]\tLoss: 1.464416\n",
      "2022-03-31 14:51:42,445 fedbiomed INFO - \n",
      " Node: node_b472c750-0198-450d-85cf-8faddc7f54e0 | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] | bla           | [16954, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n",
      "2022-03-31 14:51:42,447 fedbiomed INFO - \n",
      " Node: node_aabe8200-9df6-48e7-a0c8-820be37261e2 | Number of Datasets: 1 \n",
      "+--------+-------------+-----------+---------------+--------------------+\n",
      "| name   | data_type   | tags      | description   | shape              |\n",
      "+========+=============+===========+===============+====================+\n",
      "| mnist  | images      | ['mnist'] | bla           | [18000, 3, 64, 64] |\n",
      "+--------+-------------+-----------+---------------+--------------------+\n",
      "\n",
      "2022-03-31 14:51:42,448 fedbiomed INFO - \n",
      " Node: node_278d405c-015c-4089-a6a4-25506c07fd24 | Number of Datasets: 1 \n",
      "+--------+-------------+-----------+---------------+--------------------+\n",
      "| name   | data_type   | tags      | description   | shape              |\n",
      "+========+=============+===========+===============+====================+\n",
      "| mnist  | images      | ['mnist'] | bla           | [18000, 3, 64, 64] |\n",
      "+--------+-------------+-----------+---------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_b472c750-0198-450d-85cf-8faddc7f54e0': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': 'bla',\n",
       "   'shape': [16954, 3, 64, 64]}],\n",
       " 'node_aabe8200-9df6-48e7-a0c8-820be37261e2': [{'name': 'mnist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mnist'],\n",
       "   'description': 'bla',\n",
       "   'shape': [18000, 3, 64, 64]}],\n",
       " 'node_278d405c-015c-4089-a6a4-25506c07fd24': [{'name': 'mnist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mnist'],\n",
       "   'description': 'bla',\n",
       "   'shape': [18000, 3, 64, 64]}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'DenseNet121')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"import numpy as np\",\n",
    "                \"import os\",\n",
    "                \"from torch.utils.data import DataLoader\",\n",
    "                \"from monai.apps import download_and_extract\",\n",
    "                \"from monai.config import print_config\",\n",
    "                \"from monai.data import decollate_batch\",\n",
    "                \"from monai.metrics import ROCAUCMetric\",\n",
    "                \"from monai.networks.nets import DenseNet121\",\n",
    "                \"from monai.transforms import ( Activations, AddChannel, AsDiscrete, Compose, LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity, EnsureType, )\",\n",
    "                \"from monai.utils import set_determinism\",\n",
    "                \"from opacus import PrivacyEngine\",]\n",
    "        self.add_dependency(deps)\n",
    "         \n",
    "        self.num_class =  model_args['num_class']\n",
    "        \n",
    "        self.model = DenseNet121(spatial_dims=2, in_channels=1,\n",
    "                    out_channels = self.num_class, norm=('GROUP', {'num_groups': 8}))\n",
    "        \n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.noise_multiplier = model_args['noise_multiplier']\n",
    "        self.max_grad_norm = model_args['max_grad_norm']\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    class MedNISTDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, image_files, labels, transforms):\n",
    "                self.image_files = image_files\n",
    "                self.labels = labels\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_files)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return self.transforms(self.image_files[index]), self.labels[index]\n",
    "    \n",
    "    def parse_data(self, path):\n",
    "        print(self.dataset_path)\n",
    "        class_names = sorted(x for x in os.listdir(path)\n",
    "                     if os.path.isdir(os.path.join(path, x)))\n",
    "        num_class = len(class_names)\n",
    "        image_files = [\n",
    "                        [\n",
    "                            os.path.join(path, class_names[i], x)\n",
    "                            for x in os.listdir(os.path.join(path, class_names[i]))\n",
    "                        ]\n",
    "                        for i in range(num_class)\n",
    "                      ]\n",
    "        \n",
    "        return image_files, num_class\n",
    "    \n",
    "    def training_data(self, batch_size = 48):\n",
    "        self.image_files, num_class = self.parse_data(self.dataset_path)\n",
    "        \n",
    "        if self.num_class!=num_class:\n",
    "                raise Exception('number of available classes does not match declared classes')\n",
    "        \n",
    "        num_each = [len(self.image_files[i]) for i in range(self.num_class)]\n",
    "        image_files_list = []\n",
    "        image_class = []\n",
    "        \n",
    "        for i in range(self.num_class):\n",
    "            image_files_list.extend(self.image_files[i])\n",
    "            image_class.extend([i] * num_each[i])\n",
    "        num_total = len(image_class)\n",
    "        \n",
    "        \n",
    "        length = len(image_files_list)\n",
    "        indices = np.arange(length)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        val_split = int(1. * length) \n",
    "        train_indices = indices[:val_split]\n",
    "\n",
    "        train_x = [image_files_list[i] for i in train_indices]\n",
    "        train_y = [image_class[i] for i in train_indices]\n",
    "\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImage(image_only=True),\n",
    "                AddChannel(),\n",
    "                ScaleIntensity(),\n",
    "                RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "                RandFlip(spatial_axis=0, prob=0.5),\n",
    "                RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "                EnsureType(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transforms = Compose(\n",
    "            [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "        y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "        y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])\n",
    "\n",
    "        print(\n",
    "            f\"Training count: {len(train_x)}\")\n",
    "        \n",
    "        \n",
    "        train_ds = self.MedNISTDataset(train_x, train_y, train_transforms)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_ds, batch_size, shuffle=True)\n",
    "        \n",
    "        \n",
    "        # enter PrivacyEngine\n",
    "        privacy_engine = PrivacyEngine()\n",
    "        self.model, self.optimizer, data_loader = privacy_engine.make_private(module=self.model,\n",
    "                                                                    optimizer=self.optimizer,\n",
    "                                                                    data_loader=train_loader,\n",
    "                                                                    noise_multiplier=self.noise_multiplier,\n",
    "                                                                    max_grad_norm=self.max_grad_norm,\n",
    "                                                                    )\n",
    "        \n",
    "        return train_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = self.loss_function(output, target)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def postprocess(self, params):\n",
    "        # params keys are changed by the privacy engine (as _module.param_key): should be re-named\n",
    "        params_keys = list(params.keys())\n",
    "        for key in params_keys:\n",
    "            if '_module' in key:\n",
    "                newkey = key.replace('_module.', '')\n",
    "                params[newkey] = params.pop(key)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side. For instance, the privacy parameters should be passed here.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. 🤓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {'noise_multiplier':0., 'max_grad_norm':1.0, 'num_class':6,}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 3, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 250 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and run the experiment\n",
    "\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 14:51:45,747 fedbiomed INFO - Searching dataset with data tags: ['mnist'] for all nodes\n",
      "2022-03-31 14:51:45,755 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'tags': ['mnist'], 'command': 'search'}\n",
      "2022-03-31 14:51:45,757 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'tags': ['mnist'], 'command': 'search'}\n",
      "2022-03-31 14:51:45,758 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'tags': ['mnist'], 'command': 'search'}\n",
      "2022-03-31 14:51:50,944 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [1400/16954 (8%)]\tLoss: 1.299348\n",
      "2022-03-31 14:51:55,754 fedbiomed INFO - Node selected for training -> node_aabe8200-9df6-48e7-a0c8-820be37261e2\n",
      "2022-03-31 14:51:55,755 fedbiomed INFO - Node selected for training -> node_278d405c-015c-4089-a6a4-25506c07fd24\n",
      "2022-03-31 14:51:55,756 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "2022-03-31 14:51:55,922 fedbiomed DEBUG - Model file has been saved: /Users/mlorenzi/works/temp/fedbiomed/var/experiments/Experiment_0004/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py\n",
      "2022-03-31 14:51:55,991 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/mlorenzi/works/temp/fedbiomed/var/experiments/Experiment_0004/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py successful, with status code 201\n",
      "2022-03-31 14:51:58,887 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/mlorenzi/works/temp/fedbiomed/var/experiments/Experiment_0004/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['mnist']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 14:51:58,897 fedbiomed INFO - Sampled nodes in round 0 ['node_aabe8200-9df6-48e7-a0c8-820be37261e2', 'node_278d405c-015c-4089-a6a4-25506c07fd24']\n",
      "2022-03-31 14:51:58,898 fedbiomed INFO - Send message to node node_aabe8200-9df6-48e7-a0c8-820be37261e2 - {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_aabe8200-9df6-48e7-a0c8-820be37261e2': ['dataset_130fc886-a393-4d20-8b8f-a59738405b4a']}}\n",
      "2022-03-31 14:51:58,900 fedbiomed DEBUG - researcher_2a29744e-4430-4e85-9661-1c02afbdd825\n",
      "2022-03-31 14:51:58,901 fedbiomed INFO - Send message to node node_278d405c-015c-4089-a6a4-25506c07fd24 - {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_278d405c-015c-4089-a6a4-25506c07fd24': ['dataset_bd42e58f-6095-4f26-b840-a790c16c0215']}}\n",
      "2022-03-31 14:51:58,902 fedbiomed DEBUG - researcher_2a29744e-4430-4e85-9661-1c02afbdd825\n",
      "2022-03-31 14:51:58,922 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_aabe8200-9df6-48e7-a0c8-820be37261e2': ['dataset_130fc886-a393-4d20-8b8f-a59738405b4a']}}\n",
      "2022-03-31 14:51:58,924 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - [TASKS QUEUE] Item:{'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'training_data': {'node_aabe8200-9df6-48e7-a0c8-820be37261e2': ['dataset_130fc886-a393-4d20-8b8f-a59738405b4a']}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2022-03-31 14:51:58,927 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_278d405c-015c-4089-a6a4-25506c07fd24': ['dataset_bd42e58f-6095-4f26-b840-a790c16c0215']}}\n",
      "2022-03-31 14:51:58,933 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - [TASKS QUEUE] Item:{'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_init_41ea1992-6a41-4e25-bae0-214aa6201781.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'training_data': {'node_278d405c-015c-4089-a6a4-25506c07fd24': ['dataset_bd42e58f-6095-4f26-b840-a790c16c0215']}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2022-03-31 14:51:58,946 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - upload (HTTP GET request) of file my_model_f5fe871cda834051abd7efc24388edc8.py successful, with status code 200\n",
      "2022-03-31 14:51:58,956 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - upload (HTTP GET request) of file my_model_55007dab7c3e4da78e2529de06bcdb84.py successful, with status code 200\n",
      "2022-03-31 14:52:00,369 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - upload (HTTP GET request) of file my_model_1c55bc43-35d9-4984-88f2-d9ccb02b4fa0.pt successful, with status code 200\n",
      "2022-03-31 14:52:00,371 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - upload (HTTP GET request) of file my_model_bfa267fb-ced7-4e0d-ba51-b79db2fb769f.pt successful, with status code 200\n",
      "2022-03-31 14:52:00,762 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - training with arguments {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x143986eb0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}\n",
      "2022-03-31 14:52:00,763 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Dataset path has been set as/Users/mlorenzi/works/temp/MedNIST/client_1\n",
      "2022-03-31 14:52:00,773 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - training with arguments {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x149276eb0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}\n",
      "2022-03-31 14:52:00,776 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Dataset path has been set as/Users/mlorenzi/works/temp/MedNIST/client_2\n",
      "2022-03-31 14:52:00,777 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Using device cpu for training (cuda_available=False, gpu=False, gpu_only=False, use_gpu=False, gpu_num=None)\n",
      "2022-03-31 14:52:00,784 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Using device cpu for training (cuda_available=False, gpu=False, gpu_only=False, use_gpu=False, gpu_num=None)\n",
      "2022-03-31 14:52:01,343 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [1600/16954 (9%)]\tLoss: 1.205467\n",
      "2022-03-31 14:52:09,659 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [0/18000 (0%)]\tLoss: 1.891493\n",
      "2022-03-31 14:52:09,714 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [0/18000 (0%)]\tLoss: 1.849434\n",
      "2022-03-31 14:52:17,456 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [1800/16954 (11%)]\tLoss: 1.095052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 14:52:30,884 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [2000/16954 (12%)]\tLoss: 0.979356\n",
      "2022-03-31 14:52:45,219 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [2200/16954 (13%)]\tLoss: 0.976170\n",
      "2022-03-31 14:52:59,965 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [2400/16954 (14%)]\tLoss: 0.847939\n",
      "2022-03-31 14:53:14,459 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [2600/16954 (15%)]\tLoss: 0.955607\n",
      "2022-03-31 14:53:23,910 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [480/18000 (3%)]\tLoss: 1.743234\n",
      "2022-03-31 14:53:24,347 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [480/18000 (3%)]\tLoss: 1.719625\n",
      "2022-03-31 14:53:28,433 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [2800/16954 (17%)]\tLoss: 0.800255\n",
      "2022-03-31 14:53:43,470 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [3000/16954 (18%)]\tLoss: 0.754133\n",
      "2022-03-31 14:53:57,851 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [3200/16954 (19%)]\tLoss: 0.685684\n",
      "2022-03-31 14:54:12,513 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / INFO - Train Epoch: 1 [3400/16954 (20%)]\tLoss: 0.591022\n",
      "2022-03-31 14:54:27,444 fedbiomed INFO - log from: node_b472c750-0198-450d-85cf-8faddc7f54e0 / CRITICAL - Node stopped in signal_handler, probably by user decision (Ctrl C)\n",
      "2022-03-31 14:54:34,037 fedbiomed INFO - Error message received during training: FB312: Node stopped in SIGTERM signal handler\n",
      "2022-03-31 14:54:34,041 fedbiomed WARNING - Error message from node_b472c750-0198-450d-85cf-8faddc7f54e0 ignored, since this node is not part ot the training anymode\n",
      "2022-03-31 14:54:37,681 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [960/18000 (5%)]\tLoss: 1.389410\n",
      "2022-03-31 14:54:38,519 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [960/18000 (5%)]\tLoss: 1.518156\n",
      "2022-03-31 14:55:41,671 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [1440/18000 (8%)]\tLoss: 0.775682\n",
      "2022-03-31 14:55:42,549 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [1440/18000 (8%)]\tLoss: 0.836718\n",
      "2022-03-31 14:56:46,080 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [1920/18000 (11%)]\tLoss: 0.963680\n",
      "2022-03-31 14:56:46,908 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [1920/18000 (11%)]\tLoss: 2.396724\n",
      "2022-03-31 14:57:48,137 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [2400/18000 (13%)]\tLoss: 0.532838\n",
      "2022-03-31 14:57:49,004 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [2400/18000 (13%)]\tLoss: 0.901942\n",
      "2022-03-31 14:58:51,907 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [2880/18000 (16%)]\tLoss: 0.569976\n",
      "2022-03-31 14:58:52,786 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [2880/18000 (16%)]\tLoss: 0.267759\n",
      "2022-03-31 14:59:50,253 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [3360/18000 (19%)]\tLoss: 1.279764\n",
      "2022-03-31 14:59:51,372 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [3360/18000 (19%)]\tLoss: 0.824137\n",
      "2022-03-31 15:00:47,448 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [3840/18000 (21%)]\tLoss: 0.934345\n",
      "2022-03-31 15:00:49,030 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [3840/18000 (21%)]\tLoss: 0.607724\n",
      "2022-03-31 15:01:46,230 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [4320/18000 (24%)]\tLoss: 0.276740\n",
      "2022-03-31 15:01:47,679 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [4320/18000 (24%)]\tLoss: 0.332106\n",
      "2022-03-31 15:02:45,435 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [4800/18000 (27%)]\tLoss: 0.220607\n",
      "2022-03-31 15:02:47,082 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [4800/18000 (27%)]\tLoss: 0.237508\n",
      "2022-03-31 15:03:43,797 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [5280/18000 (29%)]\tLoss: 0.318228\n",
      "2022-03-31 15:03:45,459 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [5280/18000 (29%)]\tLoss: 0.142807\n",
      "2022-03-31 15:04:42,027 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [5760/18000 (32%)]\tLoss: 0.133575\n",
      "2022-03-31 15:04:43,638 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [5760/18000 (32%)]\tLoss: 0.231226\n",
      "2022-03-31 15:05:39,858 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [6240/18000 (35%)]\tLoss: 0.397132\n",
      "2022-03-31 15:05:41,515 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [6240/18000 (35%)]\tLoss: 0.427437\n",
      "2022-03-31 15:06:37,553 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [6720/18000 (37%)]\tLoss: 0.641895\n",
      "2022-03-31 15:06:39,061 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [6720/18000 (37%)]\tLoss: 0.407932\n",
      "2022-03-31 15:07:35,550 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [7200/18000 (40%)]\tLoss: 0.230807\n",
      "2022-03-31 15:07:37,151 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [7200/18000 (40%)]\tLoss: 0.050169\n",
      "2022-03-31 15:08:32,956 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [7680/18000 (43%)]\tLoss: 0.205630\n",
      "2022-03-31 15:08:34,697 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [7680/18000 (43%)]\tLoss: 0.520866\n",
      "2022-03-31 15:09:30,627 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [8160/18000 (45%)]\tLoss: 0.005334\n",
      "2022-03-31 15:09:32,410 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [8160/18000 (45%)]\tLoss: 0.413247\n",
      "2022-03-31 15:10:26,606 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [8640/18000 (48%)]\tLoss: 0.167181\n",
      "2022-03-31 15:10:28,813 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [8640/18000 (48%)]\tLoss: 0.266689\n",
      "2022-03-31 15:11:25,096 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [9120/18000 (51%)]\tLoss: 0.125159\n",
      "2022-03-31 15:11:27,302 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [9120/18000 (51%)]\tLoss: 0.475730\n",
      "2022-03-31 15:12:20,567 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [9600/18000 (53%)]\tLoss: 0.368819\n",
      "2022-03-31 15:12:22,988 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [9600/18000 (53%)]\tLoss: 0.005412\n",
      "2022-03-31 15:13:16,603 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [10080/18000 (56%)]\tLoss: 0.010405\n",
      "2022-03-31 15:13:19,046 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [10080/18000 (56%)]\tLoss: 0.498000\n",
      "2022-03-31 15:14:14,705 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [10560/18000 (59%)]\tLoss: 0.071665\n",
      "2022-03-31 15:14:17,230 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [10560/18000 (59%)]\tLoss: 0.057758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 15:15:12,122 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [11040/18000 (61%)]\tLoss: 0.597983\n",
      "2022-03-31 15:15:14,922 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [11040/18000 (61%)]\tLoss: 0.188527\n",
      "2022-03-31 15:16:07,745 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [11520/18000 (64%)]\tLoss: 0.164078\n",
      "2022-03-31 15:16:10,545 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [11520/18000 (64%)]\tLoss: 0.332423\n",
      "2022-03-31 15:17:03,439 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-03-31 15:17:06,083 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-03-31 15:17:08,974 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [0/18000 (0%)]\tLoss: 0.325795\n",
      "2022-03-31 15:17:11,584 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [0/18000 (0%)]\tLoss: 0.262905\n",
      "2022-03-31 15:18:04,450 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [480/18000 (3%)]\tLoss: 0.114269\n",
      "2022-03-31 15:18:07,001 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [480/18000 (3%)]\tLoss: 0.410047\n",
      "2022-03-31 15:19:00,027 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [960/18000 (5%)]\tLoss: 0.086699\n",
      "2022-03-31 15:19:02,696 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [960/18000 (5%)]\tLoss: 0.108973\n",
      "2022-03-31 15:19:55,426 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [1440/18000 (8%)]\tLoss: 0.408538\n",
      "2022-03-31 15:19:58,298 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [1440/18000 (8%)]\tLoss: 0.000904\n",
      "2022-03-31 15:20:50,891 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [1920/18000 (11%)]\tLoss: 0.049418\n",
      "2022-03-31 15:20:53,662 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [1920/18000 (11%)]\tLoss: 0.059871\n",
      "2022-03-31 15:21:46,583 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [2400/18000 (13%)]\tLoss: 0.005941\n",
      "2022-03-31 15:21:49,464 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [2400/18000 (13%)]\tLoss: 0.303560\n",
      "2022-03-31 15:22:42,121 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [2880/18000 (16%)]\tLoss: 0.178774\n",
      "2022-03-31 15:22:44,992 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [2880/18000 (16%)]\tLoss: 0.414776\n",
      "2022-03-31 15:23:38,103 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [3360/18000 (19%)]\tLoss: 0.316008\n",
      "2022-03-31 15:23:41,079 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [3360/18000 (19%)]\tLoss: 0.019692\n",
      "2022-03-31 15:24:34,421 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [3840/18000 (21%)]\tLoss: 0.037202\n",
      "2022-03-31 15:24:37,694 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [3840/18000 (21%)]\tLoss: 0.177141\n",
      "2022-03-31 15:25:31,236 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [4320/18000 (24%)]\tLoss: 0.278426\n",
      "2022-03-31 15:25:34,817 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [4320/18000 (24%)]\tLoss: 0.000293\n",
      "2022-03-31 15:26:27,626 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [4800/18000 (27%)]\tLoss: 0.039324\n",
      "2022-03-31 15:26:30,776 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [4800/18000 (27%)]\tLoss: 0.096262\n",
      "2022-03-31 15:27:23,192 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [5280/18000 (29%)]\tLoss: 0.466448\n",
      "2022-03-31 15:27:26,377 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [5280/18000 (29%)]\tLoss: 0.238952\n",
      "2022-03-31 15:28:18,803 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [5760/18000 (32%)]\tLoss: 0.016700\n",
      "2022-03-31 15:28:22,005 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [5760/18000 (32%)]\tLoss: 0.371640\n",
      "2022-03-31 15:29:13,967 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [6240/18000 (35%)]\tLoss: 0.194316\n",
      "2022-03-31 15:29:17,114 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [6240/18000 (35%)]\tLoss: 0.197919\n",
      "2022-03-31 15:30:11,797 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [6720/18000 (37%)]\tLoss: 0.149720\n",
      "2022-03-31 15:30:14,942 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [6720/18000 (37%)]\tLoss: 0.147098\n",
      "2022-03-31 15:31:08,947 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [7200/18000 (40%)]\tLoss: 0.333387\n",
      "2022-03-31 15:31:12,148 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [7200/18000 (40%)]\tLoss: 0.277006\n",
      "2022-03-31 15:32:04,610 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [7680/18000 (43%)]\tLoss: 0.000726\n",
      "2022-03-31 15:32:07,899 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [7680/18000 (43%)]\tLoss: 0.226831\n",
      "2022-03-31 15:33:00,437 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [8160/18000 (45%)]\tLoss: 0.000446\n",
      "2022-03-31 15:33:03,754 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [8160/18000 (45%)]\tLoss: 0.000714\n",
      "2022-03-31 15:33:55,907 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [8640/18000 (48%)]\tLoss: 0.107421\n",
      "2022-03-31 15:33:59,348 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [8640/18000 (48%)]\tLoss: 0.150734\n",
      "2022-03-31 15:34:54,009 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [9120/18000 (51%)]\tLoss: 0.224612\n",
      "2022-03-31 15:34:57,079 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [9120/18000 (51%)]\tLoss: 0.069448\n",
      "2022-03-31 15:35:48,889 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [9600/18000 (53%)]\tLoss: 0.014704\n",
      "2022-03-31 15:35:52,225 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [9600/18000 (53%)]\tLoss: 0.218827\n",
      "2022-03-31 15:36:43,427 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [10080/18000 (56%)]\tLoss: 0.000652\n",
      "2022-03-31 15:36:46,494 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [10080/18000 (56%)]\tLoss: 0.268218\n",
      "2022-03-31 15:37:37,810 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [10560/18000 (59%)]\tLoss: 0.343464\n",
      "2022-03-31 15:37:40,948 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [10560/18000 (59%)]\tLoss: 0.192436\n",
      "2022-03-31 15:38:42,065 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [11040/18000 (61%)]\tLoss: 0.726484\n",
      "2022-03-31 15:38:45,200 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [11040/18000 (61%)]\tLoss: 0.828126\n",
      "2022-03-31 15:39:36,786 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 2 [11520/18000 (64%)]\tLoss: 0.210083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 15:39:40,031 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 2 [11520/18000 (64%)]\tLoss: 0.018967\n",
      "2022-03-31 15:40:33,845 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-03-31 15:40:38,717 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-03-31 15:40:40,839 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [0/18000 (0%)]\tLoss: 0.000564\n",
      "2022-03-31 15:40:44,294 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [0/18000 (0%)]\tLoss: 0.038664\n",
      "2022-03-31 15:41:35,893 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [480/18000 (3%)]\tLoss: 0.000210\n",
      "2022-03-31 15:41:39,349 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [480/18000 (3%)]\tLoss: 0.006587\n",
      "2022-03-31 15:42:30,431 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [960/18000 (5%)]\tLoss: 0.104339\n",
      "2022-03-31 15:42:34,032 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [960/18000 (5%)]\tLoss: 0.036377\n",
      "2022-03-31 15:43:29,895 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [1440/18000 (8%)]\tLoss: 0.000190\n",
      "2022-03-31 15:43:37,467 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [1440/18000 (8%)]\tLoss: 0.014769\n",
      "2022-03-31 15:44:32,132 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [1920/18000 (11%)]\tLoss: 0.000269\n",
      "2022-03-31 15:44:36,935 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [1920/18000 (11%)]\tLoss: 0.121609\n",
      "2022-03-31 15:45:41,974 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [2400/18000 (13%)]\tLoss: 0.428678\n",
      "2022-03-31 15:45:47,117 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [2400/18000 (13%)]\tLoss: 0.136059\n",
      "2022-03-31 15:46:35,385 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [2880/18000 (16%)]\tLoss: 0.000218\n",
      "2022-03-31 15:46:40,362 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [2880/18000 (16%)]\tLoss: 0.282241\n",
      "2022-03-31 15:47:27,956 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [3360/18000 (19%)]\tLoss: 0.000194\n",
      "2022-03-31 15:47:33,075 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [3360/18000 (19%)]\tLoss: 0.167286\n",
      "2022-03-31 15:48:20,549 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [3840/18000 (21%)]\tLoss: 0.172885\n",
      "2022-03-31 15:48:25,602 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [3840/18000 (21%)]\tLoss: 0.000201\n",
      "2022-03-31 15:49:12,866 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [4320/18000 (24%)]\tLoss: 0.000407\n",
      "2022-03-31 15:49:18,312 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [4320/18000 (24%)]\tLoss: 0.023893\n",
      "2022-03-31 15:50:05,626 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [4800/18000 (27%)]\tLoss: 0.000318\n",
      "2022-03-31 15:50:10,895 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [4800/18000 (27%)]\tLoss: 0.619612\n",
      "2022-03-31 15:50:58,186 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [5280/18000 (29%)]\tLoss: 0.132350\n",
      "2022-03-31 15:51:03,644 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [5280/18000 (29%)]\tLoss: 0.227315\n",
      "2022-03-31 15:51:50,857 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [5760/18000 (32%)]\tLoss: 0.000270\n",
      "2022-03-31 15:51:56,419 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [5760/18000 (32%)]\tLoss: 0.416288\n",
      "2022-03-31 15:52:43,683 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [6240/18000 (35%)]\tLoss: 0.000330\n",
      "2022-03-31 15:52:49,418 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [6240/18000 (35%)]\tLoss: 0.243538\n",
      "2022-03-31 15:53:36,493 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [6720/18000 (37%)]\tLoss: 0.000077\n",
      "2022-03-31 15:53:42,025 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [6720/18000 (37%)]\tLoss: 0.000872\n",
      "2022-03-31 15:54:29,214 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [7200/18000 (40%)]\tLoss: 0.000128\n",
      "2022-03-31 15:54:34,815 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [7200/18000 (40%)]\tLoss: 0.152032\n",
      "2022-03-31 15:55:25,177 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [7680/18000 (43%)]\tLoss: 0.052387\n",
      "2022-03-31 15:55:31,762 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [7680/18000 (43%)]\tLoss: 0.000724\n",
      "2022-03-31 15:56:36,999 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [8160/18000 (45%)]\tLoss: 0.292086\n",
      "2022-03-31 15:56:43,558 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [8160/18000 (45%)]\tLoss: 0.142907\n",
      "2022-03-31 15:57:32,939 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [8640/18000 (48%)]\tLoss: 0.093495\n",
      "2022-03-31 15:57:39,480 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [8640/18000 (48%)]\tLoss: 0.491312\n",
      "2022-03-31 15:58:29,078 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [9120/18000 (51%)]\tLoss: 0.000193\n",
      "2022-03-31 15:58:34,917 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [9120/18000 (51%)]\tLoss: 0.050583\n",
      "2022-03-31 15:59:23,397 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [9600/18000 (53%)]\tLoss: 0.121073\n",
      "2022-03-31 15:59:29,344 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [9600/18000 (53%)]\tLoss: 0.000249\n",
      "2022-03-31 16:00:20,020 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [10080/18000 (56%)]\tLoss: 0.138237\n",
      "2022-03-31 16:00:25,713 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [10080/18000 (56%)]\tLoss: 0.090166\n",
      "2022-03-31 16:01:13,105 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [10560/18000 (59%)]\tLoss: 0.191257\n",
      "2022-03-31 16:01:18,873 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [10560/18000 (59%)]\tLoss: 0.193552\n",
      "2022-03-31 16:02:12,319 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [11040/18000 (61%)]\tLoss: 0.000214\n",
      "2022-03-31 16:02:20,870 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [11040/18000 (61%)]\tLoss: 0.447606\n",
      "2022-03-31 16:03:15,600 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 3 [11520/18000 (64%)]\tLoss: 0.119104\n",
      "2022-03-31 16:03:23,560 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 3 [11520/18000 (64%)]\tLoss: 0.160752\n",
      "2022-03-31 16:04:17,778 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-03-31 16:04:17,795 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - running model.postprocess() method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 16:04:20,417 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - upload (HTTP POST request) of file /Users/mlorenzi/works/temp/fedbiomed/var/tmp/node_params_f8e96538-b623-4e71-9ca3-d6d079be7f95.pt successful, with status code 201\n",
      "2022-03-31 16:04:20,460 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - results uploaded successfully \n",
      "2022-03-31 16:04:23,471 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-03-31 16:04:23,482 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - running model.postprocess() method\n",
      "2022-03-31 16:04:25,509 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - upload (HTTP POST request) of file /Users/mlorenzi/works/temp/fedbiomed/var/tmp/node_params_c21ebfa2-4c6c-43bd-bffb-8c10c0137c5e.pt successful, with status code 201\n",
      "2022-03-31 16:04:25,536 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - results uploaded successfully \n",
      "2022-03-31 16:04:33,707 fedbiomed INFO - Downloading model params after training on node_aabe8200-9df6-48e7-a0c8-820be37261e2 - from http://localhost:8844/media/uploads/2022/03/31/node_params_f8e96538-b623-4e71-9ca3-d6d079be7f95.pt\n",
      "2022-03-31 16:04:34,518 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_2b295b7b-1401-4d2f-85b5-67aa963cdacc.pt successful, with status code 200\n",
      "2022-03-31 16:04:34,696 fedbiomed INFO - Downloading model params after training on node_278d405c-015c-4089-a6a4-25506c07fd24 - from http://localhost:8844/media/uploads/2022/03/31/node_params_c21ebfa2-4c6c-43bd-bffb-8c10c0137c5e.pt\n",
      "2022-03-31 16:04:35,376 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_fa31351f-6bcd-450c-8ce5-ad3a161340a4.pt successful, with status code 200\n",
      "2022-03-31 16:04:35,515 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_aabe8200-9df6-48e7-a0c8-820be37261e2', 'node_278d405c-015c-4089-a6a4-25506c07fd24']\n",
      "2022-03-31 16:04:37,766 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/mlorenzi/works/temp/fedbiomed/var/experiments/Experiment_0004/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt successful, with status code 201\n",
      "2022-03-31 16:04:37,769 fedbiomed INFO - Saved aggregated params for round 0 in /Users/mlorenzi/works/temp/fedbiomed/var/experiments/Experiment_0004/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt\n",
      "2022-03-31 16:04:37,770 fedbiomed INFO - Sampled nodes in round 1 ['node_aabe8200-9df6-48e7-a0c8-820be37261e2', 'node_278d405c-015c-4089-a6a4-25506c07fd24']\n",
      "2022-03-31 16:04:37,771 fedbiomed INFO - Send message to node node_aabe8200-9df6-48e7-a0c8-820be37261e2 - {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_aabe8200-9df6-48e7-a0c8-820be37261e2': ['dataset_130fc886-a393-4d20-8b8f-a59738405b4a']}}\n",
      "2022-03-31 16:04:37,773 fedbiomed DEBUG - researcher_2a29744e-4430-4e85-9661-1c02afbdd825\n",
      "2022-03-31 16:04:37,774 fedbiomed INFO - Send message to node node_278d405c-015c-4089-a6a4-25506c07fd24 - {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_278d405c-015c-4089-a6a4-25506c07fd24': ['dataset_bd42e58f-6095-4f26-b840-a790c16c0215']}}\n",
      "2022-03-31 16:04:37,775 fedbiomed DEBUG - researcher_2a29744e-4430-4e85-9661-1c02afbdd825\n",
      "2022-03-31 16:04:37,802 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_aabe8200-9df6-48e7-a0c8-820be37261e2': ['dataset_130fc886-a393-4d20-8b8f-a59738405b4a']}}\n",
      "2022-03-31 16:04:37,804 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - [TASKS QUEUE] Item:{'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'training_data': {'node_aabe8200-9df6-48e7-a0c8-820be37261e2': ['dataset_130fc886-a393-4d20-8b8f-a59738405b4a']}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2022-03-31 16:04:37,817 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Message received: {'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_278d405c-015c-4089-a6a4-25506c07fd24': ['dataset_bd42e58f-6095-4f26-b840-a790c16c0215']}}\n",
      "2022-03-31 16:04:37,854 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - [TASKS QUEUE] Item:{'researcher_id': 'researcher_2a29744e-4430-4e85-9661-1c02afbdd825', 'job_id': '2c1f1a9b-e550-4024-b8ba-0ed128e35750', 'params_url': 'http://localhost:8844/media/uploads/2022/03/31/aggregated_params_a1e04a7e-367f-48d2-b3c6-35ec8a94c6c0.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}, 'training_data': {'node_278d405c-015c-4089-a6a4-25506c07fd24': ['dataset_bd42e58f-6095-4f26-b840-a790c16c0215']}, 'model_args': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0, 'num_class': 6}, 'model_url': 'http://localhost:8844/media/uploads/2022/03/31/my_model_8eadde75-dd5c-4e3d-83e4-2293e4eea2c1.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2022-03-31 16:04:37,868 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - upload (HTTP GET request) of file my_model_4f07d83224f148beb79b2c18f9a4b13b.py successful, with status code 200\n",
      "2022-03-31 16:04:37,870 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - upload (HTTP GET request) of file my_model_8ec4c6f73ebe49cdbd60503191237d74.py successful, with status code 200\n",
      "2022-03-31 16:04:38,875 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - upload (HTTP GET request) of file my_model_2aba2669-9d00-4e57-9099-fa61b0c44092.pt successful, with status code 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 16:04:38,932 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - upload (HTTP GET request) of file my_model_cb833a7e-dd24-4367-9583-540831c99c58.pt successful, with status code 200\n",
      "2022-03-31 16:04:39,268 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - training with arguments {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x137d15070>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}\n",
      "2022-03-31 16:04:39,269 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Dataset path has been set as/Users/mlorenzi/works/temp/MedNIST/client_2\n",
      "2022-03-31 16:04:39,270 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / DEBUG - Using device cpu for training (cuda_available=False, gpu=False, gpu_only=False, use_gpu=False, gpu_num=None)\n",
      "2022-03-31 16:04:39,291 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - training with arguments {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x145fbba60>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 3, 'dry_run': False, 'batch_maxnum': 250}\n",
      "2022-03-31 16:04:39,292 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Dataset path has been set as/Users/mlorenzi/works/temp/MedNIST/client_1\n",
      "2022-03-31 16:04:39,302 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / DEBUG - Using device cpu for training (cuda_available=False, gpu=False, gpu_only=False, use_gpu=False, gpu_num=None)\n",
      "2022-03-31 16:04:46,722 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [0/18000 (0%)]\tLoss: 0.001667\n",
      "2022-03-31 16:04:46,747 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [0/18000 (0%)]\tLoss: 0.072526\n",
      "2022-03-31 16:05:41,154 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [480/18000 (3%)]\tLoss: 0.141401\n",
      "2022-03-31 16:05:41,220 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [480/18000 (3%)]\tLoss: 0.061796\n",
      "2022-03-31 16:06:35,936 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [960/18000 (5%)]\tLoss: 0.063040\n",
      "2022-03-31 16:06:36,146 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [960/18000 (5%)]\tLoss: 0.155829\n",
      "2022-03-31 16:07:28,710 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [1440/18000 (8%)]\tLoss: 0.264658\n",
      "2022-03-31 16:07:28,921 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [1440/18000 (8%)]\tLoss: 0.135822\n",
      "2022-03-31 16:08:22,806 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [1920/18000 (11%)]\tLoss: 0.164957\n",
      "2022-03-31 16:08:23,014 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [1920/18000 (11%)]\tLoss: 0.167438\n",
      "2022-03-31 16:09:20,869 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [2400/18000 (13%)]\tLoss: 0.097903\n",
      "2022-03-31 16:09:21,109 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [2400/18000 (13%)]\tLoss: 0.060042\n",
      "2022-03-31 16:10:23,441 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [2880/18000 (16%)]\tLoss: 0.228647\n",
      "2022-03-31 16:10:24,004 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [2880/18000 (16%)]\tLoss: 0.000566\n",
      "2022-03-31 16:11:24,050 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [3360/18000 (19%)]\tLoss: 0.024211\n",
      "2022-03-31 16:11:24,445 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [3360/18000 (19%)]\tLoss: 0.723798\n",
      "2022-03-31 16:12:21,199 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [3840/18000 (21%)]\tLoss: 0.214533\n",
      "2022-03-31 16:12:21,379 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [3840/18000 (21%)]\tLoss: 0.211497\n",
      "2022-03-31 16:13:22,000 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [4320/18000 (24%)]\tLoss: 0.000160\n",
      "2022-03-31 16:13:22,235 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [4320/18000 (24%)]\tLoss: 0.304226\n",
      "2022-03-31 16:14:17,229 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [4800/18000 (27%)]\tLoss: 0.001260\n",
      "2022-03-31 16:14:17,489 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [4800/18000 (27%)]\tLoss: 0.000076\n",
      "2022-03-31 16:15:12,906 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [5280/18000 (29%)]\tLoss: 0.187978\n",
      "2022-03-31 16:15:13,232 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [5280/18000 (29%)]\tLoss: 0.000202\n",
      "2022-03-31 16:16:14,789 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [5760/18000 (32%)]\tLoss: 0.087666\n",
      "2022-03-31 16:16:15,228 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [5760/18000 (32%)]\tLoss: 0.006830\n",
      "2022-03-31 16:17:13,306 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [6240/18000 (35%)]\tLoss: 0.086471\n",
      "2022-03-31 16:17:13,784 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [6240/18000 (35%)]\tLoss: 0.000049\n",
      "2022-03-31 16:18:13,238 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [6720/18000 (37%)]\tLoss: 0.029372\n",
      "2022-03-31 16:18:13,661 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [6720/18000 (37%)]\tLoss: 0.144017\n",
      "2022-03-31 16:19:11,003 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [7200/18000 (40%)]\tLoss: 0.000164\n",
      "2022-03-31 16:19:11,452 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [7200/18000 (40%)]\tLoss: 0.357483\n",
      "2022-03-31 16:20:11,843 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / INFO - Train Epoch: 1 [7680/18000 (43%)]\tLoss: 0.065453\n",
      "2022-03-31 16:20:11,969 fedbiomed INFO - log from: node_aabe8200-9df6-48e7-a0c8-820be37261e2 / CRITICAL - Node stopped in signal_handler, probably by user decision (Ctrl C)\n",
      "2022-03-31 16:20:12,337 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / INFO - Train Epoch: 1 [7680/18000 (43%)]\tLoss: 0.070475\n",
      "2022-03-31 16:20:13,943 fedbiomed INFO - log from: node_278d405c-015c-4089-a6a4-25506c07fd24 / CRITICAL - Node stopped in signal_handler, probably by user decision (Ctrl C)\n",
      "2022-03-31 16:20:23,358 fedbiomed INFO - Error message received during training: FB312: Node stopped in SIGTERM signal handler\n",
      "2022-03-31 16:20:23,359 fedbiomed INFO - Error message received during training: FB312: Node stopped in SIGTERM signal handler\n",
      "2022-03-31 16:20:23,362 fedbiomed ERROR - FB408: node did not answer during training (node = node_aabe8200-9df6-48e7-a0c8-820be37261e2)\n",
      "2022-03-31 16:20:23,363 fedbiomed ERROR - FB408: node did not answer during training (node = node_278d405c-015c-4089-a6a4-25506c07fd24)\n",
      "2022-03-31 16:20:23,364 fedbiomed CRITICAL - FB407: list of nodes became empty when training\n",
      "2022-03-31 16:20:23,369 fedbiomed CRITICAL - Fed-BioMed researcher stopped due to exception:\n",
      "FB407: list of nodes became empty when training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Fed-BioMed researcher stopped due to exception:\n",
      "FB407: list of nodes became empty when training\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available in `exp.training_replies()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1].data()\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies()[rounds - 1].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available in `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params().keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params()[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params()[rounds - 1]['params'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a little testing routine to extract the accuracy metrics on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    device = 'cpu'\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/len(data_loader.dataset)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "local_mnist = os.path.join(environ['TMP_DIR'], 'local_mnist')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "test_set = datasets.MNIST(root = local_mnist, download = True, train = False, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fed_model = exp.model_instance()\n",
    "fed_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])\n",
    "\n",
    "acc_federated = testing_Accuracy(fed_model, test_loader)\n",
    "\n",
    "print('\\nAccuracy federated training:  {:.4f}'.format(acc_federated[1]))\n",
    "\n",
    "print('\\nError federated training:  {:.4f}'.format(acc_federated[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
