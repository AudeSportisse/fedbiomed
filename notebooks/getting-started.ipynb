{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Connected with result code 0`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:06:32,838 fedbiomed INFO - Component environment:\n",
      "2021-12-15 13:06:32,838 fedbiomed INFO - - type = ComponentType.RESEARCHER\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+'/')\n",
    "model_file = tmp_dir_model.name + '/class_export_mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : write **only** the code to export in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /user/scansiz/home/Desktop/Inria/development/fedbiomed/var/tmp/tmpz_hvgwgj/class_export_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "               \"from torch.utils.data import DataLoader\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:13:56,138 fedbiomed INFO - Searching dataset with data tags: ['#MNIST', '#dataset'] for all nodes\n",
      "2021-12-15 13:13:56,141 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Message received: {'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'tags': ['#MNIST', '#dataset'], 'command': 'search'}\n",
      "2021-12-15 13:14:06,151 fedbiomed INFO - Node selected for training -> node_0e284192-5648-4a99-9074-2727876dec75\n",
      "2021-12-15 13:14:06,171 fedbiomed DEBUG - torchnn saved model filename: /user/scansiz/home/Desktop/Inria/development/fedbiomed/var/tmpdsyu9ad6/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #nodes=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='MyTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:14:19,371 fedbiomed INFO - Sampled nodes in round 0 ['node_0e284192-5648-4a99-9074-2727876dec75']\n",
      "2021-12-15 13:14:19,372 fedbiomed INFO - Send message to node node_0e284192-5648-4a99-9074-2727876dec75 - {'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'job_id': '6519ec32-4eed-4d35-85b3-7f4deaf8a79c', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py', 'params_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_5ae4da84-5fb1-4af1-a707-df1510e60441.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_0e284192-5648-4a99-9074-2727876dec75': ['dataset_90f83604-d3cb-4e2d-aaaf-ac3fea64f674']}}\n",
      "2021-12-15 13:14:19,373 fedbiomed DEBUG - researcher_972412b8-9c49-4e94-8487-213975f639a5\n",
      "2021-12-15 13:14:19,378 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Message received: {'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'job_id': '6519ec32-4eed-4d35-85b3-7f4deaf8a79c', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py', 'params_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_5ae4da84-5fb1-4af1-a707-df1510e60441.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_0e284192-5648-4a99-9074-2727876dec75': ['dataset_90f83604-d3cb-4e2d-aaaf-ac3fea64f674']}}\n",
      "2021-12-15 13:14:19,379 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG [TASKS QUEUE] Item:{'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'job_id': '6519ec32-4eed-4d35-85b3-7f4deaf8a79c', 'params_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_5ae4da84-5fb1-4af1-a707-df1510e60441.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training_data': {'node_0e284192-5648-4a99-9074-2727876dec75': ['dataset_90f83604-d3cb-4e2d-aaaf-ac3fea64f674']}, 'model_args': {}, 'model_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2021-12-15 13:14:19,613 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7fe700976fd0>, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\n",
      "2021-12-15 13:14:19,614 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Dataset_path/user/scansiz/home/Desktop/Inria/development/fedbiomed/data/defaults/mnist\n",
      "2021-12-15 13:14:19,766 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.295460\n",
      "2021-12-15 13:14:20,315 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [480/60000 (1%)]\tLoss: 1.297822\n",
      "2021-12-15 13:14:20,921 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [960/60000 (2%)]\tLoss: 1.079754\n",
      "2021-12-15 13:14:21,501 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [1440/60000 (2%)]\tLoss: 0.689684\n",
      "2021-12-15 13:14:22,080 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.351122\n",
      "2021-12-15 13:14:22,739 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [2400/60000 (4%)]\tLoss: 0.568509\n",
      "2021-12-15 13:14:23,764 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.498909\n",
      "2021-12-15 13:14:24,494 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [3360/60000 (6%)]\tLoss: 0.381328\n",
      "2021-12-15 13:14:25,078 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.194545\n",
      "2021-12-15 13:14:25,678 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [4320/60000 (7%)]\tLoss: 0.309863\n",
      "2021-12-15 13:14:26,422 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Reached 100 batches for this epoch, ignore remaining data\n",
      "2021-12-15 13:14:26,679 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO results uploaded successfully \n",
      "2021-12-15 13:14:34,405 fedbiomed INFO - Downloading model params after training on node_0e284192-5648-4a99-9074-2727876dec75 - from http://localhost:8844/media/uploads/2021/12/15/node_params_908390a4-d6dc-485d-9466-38c55d17ba63.pt\n",
      "2021-12-15 13:14:34,593 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_0e284192-5648-4a99-9074-2727876dec75']\n",
      "2021-12-15 13:14:34,760 fedbiomed INFO - Sampled nodes in round 1 ['node_0e284192-5648-4a99-9074-2727876dec75']\n",
      "2021-12-15 13:14:34,760 fedbiomed INFO - Send message to node node_0e284192-5648-4a99-9074-2727876dec75 - {'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'job_id': '6519ec32-4eed-4d35-85b3-7f4deaf8a79c', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py', 'params_url': 'http://localhost:8844/media/uploads/2021/12/15/researcher_params_f03a4f30-b08f-45f7-8b6e-06c86fa28d2f.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_0e284192-5648-4a99-9074-2727876dec75': ['dataset_90f83604-d3cb-4e2d-aaaf-ac3fea64f674']}}\n",
      "2021-12-15 13:14:34,761 fedbiomed DEBUG - researcher_972412b8-9c49-4e94-8487-213975f639a5\n",
      "2021-12-15 13:14:34,763 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Message received: {'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'job_id': '6519ec32-4eed-4d35-85b3-7f4deaf8a79c', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py', 'params_url': 'http://localhost:8844/media/uploads/2021/12/15/researcher_params_f03a4f30-b08f-45f7-8b6e-06c86fa28d2f.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_0e284192-5648-4a99-9074-2727876dec75': ['dataset_90f83604-d3cb-4e2d-aaaf-ac3fea64f674']}}\n",
      "2021-12-15 13:14:34,764 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG [TASKS QUEUE] Item:{'researcher_id': 'researcher_972412b8-9c49-4e94-8487-213975f639a5', 'job_id': '6519ec32-4eed-4d35-85b3-7f4deaf8a79c', 'params_url': 'http://localhost:8844/media/uploads/2021/12/15/researcher_params_f03a4f30-b08f-45f7-8b6e-06c86fa28d2f.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training_data': {'node_0e284192-5648-4a99-9074-2727876dec75': ['dataset_90f83604-d3cb-4e2d-aaaf-ac3fea64f674']}, 'model_args': {}, 'model_url': 'http://localhost:8844/media/uploads/2021/12/15/my_model_4872eb81-1457-42c0-8cc7-fc22c32f3bb7.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2021-12-15 13:14:34,801 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7fe700976f70>, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\n",
      "2021-12-15 13:14:34,801 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Dataset_path/user/scansiz/home/Desktop/Inria/development/fedbiomed/data/defaults/mnist\n",
      "2021-12-15 13:14:34,883 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.123431\n",
      "2021-12-15 13:14:35,477 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [480/60000 (1%)]\tLoss: 0.452134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:14:35,957 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [960/60000 (2%)]\tLoss: 0.513389\n",
      "2021-12-15 13:14:36,510 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [1440/60000 (2%)]\tLoss: 0.835859\n",
      "2021-12-15 13:14:37,098 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.142952\n",
      "2021-12-15 13:14:37,652 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [2400/60000 (4%)]\tLoss: 0.214618\n",
      "2021-12-15 13:14:38,216 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.103069\n",
      "2021-12-15 13:14:38,785 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [3360/60000 (6%)]\tLoss: 0.234877\n",
      "2021-12-15 13:14:39,299 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.412048\n",
      "2021-12-15 13:14:39,803 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO Train Epoch: 1 [4320/60000 (7%)]\tLoss: 0.089253\n",
      "2021-12-15 13:14:40,379 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - DEBUG Reached 100 batches for this epoch, ignore remaining data\n",
      "2021-12-15 13:14:40,550 fedbiomed INFO - log from: node_0e284192-5648-4a99-9074-2727876dec75 - INFO results uploaded successfully \n",
      "2021-12-15 13:14:49,779 fedbiomed INFO - Downloading model params after training on node_0e284192-5648-4a99-9074-2727876dec75 - from http://localhost:8844/media/uploads/2021/12/15/node_params_36282add-f5e3-442c-8a9b-88b19b852899.pt\n",
      "2021-12-15 13:14:49,799 fedbiomed INFO - Nodes that successfully reply in round 1 ['node_0e284192-5648-4a99-9074-2727876dec75']\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available in `exp.training_replies` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies.keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies[rounds - 1].data\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies[rounds - 1].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available in `exp.aggregated_params` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params.keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params[rounds - 1]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional : searching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "\n",
    "r = Requests()\n",
    "data = r.search(tags)\n",
    "\n",
    "import pandas as pd\n",
    "for node_id in data.keys():\n",
    "    print('\\n','Data for ', node_id, '\\n\\n', pd.DataFrame(data[node_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optional : clean file repository (do not run unless necessary)\n",
    "Clean all the files in the repo via the rest API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from fedbiomed.researcher.environ import environ\n",
    "\n",
    "# uploaded_models = requests.get(environ['UPLOADS_URL']).json()\n",
    "# for m in uploaded_models:\n",
    "#   requests.delete(m['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Feel free to try your own models :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
