{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f67fab2",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to store script for generating tabular random data\n",
    "\n",
    "\n",
    "- single view data\n",
    "- multi view (folder of csv files)\n",
    "- multi view data (all contained in a single csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a0e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 create random data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from typing import Iterator, Union, List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "659a9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataGenerator:\n",
    "    def __init__(self, n_samples:int, \n",
    "                 feature_names:Iterator[str]=None,\n",
    "                 is_multi_view:bool=False,\n",
    "                 as_multi_index:bool=False):\n",
    "        self._array = None\n",
    "        \n",
    "        self._n_samples = n_samples\n",
    "        self._views = {}\n",
    "        self._features_names = []\n",
    "        self._primary_key = None  # either None or a pandas serie\n",
    "        #self._is_view_set = False\n",
    "        \n",
    "    def set_primary_key(self, col_name: Union[str, int]=None):\n",
    "        if col_name is not None:\n",
    "            col_indx = self._get_index(col_name)\n",
    "            print('col_indx', col_indx)\n",
    "            self._primary_key = self._array.iloc[:,col_indx]\n",
    "\n",
    "    def set_view(self, view_name:str):\n",
    "        if self._array is not None:\n",
    "            _df = self.get_single_view_dataframe()\n",
    "        self._views[view_name] = _df\n",
    "        self._features_names = []\n",
    "        self._array = None\n",
    "    \n",
    "    def get_single_view_dataframe(self):\n",
    "        #_df = pd.DataFrame(self._array, columns=self._features_names)\n",
    "        return self._array\n",
    "    \n",
    "    def add_integers_values(self, n_col: int=1,\n",
    "                            col_name:Union[str, Iterator[str]] =None,\n",
    "                            l_bound:int=0,\n",
    "                           u_bound:int=100):\n",
    "\n",
    "        _rand_int = np.random.randint(l_bound, u_bound, size=(self._n_samples, n_col))\n",
    "        _rand_int = pd.DataFrame(_rand_int)\n",
    "        if col_name is not None:\n",
    "            _rand_int.columns = [col_name]\n",
    "        self._concatenate(_rand_int)\n",
    "        if col_name is not None:\n",
    "            self._features_names.append(col_name)\n",
    "    \n",
    "    def add_float_values(self, n_col:int=1, col_name:str=None):\n",
    "        _rand = np.random.random((self._n_samples, n_col))\n",
    "        _rand = pd.DataFrame(_rand)\n",
    "        if col_name is not None:\n",
    "            _rand.columns = [col_name]\n",
    "        self._concatenate(_rand)\n",
    "        if col_name is not None:\n",
    "            self._features_names.append(col_name)\n",
    "            \n",
    "    def add_discrete_values(self, n_col:int=1,\n",
    "                            col_name:Union[str, Iterator[str]] =None,\n",
    "                            l_bound:int=0,\n",
    "                           u_bound:int=100):\n",
    "        \n",
    "        _rand_int = np.random.randint(l_bound, u_bound, size=(self._n_samples, n_col))\n",
    "        _rand_int = np.array(_rand_int, dtype=np.float64) # changing type from int to float\n",
    "        _rand_int = pd.DataFrame(_rand_int)\n",
    "        if col_name is not None:\n",
    "            _rand_int.columns = [col_name]\n",
    "        self._concatenate(_rand_int)\n",
    "        if col_name is not None:\n",
    "            self._features_names.append(col_name)\n",
    "            \n",
    "    def add_datetime_values(self,  start=None, end=None, col_name:str=None, freq='H', **kwargs):\n",
    "        _dti = pd.date_range(start, end, periods=self._n_samples, freq=freq,**kwargs)\n",
    "        _dti = pd.DataFrame(_dti)\n",
    "        if col_name is not None:\n",
    "            _dti.columns = [col_name]\n",
    "        self._concatenate(_dti)\n",
    "        if col_name is not None:\n",
    "            self._features_names.append(col_name)\n",
    "    \n",
    "    def add_missing_samples_to_column(self, col_name:Union[str, int], n_missing_points:int=1):\n",
    "        \n",
    "        if self._array is None:\n",
    "            raise ValueError(\"please add data before completing it with missig data\")\n",
    "        if n_missing_points >= self._n_samples:\n",
    "            raise ValueError(f\"too much missing points (n_missing_points {n_missing_points} < n_samples {self._n_samples})\")\n",
    "        col_indx = self._get_index(col_name)\n",
    "        _idx = np.arange(self._n_samples)\n",
    "        np.random.shuffle(_idx)\n",
    "        _array = self._array[:, col_indx]\n",
    "        _shuffled_array = _array[_idx]\n",
    "        _shuffled_array[:n_missing_points] = np.nan\n",
    "        self._array[:, col_indx] = _shuffled_array[_idx]\n",
    "    \n",
    "    def add_boolean_values(self, n_col:int=1, col_name: Union[str, Iterator[str]]=None):\n",
    "        _rand_bool = np.random.randint(0,2,size=(100, 4), dtype=bool)\n",
    "        _rand_bool = pd.DataFrame(_rand_bool)\n",
    "        if col_name is not None:\n",
    "            _rand_bool.columns = [col_name]\n",
    "        self._concatenate(_rand_bool)\n",
    "        if col_name is not None:\n",
    "            self._features_names.append(col_name)\n",
    "        \n",
    "    def shuffle_columns(self):\n",
    "        pass\n",
    "    \n",
    "    def get_multi_index_dataframe(self):\n",
    "        _dataset = self.get_multi_view_dataset()\n",
    "        _multi_index_df = create_multi_view_dataframe(_dataset)\n",
    "        return _multi_index_df\n",
    "    \n",
    "    def get_multi_view_dataset(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"gets tab\"\"\"\n",
    "        if not self._views:\n",
    "            self._views['view_0'] = self._array\n",
    "        if self._primary_key is not None:\n",
    "            # set a primary key to all dataframe\n",
    "            for view_name in self._views.keys():\n",
    "                # iterate over all views\n",
    "                if self._primary_key.name not in self._views[view_name].columns.values:\n",
    "                    # case where primary key is not present\n",
    "                    self._views[view_name] = pd.concat([self._views[view_name],\n",
    "                                                        self._primary_key], axis=1)\n",
    "                else:\n",
    "                    # case where primary key is present: we are updating just in case\n",
    "                    self._views[view_name][self._primary_key.name] = self._primary_key\n",
    "        return self._views\n",
    "    \n",
    "    def save_multi_view_dataframe(self, path_folder:str):\n",
    "        \"\"\"saves multiview dataframe (folder containing multiple csvs)\"\"\"\n",
    "        _multi_view_dataframe = self.get_multi_view_dataset()\n",
    "        os.mkdir(path_folder)\n",
    "        for name in _multi_view_dataframe.keys():\n",
    "            file_name = os.pah.join(path_folder, name)\n",
    "            _multi_view_dataframe[name].to_csv(file_name)\n",
    "        print(f'multi view dataset saved at {file_name}')\n",
    "        \n",
    "    def _concatenate(self, array):\n",
    "        if self._array is None:\n",
    "            self._array = array\n",
    "        else:\n",
    "            _act_col_names = self._array.columns.values.tolist()\n",
    "            #_act_col_names.extend(array.columns.values.tolist())\n",
    "            self._array = pd.concat([self._array, array], axis=1)\n",
    "            _curr_col_name = self._array.columns.values \n",
    "            print(_act_col_names)\n",
    "            _act_col_names = reformate_col_name(_act_col_names)\n",
    "            _curr_col_name = reformate_col_name(_curr_col_name)\n",
    "            # needed for formatting columns name accordingly\n",
    "            # (otherwise concatenation happen badly)\n",
    "            \n",
    "            \n",
    "            self._array = self._array.rename(columns={k:v for k, v in zip(_curr_col_name, _act_col_names)})\n",
    "            \n",
    "    \n",
    "    def _get_index(self, col_name:Union[str, int])->int:\n",
    "        if isinstance(col_name, str):\n",
    "            col_indx = self._array.columns.values.tolist().index(col_name)\n",
    "        elif isinstance(col_name, int):\n",
    "            col_indx = col_name\n",
    "        return col_indx\n",
    "    \n",
    "    @staticmethod        \n",
    "    def _check_if_valid_args(n_col, col_names):\n",
    "        if isinstance(col_names, (list, tuple)):\n",
    "            if n_col == len(col_names):\n",
    "                raise ValueError(f\"Mismatch: n_col ({n_col}) != len(col_names) ({len(col_names)})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cff3a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformate_col_name(col_names:List[Union[Tuple[str], int]]) -> List[Union[str, int]]:\n",
    "    \"\"\"reformates names of columns contained in list\"\"\"\n",
    "    for i, name in enumerate(col_names):\n",
    "        if isinstance(name, tuple):\n",
    "            col_names[i] = col_names[i][0]\n",
    "    return col_names\n",
    "    \n",
    "\n",
    "def create_multi_view_dataframe(datasets: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    _header_labels = ['views', 'feature_name']\n",
    "    # 1. create multiindex header\n",
    "\n",
    "    _feature_name_array = np.array([])  # store all feature names\n",
    "    _view_name_array = []  # store all views (ie modalities) names\n",
    "\n",
    "    _concatenated_datasets = np.array([])  # store dataframe values\n",
    "\n",
    "    for key in datasets.keys():\n",
    "        #_sub_dataframe_header.append(list(datasets[key].columns.values))\n",
    "        _feature_name_array = np.concatenate([_feature_name_array,\n",
    "                                              datasets[key].columns.values])\n",
    "        if len(_concatenated_datasets) <= 0:\n",
    "            # first pass \n",
    "            _concatenated_datasets = datasets[key].values\n",
    "        else:\n",
    "            # next passes\n",
    "            try:\n",
    "                _concatenated_datasets = np.concatenate(\n",
    "                                        [_concatenated_datasets,\n",
    "                                         datasets[key].to_numpy()\n",
    "                                         ], axis=1)\n",
    "            except ValueError as val_err:\n",
    "                # catching case where nb_samples are differents\n",
    "                raise ValueError(\n",
    "                    'Cannot create multi view dataset: different number of samples for each modality have been detected'\\\n",
    "                        + 'Details: ' + str(val_err)\n",
    "                    )\n",
    "        for _ in datasets[key].columns.values:\n",
    "            _view_name_array.append(key)\n",
    "\n",
    "    _header = pd.MultiIndex.from_arrays([_view_name_array,\n",
    "                                         _feature_name_array],\n",
    "                                        names=_header_labels)\n",
    "\n",
    "\n",
    "    # 2. create multi index dataframe\n",
    "\n",
    "    multi_view_df = pd.DataFrame(_concatenated_datasets,\n",
    "                                  columns = _header)\n",
    "    return multi_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d504dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a',) ('e',) ('i',) ('o',)]\n",
      "[('a',) ('e',) ('i',) ('o',)]\n",
      "[('a',) ('e',) ('i',) ('o',)]\n",
      "[('a',) ('e',) ('i',) ('o',)]\n",
      "[('a',), ('e',), ('i',), ('o',)]\n",
      "     a   e   i   o      0      1      2      3\n",
      "0   78  66  72  53   True  False   True  False\n",
      "1   67  98   1  50   True  False   True   True\n",
      "2    2  70  46  75   True   True  False   True\n",
      "3   26   3   3  69  False  False   True  False\n",
      "4   57  61  78  40  False   True  False  False\n",
      "..  ..  ..  ..  ..    ...    ...    ...    ...\n",
      "95  36  98  30   8  False   True   True  False\n",
      "96  21  21  48  58  False  False   True  False\n",
      "97  53  15   6  77   True  False   True   True\n",
      "98  76  52  33  93   True  False   True  False\n",
      "99  23  16  56  29   True   True  False   True\n",
      "\n",
      "[100 rows x 8 columns]\n",
      "['a', 'e', 'i', 'o', 0, 1, 2, 3]\n",
      "['a', 'e', 'i', 'o', 0, 1, 2, 3, 'time']\n",
      "['a', 'e', 'i', 'o', 0, 1, 2, 3, 'time', 'pressure', 'sp02']\n",
      "     a   e   i   o      0      1      2      3                time  pressure  \\\n",
      "0   78  66  72  53   True  False   True  False 2018-01-01 00:00:00  0.209379   \n",
      "1   67  98   1  50   True  False   True   True 2018-01-01 01:00:00  0.412792   \n",
      "2    2  70  46  75   True   True  False   True 2018-01-01 02:00:00  0.327938   \n",
      "3   26   3   3  69  False  False   True  False 2018-01-01 03:00:00  0.453829   \n",
      "4   57  61  78  40  False   True  False  False 2018-01-01 04:00:00  0.065071   \n",
      "..  ..  ..  ..  ..    ...    ...    ...    ...                 ...       ...   \n",
      "95  36  98  30   8  False   True   True  False 2018-01-04 23:00:00  0.104872   \n",
      "96  21  21  48  58  False  False   True  False 2018-01-05 00:00:00  0.118902   \n",
      "97  53  15   6  77   True  False   True   True 2018-01-05 01:00:00  0.931347   \n",
      "98  76  52  33  93   True  False   True  False 2018-01-05 02:00:00  0.208917   \n",
      "99  23  16  56  29   True   True  False   True 2018-01-05 03:00:00  0.836389   \n",
      "\n",
      "        sp02   a   e   i   o  \n",
      "0   0.450405  20  64  60  49  \n",
      "1   0.596867  70  64  77   1  \n",
      "2   0.703647   8  51  81  39  \n",
      "3   0.435991  41  68  37  87  \n",
      "4   0.654273  86  97  15  50  \n",
      "..       ...  ..  ..  ..  ..  \n",
      "95  0.631425  48  19  46   5  \n",
      "96  0.926244  31  97  50  49  \n",
      "97  0.950124  22  28  10  11  \n",
      "98  0.257587  27  56  11  62  \n",
      "99  0.682497  24  32  24  47  \n",
      "\n",
      "[100 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "tbg = TabularDataGenerator(100)\n",
    "\n",
    "tbg.add_integers_values(4, ['a', 'e', 'i', 'o'])\n",
    "print(tbg._array.columns.to_numpy())\n",
    "print(tbg._array.columns.values)\n",
    "print(tbg._array.columns.values)\n",
    "print(tbg._array.columns.values)\n",
    "tbg.add_boolean_values(4)\n",
    "print(tbg._array)\n",
    "tbg.add_datetime_values(\"2018-01-01\", col_name='time')\n",
    "tbg.add_float_values(2, col_name=['pressure', 'sp02'])\n",
    "tbg.add_integers_values(4, ['a', 'e', 'i', 'o'])\n",
    "\n",
    "print(tbg._array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e10a4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbg._primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a9eb661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_indx 0\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3, 'time']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file1':      a   e   i   o      0      1      2      3                time  pressure  \\\n",
       " 0   78  66  72  53   True  False   True  False 2018-01-01 00:00:00  0.209379   \n",
       " 1   67  98   1  50   True  False   True   True 2018-01-01 01:00:00  0.412792   \n",
       " 2    2  70  46  75   True   True  False   True 2018-01-01 02:00:00  0.327938   \n",
       " 3   26   3   3  69  False  False   True  False 2018-01-01 03:00:00  0.453829   \n",
       " 4   57  61  78  40  False   True  False  False 2018-01-01 04:00:00  0.065071   \n",
       " ..  ..  ..  ..  ..    ...    ...    ...    ...                 ...       ...   \n",
       " 95  36  98  30   8  False   True   True  False 2018-01-04 23:00:00  0.104872   \n",
       " 96  21  21  48  58  False  False   True  False 2018-01-05 00:00:00  0.118902   \n",
       " 97  53  15   6  77   True  False   True   True 2018-01-05 01:00:00  0.931347   \n",
       " 98  76  52  33  93   True  False   True  False 2018-01-05 02:00:00  0.208917   \n",
       " 99  23  16  56  29   True   True  False   True 2018-01-05 03:00:00  0.836389   \n",
       " \n",
       "         sp02   a   e   i   o  \n",
       " 0   0.450405  78  64  60  49  \n",
       " 1   0.596867  67  64  77   1  \n",
       " 2   0.703647   2  51  81  39  \n",
       " 3   0.435991  26  68  37  87  \n",
       " 4   0.654273  57  97  15  50  \n",
       " ..       ...  ..  ..  ..  ..  \n",
       " 95  0.631425  36  19  46   5  \n",
       " 96  0.926244  21  97  50  49  \n",
       " 97  0.950124  53  28  10  11  \n",
       " 98  0.257587  76  56  11  62  \n",
       " 99  0.682497  23  32  24  47  \n",
       " \n",
       " [100 rows x 15 columns],\n",
       " 'file2':         0      1      2      3                time         0   a\n",
       " 0    True   True  False  False 2018-01-01 00:00:00  0.078943  78\n",
       " 1    True  False  False  False 2018-01-01 01:00:00  0.336171  67\n",
       " 2    True  False  False  False 2018-01-01 02:00:00  0.431170   2\n",
       " 3    True   True  False   True 2018-01-01 03:00:00  0.443192  26\n",
       " 4    True   True   True   True 2018-01-01 04:00:00  0.539840  57\n",
       " ..    ...    ...    ...    ...                 ...       ...  ..\n",
       " 95  False   True   True  False 2018-01-04 23:00:00  0.235311  36\n",
       " 96  False   True   True   True 2018-01-05 00:00:00  0.673035  21\n",
       " 97  False  False  False   True 2018-01-05 01:00:00  0.828489  53\n",
       " 98  False   True   True   True 2018-01-05 02:00:00  0.930632  76\n",
       " 99  False  False   True   True 2018-01-05 03:00:00  0.434578  23\n",
       " \n",
       " [100 rows x 7 columns]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbg.set_primary_key('a')\n",
    "tbg.set_view('file1')\n",
    "tbg.add_boolean_values(4)\n",
    "tbg.add_datetime_values(\"2018-01-01\", col_name='time')\n",
    "tbg.add_float_values()\n",
    "tbg.set_view('file2')\n",
    "tbg.get_multi_view_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359e44fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12., 54., 16., 16.],\n",
       "       [60., 96., 88., 44.],\n",
       "       [29., 92., 33., 18.],\n",
       "       [41., 24.,  7., 32.],\n",
       "       [59.,  0.,  6., 82.],\n",
       "       [ 2., 81., 19., 52.],\n",
       "       [25., 49., 75., 23.],\n",
       "       [27., 40., 19., 87.],\n",
       "       [49., 65., 38., 41.],\n",
       "       [28., 93., 36., 79.],\n",
       "       [15., 27., 16., 18.],\n",
       "       [27.,  8., 31., 39.],\n",
       "       [92., 42., 17., 24.],\n",
       "       [ 0., 74., 82., 43.],\n",
       "       [66., 85., 45., 40.],\n",
       "       [12., 10., 22., 52.],\n",
       "       [93., 37., 89., 54.],\n",
       "       [17., 87., 23., 72.],\n",
       "       [35., 92., 50., 26.],\n",
       "       [12., 77., 45., 35.],\n",
       "       [98., 35., 82.,  1.],\n",
       "       [60., 65., 22., 99.],\n",
       "       [91., 33., 17., 78.],\n",
       "       [47., 55., 56., 76.],\n",
       "       [84., 65., 43., 59.],\n",
       "       [81., 33., 43., 60.],\n",
       "       [29., 26., 67., 38.],\n",
       "       [17., 81., 16., 36.],\n",
       "       [29., 43., 25., 76.],\n",
       "       [84., 58., 79., 53.],\n",
       "       [90., 95., 67., 68.],\n",
       "       [30., 78., 89., 95.],\n",
       "       [14., 98., 49., 53.],\n",
       "       [62., 55., 19., 22.],\n",
       "       [47., 45.,  2., 89.],\n",
       "       [94., 67., 72., 62.],\n",
       "       [ 7., 93., 22., 66.],\n",
       "       [16., 80., 97., 44.],\n",
       "       [31., 18., 33., 39.],\n",
       "       [ 9., 22., 65., 81.],\n",
       "       [13.,  9., 80., 58.],\n",
       "       [77., 30., 12., 13.],\n",
       "       [76., 60., 95., 51.],\n",
       "       [89., 62., 49., 57.],\n",
       "       [15.,  4., 56., 15.],\n",
       "       [85.,  8., 54., 53.],\n",
       "       [52., 16., 26., 68.],\n",
       "       [78., 12., 81., 73.],\n",
       "       [74., 66., 38., 95.],\n",
       "       [ 8., 88.,  4., 10.],\n",
       "       [ 5., 72., 67., 86.],\n",
       "       [92., 62.,  4., 29.],\n",
       "       [86., 93., 92., 91.],\n",
       "       [69., 44., 74., 90.],\n",
       "       [34., 22., 10., 34.],\n",
       "       [31., 29., 68., 83.],\n",
       "       [27., 25., 49., 24.],\n",
       "       [71., 13., 32., 74.],\n",
       "       [65., 27., 53., 37.],\n",
       "       [61., 47., 46., 76.],\n",
       "       [66., 50.,  9., 63.],\n",
       "       [42., 91., 25., 91.],\n",
       "       [94., 92., 91., 37.],\n",
       "       [41., 25., 60., 52.],\n",
       "       [50., 51., 87.,  2.],\n",
       "       [31.,  7., 56., 79.],\n",
       "       [89., 48., 23., 60.],\n",
       "       [78., 88., 58.,  6.],\n",
       "       [48., 87., 84., 21.],\n",
       "       [32.,  9., 74., 48.],\n",
       "       [95.,  2., 73., 73.],\n",
       "       [ 4., 37., 73., 14.],\n",
       "       [39., 69., 22., 31.],\n",
       "       [50., 69., 66., 20.],\n",
       "       [65., 74., 66.,  6.],\n",
       "       [47., 76., 16., 71.],\n",
       "       [90., 19., 61., 53.],\n",
       "       [98., 98., 96., 63.],\n",
       "       [30., 36., 16.,  3.],\n",
       "       [21., 93., 45., 20.],\n",
       "       [16., 28., 71.,  6.],\n",
       "       [90., 52., 50., 86.],\n",
       "       [91., 72., 39., 14.],\n",
       "       [10., 58., 65., 71.],\n",
       "       [98., 34., 17., 97.],\n",
       "       [97., 37., 67., 58.],\n",
       "       [51., 57., 71., 30.],\n",
       "       [85., 56., 75., 79.],\n",
       "       [49., 53., 38., 67.],\n",
       "       [22.,  6., 37., 99.],\n",
       "       [34.,  9., 94., 97.],\n",
       "       [79., 72., 22., 77.],\n",
       "       [ 7., 13., 20., 56.],\n",
       "       [36., 37., 85., 38.],\n",
       "       [45., 60., 60., 86.],\n",
       "       [50., 28., 49., 19.],\n",
       "       [74., 61., 74., 56.],\n",
       "       [70., 72., 74., 27.],\n",
       "       [20., 72., 58., 89.],\n",
       "       [63., 92., 96., 93.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array(np.random.randint(0,100,size=(100, 4)), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f3584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
