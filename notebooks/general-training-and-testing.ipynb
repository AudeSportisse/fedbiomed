{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Testing at Each Round of Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an experiment model and parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlan, self).__init__(model_args)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "    'test_ratio': .3,\n",
    "    'test_on_local_updates': True, \n",
    "    'test_on_global_updates': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and run the experiment\n",
    "\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 11:17:51,567 fedbiomed INFO - Component environment:\n",
      "2022-03-25 11:17:51,568 fedbiomed INFO - type = ComponentType.RESEARCHER\n",
      "2022-03-25 11:17:51,832 fedbiomed INFO - Messaging researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98 successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x7fe038d93d90>\n",
      "2022-03-25 11:17:51,843 fedbiomed INFO - Searching dataset with data tags: ['#MNIST', '#dataset'] for all nodes\n",
      "2022-03-25 11:18:01,883 fedbiomed INFO - Node selected for training -> node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "2022-03-25 11:18:01,952 fedbiomed DEBUG - Model file has been saved: /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/my_model_67e28121-bfde-402a-8d84-63a37aaa12df.py\n",
      "2022-03-25 11:18:01,981 fedbiomed DEBUG - upload (HTTP POST request) of file /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/my_model_67e28121-bfde-402a-8d84-63a37aaa12df.py successful, with status code 201\n",
      "2022-03-25 11:18:02,211 fedbiomed DEBUG - upload (HTTP POST request) of file /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_init_a31d28d4-e35c-44e2-988d-c51ee8fb0ea7.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp._reqs._monitor_message_callback is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 11:18:25,615 fedbiomed INFO - Sampled nodes in round 0 ['node_409df974-a78a-4fdd-9f09-eac2963ff402']\n",
      "2022-03-25 11:18:25,617 fedbiomed INFO - Send message to node node_409df974-a78a-4fdd-9f09-eac2963ff402 - {'researcher_id': 'researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98', 'job_id': '4312f385-42b6-42a9-85d2-5ea9c8b50dad', 'training_args': {'test_ratio': 0.3, 'test_on_local_updates': True, 'test_on_global_updates': True, 'test_metric': None, 'test_metric_args': {}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training': True, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/25/my_model_67e28121-bfde-402a-8d84-63a37aaa12df.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/25/aggregated_params_init_a31d28d4-e35c-44e2-988d-c51ee8fb0ea7.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_409df974-a78a-4fdd-9f09-eac2963ff402': ['dataset_2e34efb9-edb8-4467-8bb2-739415ca5352']}}\n",
      "2022-03-25 11:18:25,618 fedbiomed DEBUG - researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98\n",
      "2022-03-25 11:18:25,769 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001bNODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b [1mMESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7f01f4825d90>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:18:34,590 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.093889\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:35,443 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 480/42000 (1%) \n",
      " \t\t\t\t\t Loss: \u001b[1m1.423899\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:36,081 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 960/42000 (2%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.916793\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:36,704 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1440/42000 (3%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.593966\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:37,284 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1920/42000 (5%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.523575\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:38,012 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2400/42000 (6%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.453029\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:38,979 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2880/42000 (7%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.309588\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:39,768 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3360/42000 (8%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.262092\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:40,389 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3840/42000 (9%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.275734\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:40,966 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 4320/42000 (10%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.464746\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:51,469 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.943167\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:18:51,704 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001bNODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b [1mMESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:19:00,662 fedbiomed INFO - Downloading model params after training on node_409df974-a78a-4fdd-9f09-eac2963ff402 - from http://localhost:8844/media/uploads/2022/03/25/node_params_4bd14e3c-b897-4ad1-a1ab-2bace70acb65.pt\n",
      "2022-03-25 11:19:00,688 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_91716f49-cd83-40af-b3db-62a6fac224a0.pt successful, with status code 200\n",
      "2022-03-25 11:19:00,709 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_409df974-a78a-4fdd-9f09-eac2963ff402']\n",
      "2022-03-25 11:19:00,957 fedbiomed DEBUG - upload (HTTP POST request) of file /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_7df4d7ec-84b2-49d2-ad9d-9d33b23268a2.pt successful, with status code 201\n",
      "2022-03-25 11:19:00,958 fedbiomed INFO - Saved aggregated params for round 0 in /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_7df4d7ec-84b2-49d2-ad9d-9d33b23268a2.pt\n",
      "2022-03-25 11:19:00,959 fedbiomed INFO - Sampled nodes in round 1 ['node_409df974-a78a-4fdd-9f09-eac2963ff402']\n",
      "2022-03-25 11:19:00,959 fedbiomed INFO - Send message to node node_409df974-a78a-4fdd-9f09-eac2963ff402 - {'researcher_id': 'researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98', 'job_id': '4312f385-42b6-42a9-85d2-5ea9c8b50dad', 'training_args': {'test_ratio': 0.3, 'test_on_local_updates': True, 'test_on_global_updates': True, 'test_metric': None, 'test_metric_args': {}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training': True, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/25/my_model_67e28121-bfde-402a-8d84-63a37aaa12df.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/25/aggregated_params_7df4d7ec-84b2-49d2-ad9d-9d33b23268a2.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_409df974-a78a-4fdd-9f09-eac2963ff402': ['dataset_2e34efb9-edb8-4467-8bb2-739415ca5352']}}\n",
      "2022-03-25 11:19:00,960 fedbiomed DEBUG - researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98\n",
      "2022-03-25 11:19:01,114 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001bNODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b [1mMESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7f015b00eaf0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:19:09,112 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.942389\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:09,709 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 480/42000 (1%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.726444\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:10,213 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 960/42000 (2%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.216884\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:11,047 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1440/42000 (3%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.298312\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:12,070 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1920/42000 (5%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.075110\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:12,852 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2400/42000 (6%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.124814\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:13,571 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2880/42000 (7%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.287729\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:14,106 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3360/42000 (8%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.469918\u001b[0m \n",
      "\t\t\t\t\t ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 11:19:14,725 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3840/42000 (9%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.273922\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:15,297 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 4320/42000 (10%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.103252\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:25,893 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.964444\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:19:26,094 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001bNODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b [1mMESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:19:36,002 fedbiomed INFO - Downloading model params after training on node_409df974-a78a-4fdd-9f09-eac2963ff402 - from http://localhost:8844/media/uploads/2022/03/25/node_params_33d20765-6e8e-4c3a-aab7-02b166625dc0.pt\n",
      "2022-03-25 11:19:36,051 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_a6578c17-bdf7-4936-b438-dcc85f3d460d.pt successful, with status code 200\n",
      "2022-03-25 11:19:36,061 fedbiomed INFO - Nodes that successfully reply in round 1 ['node_409df974-a78a-4fdd-9f09-eac2963ff402']\n",
      "2022-03-25 11:19:36,251 fedbiomed DEBUG - upload (HTTP POST request) of file /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_431c104b-d9e0-40c1-873e-ee9add0e78ae.pt successful, with status code 201\n",
      "2022-03-25 11:19:36,255 fedbiomed INFO - Saved aggregated params for round 1 in /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_431c104b-d9e0-40c1-873e-ee9add0e78ae.pt\n",
      "2022-03-25 11:19:36,257 fedbiomed INFO - \u001b[1mSending request\u001b[0m to node node_409df974-a78a-4fdd-9f09-eac2963ff402 to perform final testing on aggregated parameters\n",
      "2022-03-25 11:19:36,259 fedbiomed DEBUG - researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98\n",
      "2022-03-25 11:19:36,385 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001bNODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b [1mMESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7f01f34be550>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:19:44,486 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.964333\u001b[0m \n",
      "\t\t\t\t\t ---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 11:25:16,515 fedbiomed DEBUG - Auto increasing total rounds for experiment from 4 to 5\n",
      "2022-03-25 11:25:16,516 fedbiomed INFO - Sampled nodes in round 4 ['node_409df974-a78a-4fdd-9f09-eac2963ff402']\n",
      "2022-03-25 11:25:16,517 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t\u001b[1m Reqeust: \u001b[0m: Perform Training with arguments: {'researcher_id': 'researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98', 'job_id': '4312f385-42b6-42a9-85d2-5ea9c8b50dad', 'training_args': {'test_ratio': 0.3, 'test_on_local_updates': True, 'test_on_global_updates': True, 'test_metric': None, 'test_metric_args': {}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training': True, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/03/25/my_model_67e28121-bfde-402a-8d84-63a37aaa12df.py', 'params_url': 'http://localhost:8844/media/uploads/2022/03/25/aggregated_params_ef9bf12e-16af-45f1-994e-f484f6ccc01e.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_409df974-a78a-4fdd-9f09-eac2963ff402': ['dataset_2e34efb9-edb8-4467-8bb2-739415ca5352']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-03-25 11:25:16,518 fedbiomed DEBUG - researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98\n",
      "2022-03-25 11:25:16,652 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7f01f482f0d0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:25:24,185 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.975778\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:24,763 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 480/42000 (1%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.058382\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:25,269 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 960/42000 (2%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.342349\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:25,765 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1440/42000 (3%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.103566\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:26,913 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1920/42000 (5%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.070835\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:28,425 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2400/42000 (6%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.153539\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:29,881 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2880/42000 (7%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.009683\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:30,798 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3360/42000 (8%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.209673\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:31,459 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3840/42000 (9%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.059740\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:32,363 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 4320/42000 (10%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.025687\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:43,904 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.976500\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-03-25 11:25:44,185 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:25:51,563 fedbiomed INFO - Downloading model params after training on node_409df974-a78a-4fdd-9f09-eac2963ff402 - from http://localhost:8844/media/uploads/2022/03/25/node_params_e68fa162-dc95-406c-b5c8-ca962377931b.pt\n",
      "2022-03-25 11:25:51,585 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_0c8ca679-92ea-4b2d-b91a-4d06dedd8aa1.pt successful, with status code 200\n",
      "2022-03-25 11:25:51,599 fedbiomed INFO - Nodes that successfully reply in round 4 ['node_409df974-a78a-4fdd-9f09-eac2963ff402']\n",
      "2022-03-25 11:25:51,831 fedbiomed DEBUG - upload (HTTP POST request) of file /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_ce6437f3-7434-43ce-87a2-9aa0a005d5e2.pt successful, with status code 201\n",
      "2022-03-25 11:25:51,832 fedbiomed INFO - Saved aggregated params for round 4 in /home/scansiz/Desktop/Inria/development/fedbiomed/var/experiments/Experiment_0014/aggregated_params_ce6437f3-7434-43ce-87a2-9aa0a005d5e2.pt\n",
      "2022-03-25 11:25:51,833 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t\u001b[1m Reqeust: \u001b[0m:Perform final testing on aggregated parameters \n",
      " -----------------------------------------------------------------\n",
      "2022-03-25 11:25:51,834 fedbiomed DEBUG - researcher_9da5c1c0-e6d2-43e5-9191-ce676c5aac98\n",
      "2022-03-25 11:25:51,967 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_409df974-a78a-4fdd-9f09-eac2963ff402\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7f015b00eaf0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "----------------------------------------\n",
      "2022-03-25 11:25:58,792 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL PARAMETERS\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_409df974-a78a-4fdd-9f09-eac2963ff402 \n",
      "\t\t\t\t\t Completed: 18000/18000 (100%) \n",
      " \t\t\t\t\t ACCURACY: \u001b[1m0.978389\u001b[0m \n",
      "\t\t\t\t\t ---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run(rounds=1 , increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run(rounds=8, increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available via `exp.training_replies()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1].data()\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies()[rounds - 1].dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available via `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params().keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params()[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params()[rounds - 1]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feel free to run other sample notebooks or try your own models :D\n",
    "\n",
    "## Testing using your own testing metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlanCM(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlanCM, self).__init__(model_args)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n",
    "\n",
    "    def testing_step(self, data, target):\n",
    "        \n",
    "        output = self.forward(data)\n",
    "        loss1   = torch.nn.functional.nll_loss(output, target)\n",
    "        output = self(data)\n",
    "        loss2   = torch.nn.functional.nll_loss(output, target)\n",
    "        return [loss1, loss2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "    'test_ratio': .3,\n",
    "    'test_on_local_updates': True, \n",
    "    'test_on_global_updates': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlanCM,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
