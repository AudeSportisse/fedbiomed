{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local and Central DP with Fed-BioMed: MONAI 2d image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed the 2d image classification example provided in the project MONAI (https://monai.io/), trained with Differential Privacy (DP). We are going to compare results of:\n",
    "* non private training\n",
    "* train with Local Differential Privacy (LDP)\n",
    "* train with Central Differential Privacy (CDP)\n",
    "\n",
    "In order to enforce differential privacy during training (both local and central) we will rely on the Opcaus library (https://opacus.ai/). \n",
    "\n",
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`\n",
    "\n",
    "## Creating MedNIST nodes\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "To proceed with the tutorial, we created an iid partitioning of the MedNIST dataset between 3 clients. Each client has 3000 image samples for each class. The training partitions are availables at the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1vLIcBdtdAhh6K-vrgCFy_0Y55dxOWZwf/view\n",
    "\n",
    "The dataset owned by each client has structure:\n",
    "\n",
    "\n",
    "└── client_*/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "    \n",
    "    └── BreastMRI/\n",
    "    \n",
    "    └── CXR/\n",
    "    \n",
    "    └── ChestCT/\n",
    "    \n",
    "    └── Hand/\n",
    "    \n",
    "    └── HeadCT/   \n",
    "\n",
    "To create the federated dataset, we follow the standard procedure for node creation/population of Fed-BioMed. \n",
    "After activating the fedbiomed network with the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment network`\n",
    "\n",
    "and \n",
    "\n",
    "`./scripts/fedbiomed_run network`\n",
    "\n",
    "we create a first node by using the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment node`\n",
    "\n",
    "`./scripts/fedbiomed_run node start`\n",
    "\n",
    "We then poulate the node with the data of first client:\n",
    "\n",
    "`./scripts/fedbiomed_run node add`\n",
    "\n",
    "We select option 3 (images) to add MedNIST partition of client 1, by just picking the folder of client 1. \n",
    "Assign tag `mednist` to the data when asked.\n",
    "\n",
    "We can further check that the data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "\n",
    "Following the same procedure, we create the other two nodes with the datasets of client 2 and client 3 respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Fed-BioMed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start the reseracher enviroment with the command `source ./scripts/fedbiomed_environment researcher`, and open the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first quesry the network for the mednist dataset. In this case, the nodes are sharing the respective partitions unsing the same tag `mednist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for network and data loader of the MONAI tutorial can now be deployed in Fed-BioMed.\n",
    "We first import the necessary modules from `fedbiomed` and `monai` libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the training plan, using the standard `TorchTrainingPlan` natively provided in Fed-BioMed. We reuse the `MedNISTDataset` data loader defined in the original MONAI tutorial, which is returned by the method `training_data`, which also implements the data parsing from the nodes `dataset_path`. Following the MONAI tutorial, the model is the `DenseNet121`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'DenseNet121')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"import numpy as np\",\n",
    "                \"import os\",\n",
    "                \"from monai.apps import download_and_extract\",\n",
    "                \"from monai.config import print_config\",\n",
    "                \"from monai.data import decollate_batch\",\n",
    "                \"from monai.metrics import ROCAUCMetric\",\n",
    "                \"from monai.networks.nets import DenseNet121\",\n",
    "                \"from monai.transforms import ( Activations, AddChannel, AsDiscrete, Compose, LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity, EnsureType, )\",\n",
    "                \"from monai.utils import set_determinism\",\n",
    "                \"from opacus.validators import ModuleValidator\"]\n",
    "        self.add_dependency(deps)\n",
    "         \n",
    "        self.num_class =  model_args['num_class']\n",
    "        \n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.model = DenseNet121(spatial_dims=2, in_channels=1,\n",
    "                    out_channels = self.num_class)\n",
    "        \n",
    "        if (('DP' in model_args) and (model_args['DP']==True)):\n",
    "            self.validate_and_fix_model()\n",
    "\n",
    "    def validate_and_fix_model(self):\n",
    "        # Validate and Fix model to be DP-compliant\n",
    "        if not ModuleValidator.is_valid(self.model):\n",
    "            print('######################################## Fixing Model ########################################')\n",
    "            self.model = ModuleValidator.fix(self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    class MedNISTDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, image_files, labels, transforms):\n",
    "                self.image_files = image_files\n",
    "                self.labels = labels\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_files)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return self.transforms(self.image_files[index]), self.labels[index]\n",
    "    \n",
    "    def parse_data(self, path):\n",
    "        print(self.dataset_path)\n",
    "        class_names = sorted(x for x in os.listdir(path)\n",
    "                     if os.path.isdir(os.path.join(path, x)))\n",
    "        num_class = len(class_names)\n",
    "        image_files = [\n",
    "                        [\n",
    "                            os.path.join(path, class_names[i], x)\n",
    "                            for x in os.listdir(os.path.join(path, class_names[i]))\n",
    "                        ]\n",
    "                        for i in range(num_class)\n",
    "                      ]\n",
    "        \n",
    "        return image_files, num_class\n",
    "    \n",
    "    def training_data(self, batch_size = 48):\n",
    "        self.image_files, num_class = self.parse_data(self.dataset_path)\n",
    "        \n",
    "        if self.num_class!=num_class:\n",
    "                raise Exception('number of available classes does not match declared classes')\n",
    "        \n",
    "        num_each = [len(self.image_files[i]) for i in range(self.num_class)]\n",
    "        image_files_list = []\n",
    "        image_class = []\n",
    "        \n",
    "        for i in range(self.num_class):\n",
    "            image_files_list.extend(self.image_files[i])\n",
    "            image_class.extend([i] * num_each[i])\n",
    "        num_total = len(image_class)\n",
    "        \n",
    "        \n",
    "        length = len(image_files_list)\n",
    "        indices = np.arange(length)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        val_split = int(1. * length) \n",
    "        train_indices = indices[:val_split]\n",
    "\n",
    "        train_x = [image_files_list[i] for i in train_indices]\n",
    "        train_y = [image_class[i] for i in train_indices]\n",
    "\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImage(image_only=True),\n",
    "                AddChannel(),\n",
    "                ScaleIntensity(),\n",
    "                RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "                RandFlip(spatial_axis=0, prob=0.5),\n",
    "                RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "                EnsureType(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transforms = Compose(\n",
    "            [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "        y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "        y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])\n",
    "\n",
    "        print(f\"Training count: {len(train_x)}\")\n",
    "\n",
    "        train_ds = self.MedNISTDataset(train_x, train_y, train_transforms)\n",
    "        \n",
    "        return DataManager(dataset=train_ds, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = self.loss_function(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we import the required modules for running any experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-private training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train our model in a non-private way. We set the model and training parameters. In particular, we are going to perform 2 epochs over 3 rounds for this experiment. Moreover the training is performed on ~26% of the locally available training data. We are also trying to use GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {'num_class':6,'use_gpu': True}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 20, \n",
    "    'lr': 1e-5, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum':250 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "tags =  ['mednist']\n",
    "rounds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment can be now defined, by providing the `mednist` tag, and running the local training on nodes with model defined in `model_path`, standard `aggregator` (FedAvg) and `client_selection_strategy` (all nodes used). Federated learning is going to be perfomed through 3 optimization rounds.\n",
    "\n",
    "## WARNING:\n",
    "\n",
    "**For running this experiment, you need a computer with the following specifications:**\n",
    "\n",
    "- more than 16 GB of RAM\n",
    "- 2.5 GHz processor or higher, with at least 4 cores\n",
    "\n",
    "\n",
    "\n",
    "If your computer specification are lower, you can reduce the number of data passed when training model (set `batchnum` from 250 to 25) and the number of `rounds` (from 3 to 1) but model performances may decrease dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with LDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to repeat the same training but with private SGD: at each epoch gradients are clipped and perturbed according to the privacy parameters we are going to define in the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensioning the training parameters for LDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "\n",
    "req = Requests()\n",
    "xx = req.list()\n",
    "min_dataset_size = min([xx[i][0]['shape'][0] for i in xx])\n",
    "tot_dataset_size = sum([xx[i][0]['shape'][0] for i in xx])\n",
    "q = training_args['batch_size']/min_dataset_size\n",
    "\n",
    "sigma = 1.\n",
    "clip = 1.\n",
    "delta = .1/tot_dataset_size\n",
    "max_epsilon = 1\n",
    "max_N = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.privacy.rdp_accountant import get_iterations\n",
    "\n",
    "N, eps_list = get_iterations(delta, sigma, q, max_epsilon, max_N)\n",
    "\n",
    "max_epochs = int(N*training_args['batch_size']/min_dataset_size)\n",
    "\n",
    "assert training_args['epochs']<=max_epochs, 'Number of epochs not compatible with privacy budget'\n",
    "print(f'The maximal number of allowed epochs for LDP training is {max_epochs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update training parameters for LDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDP = {'DP_args': {'type' : 'local', 'sigma': sigma, 'clip': clip}}\n",
    "training_args.update(LDP)\n",
    "model_args.update(DP=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and run the LDP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_LDP = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_LDP.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with CDP\n",
    "\n",
    "## Dimensioning the training parameters for CDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = len([xx[i][0]['shape'][0] for i in xx])\n",
    "\n",
    "q = 1 ## All clients are selected\n",
    "sigma = 1.\n",
    "clip = 1.\n",
    "delta = .1/num_clients\n",
    "max_epsilon = 20\n",
    "max_N = int(50)\n",
    "\n",
    "max_rounds, eps_list = get_iterations(delta, sigma, q, max_epsilon, max_N)\n",
    "\n",
    "assert rounds<=max_rounds, 'Number of rounds not compatible with privacy budget'\n",
    "\n",
    "print(f'The maximal number of allowed rounds for CDP training is {max_rounds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update training parameters for CDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDP = {'DP_args': {'type' : 'central', 'sigma': sigma, 'clip': clip}}\n",
    "training_args.update(CDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and run the CDP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_CDP = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_CDP.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to test and compare locally the three final federated models on an independent testing partition.\n",
    "The test dataset is available at this link:\n",
    "\n",
    "https://drive.google.com/file/d/1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "import zipfile\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the testing dataset on the local temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "from fedbiomed.researcher.environ import environ\n",
    "\n",
    "tmp_dir = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+os.sep)\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD\"\n",
    "base_dir = tmp_dir.name\n",
    "test_file = os.path.join(base_dir, \"MedNIST_testing.zip\")\n",
    "\n",
    "gdown.download(resource, test_file, quiet=False)\n",
    "\n",
    "zf = zipfile.ZipFile(test_file)\n",
    "\n",
    "for file in zf.infolist():\n",
    "    zf.extract(file, base_dir)\n",
    "    \n",
    "data_dir = os.path.join(base_dir, \"MedNIST_testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data and create the testing data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir)\n",
    "                     if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "test_split = int(0.1 * length)\n",
    "test_indices = indices[:test_split]\n",
    "\n",
    "test_x = [image_files_list[i] for i in test_indices]\n",
    "test_y = [image_class[i] for i in test_indices]\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define testing metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the federated models we need to create model instances and assign to it the models parameters estimated at the last federated optimization rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non private training\n",
    "model = exp.model_instance()\n",
    "model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])\n",
    "\n",
    "# training with LDP\n",
    "model_LDP = exp_LDP.model_instance()\n",
    "model_LDP.load_state_dict(exp_LDP.aggregated_params()[rounds - 1]['params'])\n",
    "\n",
    "# training with CDP\n",
    "model_CDP = exp_CDP.model_instance()\n",
    "model_CDP.load_state_dict(exp_CDP.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the testing performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_LDP = []\n",
    "y_pred_CDP = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0],\n",
    "            test_data[1],\n",
    "        )\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        pred_LDP = model_LDP(test_images).argmax(dim=1)\n",
    "        pred_CDP = model_CDP(test_images).argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "            y_pred_LDP.append(pred_LDP[i].item())\n",
    "            y_pred_CDP.append(pred_CDP[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---> Results for non-private training')\n",
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "print('---> Results for training with LDP')\n",
    "print(classification_report(\n",
    "    y_true, y_pred_LDP, target_names=class_names, digits=4))\n",
    "\n",
    "print('---> Results for training with CDP')\n",
    "print(classification_report(\n",
    "    y_true, y_pred_CDP, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spite of the relatively small training performed on the data shared in the 3 nodes, the performance of the federated model seems pretty good. Well done! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
