{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43afa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Loading data from csv files\n",
    "#Excel data files\n",
    "def load_data(data_set):\n",
    "    try:\n",
    "        excel = ['.xls','.xlsx']\n",
    "        if '.csv' in data_set:\n",
    "            d1 = pd.read_csv(data_set,delimiter=';',header=0)\n",
    "            print('CSV file loaded')\n",
    "            print(d1.head())\n",
    "        elif any(x in data_set for x in excel): \n",
    "            d1 = pd.read_excel(data_set,index_col=0)\n",
    "            print('Excel file loaded')\n",
    "            print(d1.head())\n",
    "        return d1\n",
    "    except:\n",
    "        print('Error encountered in loading data file')\n",
    "    \n",
    "#Missing values \n",
    "\n",
    "#Impute missing values with mean for Qualitative Data\n",
    "\n",
    "def impute_missing_value_mean(data):\n",
    "    try:\n",
    "        for col in data.columns:\n",
    "            if (data[col].isnull().sum()>0):\n",
    "                if any(data[col].dtype in x2 for x2 in  [x.value for x in QuantitativeDataType]):\n",
    "                    data[col].fillna(value=data[col].mean(),inplace=True)\n",
    "        return data\n",
    "    except:\n",
    "        print('Error encountered in imputing missing values - mean')\n",
    "    \n",
    "#Categorical Data\n",
    "def impute_missing_values_mode(data):\n",
    "    try:\n",
    "        for col in data.columns:\n",
    "            if (data[col].isnull().sum()>0):\n",
    "                if any(data[col].dtype in x2 for x2 in  [x.value for x in CategoricalDataType]):\n",
    "                    print(col)\n",
    "                    data[col].fillna(value=data[col].mode()[0],inplace=True)\n",
    "        return data\n",
    "    except:\n",
    "         print('Error encountered in imputing missing values - mode')\n",
    "       \n",
    "\n",
    "\n",
    "    # Impute missing values with KNN            \n",
    "\n",
    "def impute_missing_value_knn(data):\n",
    "    try:\n",
    "        missing_cols = data.columns[data.isnull().any()]\n",
    "        if len(missing_cols)>0:\n",
    "                imputer =KNNImputer(n_neighbors=2)\n",
    "                data = pd.DataFrame(imputer.fit_transform(data),columns=data.columns) \n",
    "\n",
    "        return data  \n",
    "    except:\n",
    "         print('Error encountered in imputing missing values - knn')\n",
    "\n",
    "#Impute missing values with Interpolate\n",
    "def impute_missing_values_interpolate(data):\n",
    "    try:   \n",
    "        data_filled = data.interpolate()\n",
    "        return data_filled\n",
    "    except:\n",
    "         print('Error encountered in imputing missing values - interpolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc29aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import enum\n",
    "from enum import Enum, auto\n",
    "\n",
    "# the use of Enum classes will prevent incorrect combination of values\n",
    "class QuantitativeDataType(Enum):\n",
    "    CONTINUOUS = [float, np.float64]\n",
    "    DISCRETE = [int]\n",
    "\n",
    "class CategoricalDataType(Enum):\n",
    "    BOOLEAN = [bool]\n",
    "    NUMERICAL = [float, int, np.float64, np.int64]\n",
    "    CHARACTER = [str, object]\n",
    "    \n",
    "class DataType(Enum):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    QUANTITATIVE = [QuantitativeDataType.CONTINUOUS,\n",
    "                   QuantitativeDataType.DISCRETE]\n",
    "    CATEGORICAL = [CategoricalDataType.BOOLEAN,\n",
    "                  CategoricalDataType.NUMERICAL,\n",
    "                  CategoricalDataType.CHARACTER]\n",
    "    #MISSING = 'MISSING'\n",
    "    DATETIME = 'DATETIME'\n",
    "    UNKNOWN = 'UNKNOWN'\n",
    "    \n",
    "def CustomWarning(level,message):\n",
    "        logger = logging.getLogger('mylogger')\n",
    "        logger.setLevel(level)\n",
    "\n",
    "        handler = logging.FileHandler('mylog.log')\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "        if level == 'CRITICAL':\n",
    "            logger.critical(message)\n",
    "        elif level == 'WARNING':\n",
    "            logger.warning(message)\n",
    "        elif level == 'ERROR':\n",
    "            logger.error(message)\n",
    "        elif level == 'DEBUG':\n",
    "            logger.debug(message)\n",
    "        else:\n",
    "            logger.info(message)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "888775c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1 = load_data('C:\\\\Users\\\\p.santosha.dasari\\\\Desktop\\\\Feature164\\\\pseudo_adni_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ffa9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(data_set):\n",
    "    try:\n",
    "        excel = ['.xls','.xlsx']\n",
    "        if '.csv' in data_set:\n",
    "            d1 = pd.read_csv(data_set,delimiter=';',header=0)\n",
    "            print('CSV file loaded')\n",
    "            print(d1.head())\n",
    "        elif any(x in data_set for x in excel): \n",
    "            d1 = pd.read_excel(data_set,index_col=0)\n",
    "            print('Excel file loaded')\n",
    "            print(d1.head())\n",
    "        return d1\n",
    "    except:\n",
    "        print('Exception encountered in loading data file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b6bc081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDRSB.bl               0\n",
       "ADAS11.bl              1\n",
       "MMSE.bl                0\n",
       "RAVLT.immediate.bl     1\n",
       "RAVLT.learning.bl      0\n",
       "RAVLT.forgetting.bl    0\n",
       "FAQ.bl                 0\n",
       "WholeBrain.bl          0\n",
       "Ventricles.bl          0\n",
       "Hippocampus.bl         0\n",
       "MidTemp.bl             0\n",
       "Entorhinal.bl          0\n",
       "ABETA.MEDIAN.bl        0\n",
       "PTAU.MEDIAN.bl         0\n",
       "TAU.MEDIAN.bl          0\n",
       "AGE                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33cec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled = impute_missing_value_knn(csv_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccb9f67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDRSB.bl               0\n",
       "ADAS11.bl              0\n",
       "MMSE.bl                0\n",
       "RAVLT.immediate.bl     0\n",
       "RAVLT.learning.bl      0\n",
       "RAVLT.forgetting.bl    0\n",
       "FAQ.bl                 0\n",
       "WholeBrain.bl          0\n",
       "Ventricles.bl          0\n",
       "Hippocampus.bl         0\n",
       "MidTemp.bl             0\n",
       "Entorhinal.bl          0\n",
       "ABETA.MEDIAN.bl        0\n",
       "PTAU.MEDIAN.bl         0\n",
       "TAU.MEDIAN.bl          0\n",
       "AGE                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580a407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if missing values exceed threshold limit(50%)\n",
    "def check_missing_value_limit(data,percent):\n",
    "    MIN_NB_MISSING_DATA = ceil((percent/100)*data.shape[0])\n",
    "    for col in data.columns:\n",
    "        if (data[col].isnull().sum()>MIN_NB_MISSING_DATA):\n",
    "            CustomWarning('CRITICAL',f'Missing value for column {col} exceeds threshold limit {MIN_NB_MISSING_DATA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588043fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking samples limit\n",
    "\n",
    "def check_number_of_samples(data,MIN_NB_SAMPLES):\n",
    "    \n",
    "    sample_count = data.shape[0]\n",
    "    if sample_count> MIN_NB_SAMPLES:\n",
    "        CustomWarning('CRITICAL',f'Samples count exceeds the threshold limit {MIN_NB_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcff71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
