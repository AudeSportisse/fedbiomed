{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43afa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#Loading data from csv files\n",
    "#Excel data files\n",
    "def load_data(data_set):\n",
    "    try:\n",
    "        excel = ['.xls','.xlsx']\n",
    "        if '.csv' in data_set:\n",
    "            d1 = pd.read_csv(data_set,delimiter=',',header=0)\n",
    "            print('CSV file loaded')\n",
    "            print(d1.head())\n",
    "        elif any(x in data_set for x in excel): \n",
    "            d1 = pd.read_excel(data_set,index_col=None)\n",
    "            print('Excel file loaded')\n",
    "            print(d1.head())\n",
    "        return d1\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print('Error encountered in loading data file')\n",
    "\n",
    "    \n",
    "#Missing values \n",
    "\n",
    "#Impute missing values with mean for Qualitative Data\n",
    "\n",
    "def impute_missing_values_mean(data):\n",
    "    try:\n",
    "        if type(data) == pd.core.frame.DataFrame:\n",
    "            for col in data.columns:\n",
    "                if (data[col].isnull().sum()>0):\n",
    "                    if any(data[col].dtype in x2 for x2 in  [x.value for x in QuantitativeDataType]):\n",
    "                        data[col].fillna(value=data[col].mean(),inplace=True)\n",
    "        else:\n",
    "            data = data.fillna(data.mean())\n",
    "        return data\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print('Error encountered in loading data file')\n",
    "\n",
    " \n",
    " #Categorical Data\n",
    "def impute_missing_values_mode(data):\n",
    "    try:\n",
    "        if type(data) == pd.core.frame.DataFrame:\n",
    "            for col in data.columns:\n",
    "                if (data[col].isnull().sum()>0):\n",
    "                    if any(data[col].dtype in x2 for x2 in  [x.value for x in CategoricalDataType]):\n",
    "                        print(col)\n",
    "                        data[col].fillna(value=data[col].mode()[0],inplace=True)\n",
    "                        \n",
    "        else:\n",
    "            data = data.fillna(data.value_counts().index[0])\n",
    "            \n",
    "        return data\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print('Error encountered in imputing missing values - mode')\n",
    "       \n",
    "\n",
    "\n",
    "    # Impute missing values with KNN            \n",
    "\n",
    "def impute_missing_values_knn(data,k=2):\n",
    "    try:\n",
    "        if type(data) == pd.core.frame.DataFrame:\n",
    "            missing_cols = data.columns[data.isnull().any()]\n",
    "            if len(missing_cols)>0:\n",
    "                    imputer =KNNImputer(n_neighbors=k)\n",
    "                    data = pd.DataFrame(imputer.fit_transform(data),columns=data.columns) \n",
    "        else:\n",
    "            imputer =KNNImputer(n_neighbors=k)\n",
    "            data =pd.DataFrame( (imputer.fit_transform(np.array(data).reshape(1,-1))).reshape(-1,1),columns=[data.name])                    \n",
    "\n",
    "        return data  \n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print('Error encountered in imputing missing values - knn')\n",
    "\n",
    "#Impute missing values with Interpolate\n",
    "def impute_missing_values_interpolate(data):\n",
    "    try:\n",
    "        data_filled = data.interpolate()\n",
    "            \n",
    "        return data_filled\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print('Error encountered in imputing missing values - interpolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import enum\n",
    "from enum import Enum, auto\n",
    "import logging\n",
    "\n",
    "# the use of Enum classes will prevent incorrect combination of values\n",
    "class QuantitativeDataType(Enum):\n",
    "    CONTINUOUS = [float, np.float64]\n",
    "    DISCRETE = [int]\n",
    "\n",
    "class CategoricalDataType(Enum):\n",
    "    BOOLEAN = [bool]\n",
    "    NUMERICAL = [float, int, np.float64, np.int64]\n",
    "    CHARACTER = [str, object]\n",
    "    \n",
    "class DataType(Enum):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    QUANTITATIVE = [QuantitativeDataType.CONTINUOUS,\n",
    "                   QuantitativeDataType.DISCRETE]\n",
    "    CATEGORICAL = [CategoricalDataType.BOOLEAN,\n",
    "                  CategoricalDataType.NUMERICAL,\n",
    "                  CategoricalDataType.CHARACTER]\n",
    "    #MISSING = 'MISSING'\n",
    "    DATETIME = 'DATETIME'\n",
    "    UNKNOWN = 'UNKNOWN'\n",
    "    \n",
    "class CustomWarning:\n",
    "    \n",
    "        def __init__(self, level, message):\n",
    "            self.level = level\n",
    "            self.message = message\n",
    "\n",
    "            logger = logging.getLogger('mylogger')\n",
    "            logger.setLevel(level)\n",
    "\n",
    "            handler = logging.FileHandler('mylog.log')\n",
    "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            logger.addHandler(handler)\n",
    "\n",
    "         \n",
    "            if self.level == 'CRITICAL':\n",
    "                logger.critical(self.message)\n",
    "            elif self.level == 'WARNING':\n",
    "                logger.warning(self.message)\n",
    "            elif self.level == 'ERROR':\n",
    "                logger.error(self.message)\n",
    "            elif self.level == 'DEBUG':\n",
    "                logger.debug(self.message)\n",
    "            else:\n",
    "                logger.info(self.message)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888775c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1 = load_data('C:\\\\Users\\\\p.santosha.dasari\\\\Desktop\\\\Feature164\\\\pseudo_adni_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import FileHandler\n",
    "\n",
    "# note, this will create a new logger if the name doesn't exist, \n",
    "# which will have no handlers attached (yet)\n",
    "logger = logging.getLogger('mylogger')\n",
    "\n",
    "for h in logger.handlers:\n",
    "    # check the handler is a file handler \n",
    "    # (rotating handler etc. inherit from this, so it will still work)\n",
    "    # stream handlers write to stderr, so their filename is not useful to us\n",
    "    if isinstance(h, FileHandler):\n",
    "        # h.stream should be an open file handle, it's name is the path\n",
    "        print(h.stream.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffa9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(data_set):\n",
    "    try:\n",
    "        excel = ['.xls','.xlsx']\n",
    "        if '.csv' in data_set:\n",
    "            d1 = pd.read_csv(data_set,delimiter=';',header=0)\n",
    "            print('CSV file loaded')\n",
    "            print(d1.head())\n",
    "        elif any(x in data_set for x in excel): \n",
    "            d1 = pd.read_excel(data_set,index_col=0)\n",
    "            print('Excel file loaded')\n",
    "            print(d1.head())\n",
    "        return d1\n",
    "    except:\n",
    "        print('Exception encountered in loading data file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6bc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled = impute_missing_value_knn(csv_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math #Checking if missing values exceed threshold limit(50%)\n",
    "def check_missing_values_limit(data,percent):\n",
    "    MIN_NB_MISSING_DATA = math.ceil((percent/100)*data.shape[0])\n",
    "    for col in data.columns:\n",
    "        if (data[col].isnull().sum()>MIN_NB_MISSING_DATA):\n",
    "            CustomWarning('CRITICAL',f'Missing value for column {col} exceeds threshold limit {MIN_NB_MISSING_DATA}')\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588043fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking samples limit\n",
    "\n",
    "def check_number_of_samples(data,MIN_NB_SAMPLES):\n",
    "    \n",
    "    sample_count = data.shape[0]\n",
    "    if sample_count> MIN_NB_SAMPLES:\n",
    "        CustomWarning('CRITICAL',f'Samples count exceeds the threshold limit {MIN_NB_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = load_data('C:\\\\Users\\\\p.santosha.dasari\\\\Desktop\\\\Feature164\\\\Exceltest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing_value_limit(data1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d10 = load_data('C:\\\\Users\\\\p.santosha.dasari\\\\Desktop\\\\Feature164\\\\file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = load_data('/mnt/c/Users/p.santosha.dasari/Desktop/Feature164/testdata.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac644939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
