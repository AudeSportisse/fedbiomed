{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated 2d image classification with MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed the 2d image classification example provided in the project MONAI (https://monai.io/):\n",
    "\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/2d_classification/mednist_tutorial.ipynb\n",
    "\n",
    "Being MONAI based on PyTorch, the deployment within Fed-BioMed follows seamlessy the same general structure of general PyTorch models. \n",
    "\n",
    "Following the MONAI example, this tutorial is based on the MedNIST dataset.\n",
    "\n",
    "## Creating MedNIST nodes\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "To proceed with the tutorial, we created an iid partitioning of the MedNIST dataset between 3 clients. Each client has 3000 image samples for each class. The training partitions are availables at the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1vLIcBdtdAhh6K-vrgCFy_0Y55dxOWZwf/view\n",
    "\n",
    "The dataset owned by each client has structure:\n",
    "\n",
    "\n",
    "└── client_*/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "    \n",
    "    └── BreastMRI/\n",
    "    \n",
    "    └── CXR/\n",
    "    \n",
    "    └── ChestCT/\n",
    "    \n",
    "    └── Hand/\n",
    "    \n",
    "    └── HeadCT/   \n",
    "\n",
    "To create the federated dataset, we follow the standard procedure for node creation/population of Fed-BioMed. \n",
    "After activating the fedbiomed network with the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment network`\n",
    "\n",
    "and \n",
    "\n",
    "`./scripts/fedbiomed_run network`\n",
    "\n",
    "we create a first node by using the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment node`\n",
    "\n",
    "`./scripts/fedbiomed_run node start`\n",
    "\n",
    "We then poulate the node with the data of first client:\n",
    "\n",
    "`./scripts/fedbiomed_run node add`\n",
    "\n",
    "We select option 3 (images) to add MedNIST partition of client 1, by just picking the folder of client 1. \n",
    "Assign tag `mednist` to the data when asked.\n",
    "\n",
    "We can further check that the data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "\n",
    "Following the same procedure, we create the other two nodes with the datasets of client 2 and client 3 respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Fed-BioMed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start the reseracher enviroment with the command `source ./scripts/fedbiomed_environment researcher`, and open the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first quesry the network for the mednist dataset. In this case, the nodes are sharing the respective partitions unsing the same tag `mednist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 16:41:21,614 fedbiomed INFO - Component environment:\n",
      "2022-01-07 16:41:21,615 fedbiomed INFO - - type = ComponentType.RESEARCHER\n",
      "2022-01-07 16:41:22,093 fedbiomed INFO - Messaging researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x113694460>\n",
      "2022-01-07 16:41:22,194 fedbiomed INFO - Listing available datasets in all nodes... \n",
      "2022-01-07 16:41:22,204 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / DEBUG - Message received: {'researcher_id': 'researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a', 'command': 'list'}\n",
      "2022-01-07 16:41:27,265 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3000/18000 (17%)]\tLoss: 0.211852\n",
      "2022-01-07 16:41:32,198 fedbiomed INFO - \n",
      " Node: node_0310a754-697c-4fef-8f0e-231f3705598d | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] | bla           | [18000, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_0310a754-697c-4fef-8f0e-231f3705598d': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': 'bla',\n",
       "   'shape': [18000, 3, 64, 64]}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for network and data loader of the MONAI tutorial can now be deployed in Fed-BioMed.\n",
    "We first import the necessary modules from `fedbiomed` and `monai` libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+os.sep)\n",
    "model_file = os.path.join(tmp_dir_model.name, 'class_export_mednist.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the training plan. Note that we can simply use the standard `TorchTrainingPlan` natively provided in Fed-BioMed. We reuse the `MedNISTDataset` data loader defined in the original MONAI tutorial, which is returned by the method `training_data`, which also implements the data parsing from the nodes `dataset_path`. Following the MONAI tutorial, the model is the `DenseNet121`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /Users/mlorenzi/works/temp/fedbiomed/var/tmp/tmpggemflyh/class_export_mednist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'DenseNet121')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, kwargs):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"import numpy as np\",\n",
    "                \"import os\",\n",
    "                \"from torch.utils.data import DataLoader\",\n",
    "                \"from monai.apps import download_and_extract\",\n",
    "                \"from monai.config import print_config\",\n",
    "                \"from monai.data import decollate_batch\",\n",
    "                \"from monai.metrics import ROCAUCMetric\",\n",
    "                \"from monai.networks.nets import DenseNet121\",\n",
    "                \"from monai.transforms import ( Activations, AddChannel, AsDiscrete, Compose, LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity, EnsureType, )\",\n",
    "                \"from monai.utils import set_determinism\",]\n",
    "        self.add_dependency(deps)\n",
    "         \n",
    "        self.num_class =  kwargs['num_class']\n",
    "        \n",
    "        self.model = DenseNet121(spatial_dims=2, in_channels=1,\n",
    "                    out_channels = self.num_class)\n",
    "        \n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    class MedNISTDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, image_files, labels, transforms):\n",
    "                self.image_files = image_files\n",
    "                self.labels = labels\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_files)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return self.transforms(self.image_files[index]), self.labels[index]\n",
    "    \n",
    "    def parse_data(self, path):\n",
    "        print(self.dataset_path)\n",
    "        class_names = sorted(x for x in os.listdir(path)\n",
    "                     if os.path.isdir(os.path.join(path, x)))\n",
    "        num_class = len(class_names)\n",
    "        image_files = [\n",
    "                        [\n",
    "                            os.path.join(path, class_names[i], x)\n",
    "                            for x in os.listdir(os.path.join(path, class_names[i]))\n",
    "                        ]\n",
    "                        for i in range(num_class)\n",
    "                      ]\n",
    "        \n",
    "        return image_files, num_class\n",
    "    \n",
    "    def training_data(self, batch_size = 48):\n",
    "        self.image_files, num_class = self.parse_data(self.dataset_path)\n",
    "        \n",
    "        if self.num_class!=num_class:\n",
    "                raise Exception('number of available classes does not match declared classes')\n",
    "        \n",
    "        num_each = [len(self.image_files[i]) for i in range(self.num_class)]\n",
    "        image_files_list = []\n",
    "        image_class = []\n",
    "        \n",
    "        for i in range(self.num_class):\n",
    "            image_files_list.extend(self.image_files[i])\n",
    "            image_class.extend([i] * num_each[i])\n",
    "        num_total = len(image_class)\n",
    "        \n",
    "        \n",
    "        length = len(image_files_list)\n",
    "        indices = np.arange(length)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        val_split = int(1. * length) \n",
    "        train_indices = indices[:val_split]\n",
    "\n",
    "        train_x = [image_files_list[i] for i in train_indices]\n",
    "        train_y = [image_class[i] for i in train_indices]\n",
    "\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImage(image_only=True),\n",
    "                AddChannel(),\n",
    "                ScaleIntensity(),\n",
    "                RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "                RandFlip(spatial_axis=0, prob=0.5),\n",
    "                RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "                EnsureType(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transforms = Compose(\n",
    "            [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "        y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "        y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])\n",
    "\n",
    "        print(\n",
    "            f\"Training count: {len(train_x)}\")\n",
    "        \n",
    "        \n",
    "        train_ds = self.MedNISTDataset(train_x, train_y, train_transforms)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_ds, batch_size, shuffle=True)\n",
    "        \n",
    "        return train_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = self.loss_function(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the model and training parameters. Note that we use only 1 epoch for this experiment, and perform the training on ~26% of the locally available training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {'num_class':6,}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 20, \n",
    "    'lr': 1e-5, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum':250 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment can be now defined, by providing the `mednist` tag, and running the local training on nodes with model defined in `model_path`, standard `aggregator` (FedAvg) and `client_selection_strategy` (all nodes used). Federated learning is going to be perfomed through 3 optimization rounds.\n",
    "\n",
    "## WARNING:\n",
    "\n",
    "**For running this experiment, you need a computer with the following specifications:**\n",
    "\n",
    "- more than 16 GB of RAM\n",
    "- 2.5 GHz processor or higher, with at least 4 cores\n",
    "\n",
    "\n",
    "\n",
    "If your computer specification are lower, you can reduce the number of data passed when training model (set `batchnum` from 250 to 25) and the number of `rounds` (from 3 to 1) but model performances may decrease dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 16:41:35,021 fedbiomed INFO - Searching dataset with data tags: ['mednist'] for all nodes\n",
      "2022-01-07 16:41:35,028 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / DEBUG - Message received: {'researcher_id': 'researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a', 'tags': ['mednist'], 'command': 'search'}\n",
      "2022-01-07 16:41:37,849 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3200/18000 (18%)]\tLoss: 0.279123\n",
      "2022-01-07 16:41:45,024 fedbiomed INFO - Node selected for training -> node_0310a754-697c-4fef-8f0e-231f3705598d\n",
      "2022-01-07 16:41:45,191 fedbiomed DEBUG - torchnn saved model filename: /Users/mlorenzi/works/temp/fedbiomed/var/experiments/Experiment_0002/my_model_15d97680-412a-490e-8fd5-5616564263eb.py\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['mednist']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='MyTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 16:41:47,674 fedbiomed INFO - Sampled nodes in round 0 ['node_0310a754-697c-4fef-8f0e-231f3705598d']\n",
      "2022-01-07 16:41:47,676 fedbiomed INFO - Send message to node node_0310a754-697c-4fef-8f0e-231f3705598d - {'researcher_id': 'researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a', 'job_id': 'f6ec7eff-7acd-4866-ae7f-45531c92048a', 'training_args': {'batch_size': 20, 'lr': 1e-05, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/01/07/my_model_15d97680-412a-490e-8fd5-5616564263eb.py', 'params_url': 'http://localhost:8844/media/uploads/2022/01/07/aggregated_params_init_a3db9df3-05c9-4965-922f-cb17ac7ec45b.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_0310a754-697c-4fef-8f0e-231f3705598d': ['dataset_167c6b19-86d4-4dba-bdcd-7fc0a172d2a0']}}\n",
      "2022-01-07 16:41:47,677 fedbiomed DEBUG - researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a\n",
      "2022-01-07 16:41:47,686 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / DEBUG - Message received: {'researcher_id': 'researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a', 'job_id': 'f6ec7eff-7acd-4866-ae7f-45531c92048a', 'training_args': {'batch_size': 20, 'lr': 1e-05, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 250}, 'model_args': {'num_class': 6}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/01/07/my_model_15d97680-412a-490e-8fd5-5616564263eb.py', 'params_url': 'http://localhost:8844/media/uploads/2022/01/07/aggregated_params_init_a3db9df3-05c9-4965-922f-cb17ac7ec45b.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_0310a754-697c-4fef-8f0e-231f3705598d': ['dataset_167c6b19-86d4-4dba-bdcd-7fc0a172d2a0']}}\n",
      "2022-01-07 16:41:48,901 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3400/18000 (19%)]\tLoss: 0.189949\n",
      "2022-01-07 16:41:59,158 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3600/18000 (20%)]\tLoss: 0.368838\n",
      "2022-01-07 16:42:09,410 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3800/18000 (21%)]\tLoss: 0.163856\n",
      "2022-01-07 16:42:19,769 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [4000/18000 (22%)]\tLoss: 0.321131\n",
      "2022-01-07 16:42:30,522 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [4200/18000 (23%)]\tLoss: 0.597106\n",
      "2022-01-07 16:42:40,847 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [4400/18000 (24%)]\tLoss: 0.190892\n",
      "2022-01-07 16:42:51,155 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [4600/18000 (26%)]\tLoss: 0.442727\n",
      "2022-01-07 16:43:01,433 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [4800/18000 (27%)]\tLoss: 0.255820\n",
      "2022-01-07 16:43:11,736 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / DEBUG - Reached 250 batches for this epoch, ignore remaining data\n",
      "2022-01-07 16:43:13,682 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - results uploaded successfully \n",
      "2022-01-07 16:43:13,688 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / DEBUG - [TASKS QUEUE] Item:{'researcher_id': 'researcher_6b8e05d8-c27a-4866-98fa-2e04b1fd5d1a', 'job_id': 'f6ec7eff-7acd-4866-ae7f-45531c92048a', 'params_url': 'http://localhost:8844/media/uploads/2022/01/07/aggregated_params_init_a3db9df3-05c9-4965-922f-cb17ac7ec45b.pt', 'training_args': {'batch_size': 20, 'lr': 1e-05, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 250}, 'training_data': {'node_0310a754-697c-4fef-8f0e-231f3705598d': ['dataset_167c6b19-86d4-4dba-bdcd-7fc0a172d2a0']}, 'model_args': {'num_class': 6}, 'model_url': 'http://localhost:8844/media/uploads/2022/01/07/my_model_15d97680-412a-490e-8fd5-5616564263eb.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2022-01-07 16:43:14,683 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x14910ae50>, 'batch_size': 20, 'lr': 1e-05, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 250}\n",
      "2022-01-07 16:43:14,683 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / DEBUG - Dataset_path/Users/mlorenzi/works/temp/MedNIST/client_1\n",
      "2022-01-07 16:43:15,824 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [0/18000 (0%)]\tLoss: 1.755910\n",
      "2022-01-07 16:43:26,454 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [200/18000 (1%)]\tLoss: 1.688567\n",
      "2022-01-07 16:43:37,016 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [400/18000 (2%)]\tLoss: 1.499942\n",
      "2022-01-07 16:43:47,337 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [600/18000 (3%)]\tLoss: 1.413267\n",
      "2022-01-07 16:43:57,645 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [800/18000 (4%)]\tLoss: 1.281089\n",
      "2022-01-07 16:44:08,073 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [1000/18000 (6%)]\tLoss: 1.331107\n",
      "2022-01-07 16:44:18,458 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [1200/18000 (7%)]\tLoss: 1.213640\n",
      "2022-01-07 16:44:28,809 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [1400/18000 (8%)]\tLoss: 1.133041\n",
      "2022-01-07 16:44:39,439 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [1600/18000 (9%)]\tLoss: 0.961536\n",
      "2022-01-07 16:44:49,714 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [1800/18000 (10%)]\tLoss: 1.002729\n",
      "2022-01-07 16:45:00,001 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [2000/18000 (11%)]\tLoss: 0.788377\n",
      "2022-01-07 16:45:10,370 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [2200/18000 (12%)]\tLoss: 1.046620\n",
      "2022-01-07 16:45:20,667 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [2400/18000 (13%)]\tLoss: 0.797647\n",
      "2022-01-07 16:45:31,417 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [2600/18000 (14%)]\tLoss: 0.892930\n",
      "2022-01-07 16:45:42,583 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [2800/18000 (16%)]\tLoss: 0.856651\n",
      "2022-01-07 16:48:36,411 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3000/18000 (17%)]\tLoss: 0.735632\n",
      "2022-01-07 16:48:54,556 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3200/18000 (18%)]\tLoss: 0.622936\n",
      "2022-01-07 16:49:04,909 fedbiomed INFO - log from: node_0310a754-697c-4fef-8f0e-231f3705598d / INFO - Train Epoch: 1 [3400/18000 (19%)]\tLoss: 0.900519\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y1/mqwffwx97cqcz6jq_cr4twmc0000gn/T/ipykernel_79033/2112911450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/works/temp/fedbiomed/fedbiomed/researcher/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sync)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sampled nodes in round '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;31m# Trigger training round on sampled nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0manswering_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_nodes_training_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# refining/normalizing model weigths received from nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/works/temp/fedbiomed/fedbiomed/researcher/job.py\u001b[0m in \u001b[0;36mstart_nodes_training_round\u001b[0;34m(self, round)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;31m# (wait for all nodes with a ` while true` loop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m#models_done = self._reqs.get_responses(look_for_commands=['train'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mmodels_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlook_for_commands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_successful\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0;31m#print(\"=== DEBUG START start_nodes_training_round\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m#print(models_done)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/works/temp/fedbiomed/fedbiomed/researcher/requests.py\u001b[0m in \u001b[0;36mget_responses\u001b[0;34m(self, look_for_commands, timeout, only_successful)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mnew_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlook_for_commands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the federated model is obtained, it is possible to test it locally on an independent testing partition.\n",
    "The test dataset is available at this link:\n",
    "\n",
    "https://drive.google.com/file/d/1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "import zipfile\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the testing dataset on the local temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD\"\n",
    "base_dir = tmp_dir_model.name \n",
    "test_file = os.path.join(base_dir, \"MedNIST_testing.zip\")\n",
    "\n",
    "gdown.download(resource, test_file, quiet=False)\n",
    "\n",
    "zf = zipfile.ZipFile(test_file)\n",
    "\n",
    "for file in zf.infolist():\n",
    "    zf.extract(file, base_dir)\n",
    "    \n",
    "data_dir = os.path.join(base_dir, \"MedNIST_testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data and create the testing data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir)\n",
    "                     if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "test_split = int(0.1 * length)\n",
    "test_indices = indices[:test_split]\n",
    "\n",
    "test_x = [image_files_list[i] for i in test_indices]\n",
    "test_y = [image_class[i] for i in test_indices]\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define testing metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the federated model we need to create a model instance and assign to it the model parameters estimated at the last federated optimization round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model_instance\n",
    "model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the testing performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0],\n",
    "            test_data[1],\n",
    "        )\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spite of the relatively small training performed on the data shared in the 3 nodes, the performance of the federated model seems pretty good. Well done! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
