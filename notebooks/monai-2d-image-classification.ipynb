{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated 2d image classification with MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed the 2d image classification example provided in the project MONAI (https://monai.io/):\n",
    "\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/2d_classification/mednist_tutorial.ipynb\n",
    "\n",
    "Being MONAI based on PyTorch, the deployment within Fed-BioMed follows seamlessy the same general structure of general PyTorch models. \n",
    "\n",
    "Following the MONAI example, this tutorial is based on the MedNIST dataset:\n",
    "\n",
    "https://github.com/Project-MONAI/MONAI/blob/master/examples/notebooks/mednist_tutorial.ipynb.\n",
    "\n",
    "## Creating MedNIST nodes\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "To proceed with the tutorial, we created an iid partitioning of the MedNIST dataset between 3 clients. Each client has 3000 image samples for each class. The training partitions are availables at the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1vLIcBdtdAhh6K-vrgCFy_0Y55dxOWZwf/view\n",
    "\n",
    "The dataset owned by each client has structure:\n",
    "\n",
    "\n",
    "└── client_*/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "    \n",
    "    └── BreastMRI/\n",
    "    \n",
    "    └── CXR/\n",
    "    \n",
    "    └── ChestCT/\n",
    "    \n",
    "    └── Hand/\n",
    "    \n",
    "    └── HeadCT/   \n",
    "\n",
    "To create the federated dataset, we follow the standard procedure for node creation/population of Fed-BioMed. \n",
    "After activating the fedbiomed network with the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment network`\n",
    "\n",
    "and \n",
    "\n",
    "`./scripts/fedbiomed_run network`\n",
    "\n",
    "we create a first node by using the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment node`\n",
    "\n",
    "`./scripts/fedbiomed_run node start`\n",
    "\n",
    "We then poulate the node with the data of first client:\n",
    "\n",
    "`./scripts/fedbiomed_run node add`\n",
    "\n",
    "We select option 3 (images) to add MedNIST partition of client 1, by just picking the folder of client 1. \n",
    "Assign tag `mednist` to the data when asked.\n",
    "\n",
    "We can further check that the data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "\n",
    "Following the same procedure, we create the other two nodes with the datasets of client 2 and client 3 respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Fed-BioMed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start the reseracher enviroment with the command `source ./scripts/fedbiomed_environment researcher`, and open the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first quesry the network for the mednist dataset. In this case, the nodes are sharing the respective partitions unsing the same tag `mednist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 19:29:58,786 fedbiomed INFO - Component environment:\n",
      "2022-01-06 19:29:58,787 fedbiomed INFO - - type = ComponentType.RESEARCHER\n",
      "2022-01-06 19:29:59,143 fedbiomed INFO - Messaging researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x7fbd8854dd90>\n",
      "2022-01-06 19:29:59,170 fedbiomed INFO - Listing available datasets in all nodes... \n",
      "2022-01-06 19:29:59,172 fedbiomed INFO - log from: node_b4eb76b3-54fe-42e4-8f01-501a4f1a179a / DEBUG - Message received: {'researcher_id': 'researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f', 'command': 'list'}\n",
      "2022-01-06 19:29:59,183 fedbiomed INFO - log from: node_30bcc00b-f402-4658-982c-6642390eb80a / DEBUG - Message received: {'researcher_id': 'researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f', 'command': 'list'}\n",
      "2022-01-06 19:29:59,185 fedbiomed INFO - log from: node_0341dbee-4250-4f28-8f05-fc0a98bde6b7 / DEBUG - Message received: {'researcher_id': 'researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f', 'command': 'list'}\n",
      "2022-01-06 19:30:09,192 fedbiomed INFO - \n",
      " Node: node_b4eb76b3-54fe-42e4-8f01-501a4f1a179a | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] |               | [18000, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n",
      "2022-01-06 19:30:09,195 fedbiomed INFO - \n",
      " Node: node_30bcc00b-f402-4658-982c-6642390eb80a | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] |               | [16954, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n",
      "2022-01-06 19:30:09,197 fedbiomed INFO - \n",
      " Node: node_0341dbee-4250-4f28-8f05-fc0a98bde6b7 | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] |               | [18000, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_b4eb76b3-54fe-42e4-8f01-501a4f1a179a': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': '',\n",
       "   'shape': [18000, 3, 64, 64]}],\n",
       " 'node_30bcc00b-f402-4658-982c-6642390eb80a': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': '',\n",
       "   'shape': [16954, 3, 64, 64]}],\n",
       " 'node_0341dbee-4250-4f28-8f05-fc0a98bde6b7': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': '',\n",
       "   'shape': [18000, 3, 64, 64]}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for network and data loader of the MONAI tutorial can now be deployed in Fed-BioMed.\n",
    "We first import the necessary modules from `fedbiomed` and `monai` libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+os.sep)\n",
    "model_file = os.path.join(tmp_dir_model.name, 'class_export_mednist.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the training plan. Note that we can simply use the standard `TorchTrainingPlan` natively provided in Fed-BioMed. We reuse the `MedNISTDataset` data loader defined in the original MONAI tutorial, which is returned by the method `training_data`, which also implements the data parsing from the nodes `dataset_path`. Following the MONAI tutorial, the model is the `DenseNet121`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/ybouilla/fedbiomed/var/tmp/tmpo8drwl14/class_export_mednist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, kwargs):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"import numpy as np\",\n",
    "                \"import os\",\n",
    "                \"from torch.utils.data import DataLoader\",\n",
    "                \"from monai.apps import download_and_extract\",\n",
    "                \"from monai.config import print_config\",\n",
    "                \"from monai.data import decollate_batch\",\n",
    "                \"from monai.metrics import ROCAUCMetric\",\n",
    "                \"from monai.networks.nets import DenseNet121\",\n",
    "                \"from monai.transforms import ( Activations, AddChannel, AsDiscrete, Compose, LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity, EnsureType, )\",\n",
    "                \"from monai.utils import set_determinism\",]\n",
    "        self.add_dependency(deps)\n",
    "         \n",
    "        self.num_class =  kwargs['num_class']  \n",
    "        self.model = DenseNet121(spatial_dims=2, in_channels=1,\n",
    "                    out_channels = self.num_class)\n",
    "        \n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    class MedNISTDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, image_files, labels, transforms):\n",
    "                self.image_files = image_files\n",
    "                self.labels = labels\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_files)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return self.transforms(self.image_files[index]), self.labels[index]\n",
    "    \n",
    "    def parse_data(self, path):\n",
    "        print(self.dataset_path)\n",
    "        class_names = sorted(x for x in os.listdir(path)\n",
    "                     if os.path.isdir(os.path.join(path, x)))\n",
    "        num_class = len(class_names)\n",
    "        image_files = [\n",
    "                        [\n",
    "                            os.path.join(path, class_names[i], x)\n",
    "                            for x in os.listdir(os.path.join(path, class_names[i]))\n",
    "                        ]\n",
    "                        for i in range(num_class)\n",
    "                      ]\n",
    "        \n",
    "        return image_files, num_class\n",
    "    \n",
    "    def training_data(self, batch_size = 48):\n",
    "        self.image_files, num_class = self.parse_data(self.dataset_path)\n",
    "        \n",
    "        if self.num_class!=num_class:\n",
    "                raise Exception('number of available classes does not match declared classes')\n",
    "        \n",
    "        num_each = [len(self.image_files[i]) for i in range(self.num_class)]\n",
    "        image_files_list = []\n",
    "        image_class = []\n",
    "        \n",
    "        for i in range(self.num_class):\n",
    "            image_files_list.extend(self.image_files[i])\n",
    "            image_class.extend([i] * num_each[i])\n",
    "        num_total = len(image_class)\n",
    "        \n",
    "        \n",
    "        length = len(image_files_list)\n",
    "        indices = np.arange(length)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        val_split = int(1. * length) \n",
    "        train_indices = indices[:val_split]\n",
    "\n",
    "        train_x = [image_files_list[i] for i in train_indices]\n",
    "        train_y = [image_class[i] for i in train_indices]\n",
    "\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImage(image_only=True),\n",
    "                AddChannel(),\n",
    "                ScaleIntensity(),\n",
    "                RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "                RandFlip(spatial_axis=0, prob=0.5),\n",
    "                RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "                EnsureType(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transforms = Compose(\n",
    "            [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "        y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "        y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])\n",
    "\n",
    "        print(\n",
    "            f\"Training count: {len(train_x)}\")\n",
    "        \n",
    "        \n",
    "        train_ds = self.MedNISTDataset(train_x, train_y, train_transforms)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_ds, batch_size, shuffle=True)\n",
    "        \n",
    "        return train_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = self.loss_function(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the model and training parameters. Note that we use only 1 epoch for this experiment, and perform the training on ~26% of the locally available training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {'num_class':6,}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 20, \n",
    "    'lr': 1e-5, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum':250 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment can be now defined, by providing the `mednist` tag, and running the local training on nodes with model defined in `model_path`, standard `aggregator` (FedAvg) and `client_selection_strategy` (all nodes used). Federated learning is going to be perfomed through 3 optimization rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 19:30:34,669 fedbiomed INFO - Searching dataset with data tags: ['mednist'] for all nodes\n",
      "2022-01-06 19:30:34,671 fedbiomed INFO - log from: node_b4eb76b3-54fe-42e4-8f01-501a4f1a179a / DEBUG - Message received: {'researcher_id': 'researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f', 'tags': ['mednist'], 'command': 'search'}\n",
      "2022-01-06 19:30:34,671 fedbiomed INFO - log from: node_0341dbee-4250-4f28-8f05-fc0a98bde6b7 / DEBUG - Message received: {'researcher_id': 'researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f', 'tags': ['mednist'], 'command': 'search'}\n",
      "2022-01-06 19:30:34,672 fedbiomed INFO - log from: node_30bcc00b-f402-4658-982c-6642390eb80a / DEBUG - Message received: {'researcher_id': 'researcher_ccf4bfd5-a09e-4e86-b698-d656c390b98f', 'tags': ['mednist'], 'command': 'search'}\n",
      "2022-01-06 19:30:44,682 fedbiomed INFO - Node selected for training -> node_b4eb76b3-54fe-42e4-8f01-501a4f1a179a\n",
      "2022-01-06 19:30:44,685 fedbiomed INFO - Node selected for training -> node_0341dbee-4250-4f28-8f05-fc0a98bde6b7\n",
      "2022-01-06 19:30:44,687 fedbiomed INFO - Node selected for training -> node_30bcc00b-f402-4658-982c-6642390eb80a\n",
      "2022-01-06 19:30:44,690 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "2022-01-06 19:30:45,004 fedbiomed DEBUG - torchnn saved model filename: /home/ybouilla/fedbiomed/var/experiments/Experiment_0000/my_model_3741fb7c-a0e8-48fe-82de-48ef82904df1.py\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['mednist']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='MyTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the federated model is obtained, it is possible to test it locally on an independent testing partition.\n",
    "The test dataset is available at this link:\n",
    "\n",
    "https://drive.google.com/file/d/1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (4.2.0)\n",
      "Requirement already satisfied: six in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/ybouilla/.local/lib/python3.9/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: requests[socks] in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from gdown) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from requests[socks]->gdown) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ybouilla/.conda/envs/fedbiomed-researcher/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.8.1+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.19.0\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.7.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.9.1+cu102\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.5\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "import zipfile\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the testing dataset on the local temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD\n",
      "To: /home/ybouilla/fedbiomed/var/tmp/tmpo8drwl14/MedNIST_testing.zip\n",
      "100%|██████████████████████████████████████| 9.50M/9.50M [00:07<00:00, 1.31MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD\"\n",
    "base_dir = tmp_dir_model.name \n",
    "test_file = os.path.join(base_dir, \"MedNIST_testing.zip\")\n",
    "\n",
    "gdown.download(resource, test_file, quiet=False)\n",
    "\n",
    "zf = zipfile.ZipFile(test_file)\n",
    "\n",
    "for file in zf.infolist():\n",
    "    zf.extract(file, base_dir)\n",
    "    \n",
    "data_dir = os.path.join(base_dir, \"MedNIST_testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data and create the testing data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image count: 6000\n",
      "Image dimensions: 64 x 64\n",
      "Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
      "Label counts: [1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir)\n",
    "                     if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "test_split = int(0.1 * length)\n",
    "test_indices = indices[:test_split]\n",
    "\n",
    "test_x = [image_files_list[i] for i in test_indices]\n",
    "test_y = [image_class[i] for i in test_indices]\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define testing metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the federated model we need to create a model instance and assign to it the model parameters estimated at the last federated optimization round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = exp.model_instance\n",
    "model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the testing performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   AbdomenCT     0.9802    0.9900    0.9851       100\n",
      "   BreastMRI     0.9885    1.0000    0.9942        86\n",
      "         CXR     1.0000    0.9902    0.9951       102\n",
      "     ChestCT     0.9895    1.0000    0.9947        94\n",
      "        Hand     0.9902    1.0000    0.9951       101\n",
      "      HeadCT     1.0000    0.9744    0.9870       117\n",
      "\n",
      "    accuracy                         0.9917       600\n",
      "   macro avg     0.9914    0.9924    0.9919       600\n",
      "weighted avg     0.9918    0.9917    0.9917       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spite of the relatively small training performed on the data shared in the 3 nodes, the performance of the federated model seems pretty good. Well done! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
