{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e87007",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher to train a federated scikit learn model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e17d2f",
   "metadata": {},
   "source": [
    "## Purpose of the exercise :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb782b14",
   "metadata": {},
   "source": [
    "Three datasets n1.csv , n2.csv and n3.csv has been generated randomly using a linear transformation A = [ 5 8 9 5 0 ].\n",
    "We will fit a Stochastic Gradient Regressor to approximate this transformation using Federated Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf562e",
   "metadata": {},
   "source": [
    "## Extending this notebook to any incremental learning scikit model:\n",
    "\n",
    "The same federated learning scheme below applies to any sklearn model supporting the method partial_fit():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98bbac",
   "metadata": {},
   "source": [
    "A family of models could be naturally imported in Fed-BioMed, following the same approach. For example: \n",
    "- Naive Bayes.  \n",
    "- Logistic regression,\n",
    "- SVM/SVC (linear and non-linear), \n",
    "- perceptron, \n",
    "- KMeans, \n",
    "- incremental PCA, \n",
    "- mini batch dictionary learning, \n",
    "- latent Dirichlet annotation, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f160e",
   "metadata": {},
   "source": [
    "## Start the network and setting the client up\n",
    "Before running this notebook:\n",
    "1. You should start the network from fedbiomed-network, as detailed in :\n",
    "https://gitlab.inria.fr/fedbiomed/fedbiomed\n",
    "2. Download n1.csv, n2.csv and n3.csv to some place in your computer from https://gitlab.inria.fr/fedbiomed/fedbiomed/-/tree/develop/notebooks/data\n",
    "3. You need to configure at least 2 nodes: <br/>\n",
    "* **Node 1 :** `./scripts/fedbiomed_run node add`\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset (you can write 'sk' always and it will be good)\n",
    "  * Pick the .csv file n1.csv .\n",
    "  * Check that your data has been added in node 1 by executing `./scripts/fedbiomed_run node list`\n",
    "  * Run the node using `./scripts/fedbiomed_run node start`. <br/>\n",
    "\n",
    "* **Node 2 :** Open a second terminal and run ./scripts/fedbiomed_run node add config n2.ini\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset (you can write 'sk' always and it will be good)\n",
    "  * Pick the .csv file n2.csv .\n",
    "  * Check that your data has been added in node 2 by executing `./scripts/fedbiomed_run node list config n2.ini`\n",
    "  * Run the node using `./scripts/fedbiomed_run node start config n2.ini`.\n",
    "  \n",
    "* **Node 3 :** Open a second terminal and run ./scripts/fedbiomed_run node add config n3.ini\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset (you can write 'sk' always and it will be good)\n",
    "  * Pick the .csv file n3.csv .\n",
    "  * Check that your data has been added in node 2 by executing `./scripts/fedbiomed_run node list config n3.ini`\n",
    "  * Run the node using `./scripts/fedbiomed_run node start config n3.ini`.\n",
    "\n",
    " Wait until you get `Connected with result code 0`. it means you are online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c80070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fedbiomed.researcher.environ import TMP_DIR\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=TMP_DIR+'/')\n",
    "model_file = tmp_dir_model.name + '/fedbiosklearn.py'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91e69a",
   "metadata": {},
   "source": [
    "**model_args** is a dictionnary containing your model arguments, in case of SGDRegressor this will be max_iter and tol.\n",
    "\n",
    "**training_args** is a dictionnary with parameters , related to Federated Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8305d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sklearn_model = 'BernoulliNB'\n",
    "\n",
    "# n_features = 20\n",
    "# n_classes = 2\n",
    "\n",
    "# theta_ = np.array([0.1] * (n_features*n_classes)).reshape(n_classes,n_features)\n",
    "# feature_count_ = np.array([0] * (n_features*n_classes)).reshape(n_classes,n_features)\n",
    "# class_count_ = np.array([0] * (n_classes))\n",
    "\n",
    "# model_args = { 'model': input_sklearn_model, 'max_iter':1000, 'tol': 1e-3 , \n",
    "#               'init_params' : {'theta_': theta_, 'feature_count_' : feature_count_, 'class_count_' : class_count_}}\n",
    "\n",
    "# training_args = {\n",
    "#     'batch_size': None, \n",
    "#     'lr': 1e-3, \n",
    "#     'epochs': 5, \n",
    "#     'dry_run': False,  \n",
    "#     'batch_maxnum': 0\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sklearn_model = 'Perceptron'\n",
    "\n",
    "n_features = 20\n",
    "n_classes = 2\n",
    "\n",
    "model_args = { 'model': input_sklearn_model, 'max_iter':1000, 'tol': 1e-3 , \n",
    "               'n_features' : n_features, 'n_classes' : n_classes}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': None, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 5, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9aaa87",
   "metadata": {},
   "source": [
    "Hereafter the template of the class you should provide to Fedbiomed :\n",
    "\n",
    "**after_training_params** : a dictionnary containing the model parameters. \n",
    "In SGDRegressor case we will have coef and intercept. For kmeans that will be cluster_center and labels.\n",
    "       \n",
    "**training_step** : the most part of the time, it will be the method partial_fit, \n",
    "of a scikit incremental learning model. You can uncomment the prints in order to check the evolution of training.\n",
    "       \n",
    "**training_data** : you must return here the (X,y) that must be of the same type of \n",
    "your method partial_fit parameters. To simplify we dont use batch_size here, but the code should work if you want to train on a specific batch of the dataset. \n",
    "\n",
    "You can uncomment the prints in order to check the evolution of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10cc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "from fedbiomed.common.fedbiosklearn import SGDSkLearnModel\n",
    "import numpy as np\n",
    "\n",
    "class SkLearnTrainingPlan(SGDSkLearnModel):\n",
    "    def __init__(self, model_args):\n",
    "        super(SkLearnTrainingPlan,self).__init__(model_args)\n",
    "    \n",
    "    def training_data(self,batch_size=None):\n",
    "        NUMBER_COLS = 20\n",
    "        dataset = pd.read_csv(self.dataset_path,header=None,delimiter=',')\n",
    "        if batch_size == None:\n",
    "            X = dataset.iloc[:,0:NUMBER_COLS].values\n",
    "            y = dataset.iloc[:,NUMBER_COLS]\n",
    "        else:\n",
    "            X = dataset.iloc[0:batch_size,0:NUMBER_COLS].values\n",
    "            y = dataset.iloc[0:batch_size,NUMBER_COLS]\n",
    "        return (X,y.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['sk']\n",
    "rounds = 8\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #clients=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='SkLearnTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 client_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2a782",
   "metadata": {},
   "source": [
    "## Lets build now a dataset test, **A** is the linear transformation that has been used to build the csv file datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8853e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "xx = SGDClassifier()\n",
    "print(xx.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4439e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/mlorenzi/Downloads/c3.csv')\n",
    "\n",
    "# this dataset corresponds to the last 50 samples of the data created with this instance:\n",
    "# X,y = make_classification(n_samples=300, n_features=20,n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, \n",
    "#                           hypercube=True, shift=0.0, scale=1.0,shuffle=True, random_state=123)\n",
    "#\n",
    "# The first 250 samples are used to create the training clients (datasets c1 and c2)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_test = data.iloc[:,:n_features]\n",
    "y_test = data.iloc[:,n_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6d380",
   "metadata": {},
   "source": [
    "The MSE should be decreasing at each iteration with the federated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_sklearn_model in ['SGDClassifier', 'Perceptron']:\n",
    "    from sklearn.metrics import f1_score\n",
    "    loss_metric = f1_score\n",
    "if input_sklearn_model=='SGDRegressor':\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    loss_metric = mean_squared_error\n",
    "    \n",
    "testing_error = []\n",
    "\n",
    "for i in range(rounds):\n",
    "    fed_model = exp.model_instance.get_model()\n",
    "    fed_model.coef_ = exp.aggregated_params[i]['params']['coef_']\n",
    "    fed_model.intercept_ = exp.aggregated_params[i]['params']['intercept_']\n",
    "    metric = loss_metric(fed_model.predict(X_test),y_test.ravel())\n",
    "    print('Accuracy metric: ', metric, )\n",
    "    testing_error.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1196d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perc = Perceptron()\n",
    "perc.fit(X_test, y_test)\n",
    "print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41023e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
