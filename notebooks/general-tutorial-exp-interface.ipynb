{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details of the Experiment Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment class provides an interface that you can manage your experiment with backward compatibility. It means that even your Experiment has been built/defined you will be able to configure its parameters. This feature will provide more control over your experiment even after your running your experiment for several rounds. In this tutorial, detailed experiment interface will be explained using MNIST basic example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Environment\n",
    "Before running this notebook, you need to configure your environment by completing following steps:\n",
    "\n",
    "### Starting the Network Component\n",
    "Please run following command to start Network component that provided communication between your notebook and the node;\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run network\n",
    "```\n",
    "<div class=\"note\">\n",
    "<p>This command will launch docker containers. Therefore, please make sure that your Docker engine is up and running.</p>\n",
    "</div>\n",
    "\n",
    "### Deploying MNIST Dataset in the None\n",
    "Please run following command to add MNIST dataset into your Node. This command will deploy MNIST dataset in your default node whose config file is located in `{FEDBIOMED_DIR}/etc` directory as `config_node.ini`\n",
    "\n",
    "After running following command, please select data type `2) default`, use default `tags` and select the folder where MNIST dataset will be saved.\n",
    "\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node add\n",
    "```\n",
    "\n",
    "### Starting the Node\n",
    " After you have successfully completed previous step, please run following commad to start your node.\n",
    "\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model\n",
    "\n",
    "Before declaring an experiment, the model that will be used for federated training should be defined. The model that is goÄ±ng to be used is exactly the same model that has been created in the Basic MNIST tutorial. We recommend you to follow Basic MNIST tutorial on PyTorch Framework to understand follwing steps. s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from fedbiomed.researcher.environ import environ\n",
    "\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR'])\n",
    "model_file = os.path.join(tmp_dir_model.name, 'class_export_mnist.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "               \"from torch.utils.data import DataLoader\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After runing the cells above, your model codes will be saved in path which is defined in the variable `model_file`. This path will be used let while declaring an experiment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craeting an Experiment Step by Step  \n",
    "\n",
    "The experiment class can be created without passing any argument. This will just build an empty experiment object. Afterwards, you will be able define your arguments using setter methods.  \n",
    "\n",
    "\n",
    "<div class=\"note\"><p>It is always possible to create a fully configured experiment by passing all arguments during the intialization. You can also create your experiment with some of the arguments and set the other arguments after.</p></div>\n",
    "\n",
    "### Building an Empty Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building an empty experiment you won't be able to perform federated training, since it is not fully configured. That's why the output of the initialization will always remind you that the experiment experiment is not fully configured by logging required arguments.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 10:44:34,804 fedbiomed DEBUG - Experiment not fully configured yet: no training data\n",
      "2022-02-18 10:44:34,805 fedbiomed DEBUG - Experiment not fully configured yet: no node selection strategy\n",
      "2022-02-18 10:44:34,806 fedbiomed DEBUG - Experiment not fully configured yet: no valid model, model_class=None model_path=None\n",
      "2022-02-18 10:44:34,807 fedbiomed DEBUG - Experiment not fully configured yet: no job. Missing proper model definition (model_class=None model_path=None)\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "exp = Experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Current Status of Experiment\n",
    "As an addition to output of the initialization, to find out more about the currrent status of the experiment, you can call the `info()` method of experiment object. This method will print the information about your experiment and what you should complete to be able to start your federated training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments           Values\n",
      "------------------  ----------------------------------------\n",
      "Tags                None\n",
      "Nodes filter        None\n",
      "Training Data       None\n",
      "Aggregator          <fedbiomed.researcher.aggregators.fedavg\n",
      "                    .FedAverage object at 0x1036f4070>\n",
      "Strategy            None\n",
      "Job                 None\n",
      "Model Path          None\n",
      "Model Class         None\n",
      "Model Arguments     {}\n",
      "Training Arguments  {}\n",
      "Rounds already run  0\n",
      "Rounds total        None\n",
      "Experiment folder   Experiment_0001\n",
      "Experiment Path     /Users/sergencansiz/Documents/Inria/Fed-\n",
      "                    BioMed/fedbiomed/var/experiments/Experim\n",
      "                    ent_0001\n",
      "Breakpoint State    False\n",
      "Monitoring          None\n",
      "\n",
      "Experiment cannot be run (not fully defined), missing :\n",
      "- Training Data\n",
      "- Strategy\n",
      "- Model\n",
      "- Job\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output, some arguments are defined with default values, while others are not. Model arguments, training arguments, tags, round limit, training data etc. have no default value and they are required to be set. However, these arguments are related to each other. For example, to be able to define your federeated training data you need to define the `tags` first, and then while setting your training data argument, experiment will be able to send search request to the nodes to recive information about the datasets. These relation between the arguments will explained in the follwing steps.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Model for The Experiment\n",
    "\n",
    "The model that is going to be used for training can be set in the experiment using the methods `set_model_path` and `set_model_class`. The `model_path` is the path your model is saved as a python script. As you remember, in the previous section, the model class has been created and saved in the path which is defined in the variable `model_file`. The experiment also need to now your class name. You can set your class name as a `string` with `set_model_class`. Since it is a python script (module), class name will be used for importing operation at the back-end. Therefore, it always better to define both argument successively. \n",
    "\n",
    "<div class=\"note\">\n",
    "    <p>\n",
    "        If you are not running your code in Jupyter notebook (IPython kernel), you directly set your class as it is with <code>set_model_class()</code> as a python class (not string). The experiment will be able to extract source of your class and you won't need to provide the argument <code>model_path</code>. \n",
    "    <p/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sergencansiz/Documents/Inria/Fed-BioMed/fedbiomed/var/tmp/tmp6rlwq56w/class_export_mnist.py'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_model_class(model_class=\"MyTrainingPlan\")\n",
    "exp.set_model_path(model_path=model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"note\">\n",
    "    <p>If you set your model path first, setter will log a debug message which will inform you about the model is not defined yet. This si because the model class has been set yet</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Model and Training Arguments\n",
    "In the previous step, the model has been defined for experiment. Now, you can define your model arguments and training arguments that will be used respectivly for building your model class and training your model on the node side. The methods `set_model_args` and `set_trainin_args` of experiment will allow you to set these arguments. \n",
    "\n",
    "<div class=\"\">\n",
    "    <p>There is requirement in the order of defening model class and mode/training arguments. It is also possible to \n",
    "        define model/training arguments first and model class after. \n",
    "    </p>    \n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 48,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 1,\n",
       " 'dry_run': False,\n",
       " 'batch_maxnum': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model arguments should be an empty Dict, since our model does not require \n",
    "# any argument for initialization\n",
    "model_args = {}\n",
    "\n",
    "# Training Arguments\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "exp.set_model_args(model_args=model_args)\n",
    "exp.set_training_args(training_args=training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags for the dataset search request can be set using `set_tags` method of experiment object. \n",
    "\n",
    "<br><div class=\"note\"><p>Setting tags does not mean to send dataset search request. Search request is sent while setting training data. `tags` is the argument that is required for the search request.</p></div>\n",
    "\n",
    "The arguments tags of `set_tags` method should an array of tags which are in `string` type or just a `string`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 12:23:33,556 fedbiomed DEBUG - Experimentation tags changed, you may need to update `training_data`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#MNIST', '#dataset']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['#MNIST', '#dataset']\n",
    "exp.set_tags(tags = tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the tags that are set, you can run `tags()` method of experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#MNIST', '#dataset']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Training Data\n",
    "Training data is a `FederatedDataset` instance which comes from the module `fedbiomed.researcher.datasets`. There are several ways to define your training data.\n",
    "\n",
    "1. You can run `set_training_data(training_data=None)` method by passing the argument `training_data` as `None`. This will send search request to the nodes  to get dataset information by using the `tags` which should defined before. \n",
    "2. You can provide `training_data` argument which is an instance of `FederatedDataSet`. \n",
    "3.  You can provide `training_data` argument as python `dict` and setter will create a `FederatedDataSet` object by it self. \n",
    "\n",
    "<div class=\"note\"><p>While using the third option please make sure that your `dict` object is configured as coherent to `FedereatedDataset` schema. Otherwise, you might get error while runing your experiment. </p></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 11:41:00,292 fedbiomed INFO - Searching dataset with data tags: ['#MNIST', '#dataset'] for all nodes\n",
      "2022-02-18 11:41:00,298 fedbiomed INFO - log from: node_0f7ddd0a-3879-4864-828c-014d8dfce442 / DEBUG - Message received: {'researcher_id': 'researcher_4ad5a2c1-8d01-47d4-91a9-8f7aad804c5e', 'tags': ['#MNIST', '#dataset'], 'command': 'search'}\n",
      "2022-02-18 11:41:10,302 fedbiomed INFO - Node selected for training -> node_0f7ddd0a-3879-4864-828c-014d8dfce442\n"
     ]
    }
   ],
   "source": [
    "training_data = exp.set_training_data(training_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it will send search request to the nodes, the ouput will inform you about selected nodes for training. It means that those nodes are have the dataset and able to train your model.\n",
    "\n",
    "`set_training_data` will return a `FederatedDataSet` object. You can either use the return value of the setter or the getter for training data which is `training_data()` method of the experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = exp.training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the result in detail you can call the method `data()` of the `FedereatedDataSet` object. This will return a python dictionary thats includes information about the datasets that has been found in the nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_0f7ddd0a-3879-4864-828c-014d8dfce442': [{'name': 'MNIST',\n",
       "   'data_type': 'default',\n",
       "   'tags': ['#MNIST', '#dataset'],\n",
       "   'description': 'MNIST database',\n",
       "   'shape': [60000, 1, 28, 28],\n",
       "   'dataset_id': 'dataset_35c1ef06-8532-45fc-8b8d-343f8d381e0f',\n",
       "   'dtypes': []}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it mention before, setting training data once doesn't mean that you can change it. You can create a new `FederatedDataSet` with a `dict` that includes the information about datasets. This will allow you to select the datasets that will be used for federeated training. \n",
    "\n",
    "<div class=\"note\"><p>Since the dataset information will be provided, there will be no need to send request to the nodes</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.datasets.FederatedDataSet at 0x134975430>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.datasets import FederatedDataSet \n",
    "\n",
    "tr_data = training_data.data()\n",
    "federeated_dataset = FederatedDataSet(tr_data)\n",
    "exp.set_training_data(training_data = federeated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can directly use `tr_data` in `set_training_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.datasets.FederatedDataSet at 0x1349d9460>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_training_data(training_data = tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"name\">\n",
    "    <p>\n",
    "        If you change the tags for the dataset by using <code>set_tags</code> and if there is already a defined trainign data in your experiment object, you have to update your training data by running <code>exp.set_training_data(training_data=None)</code>.  \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting an Aggregator  \n",
    "\n",
    "An aggreagtor is one of the required arguments for the experiment. It is used for aggergating model parameters that are received from the nodes after every round. By default, when the experiment is initialized without passing any aggregator, it will auotmaticly use the default `FedAverage` aggregator class. However, it also possbile to set different aggregation algorithm with the method `set_aggregator`. Currently, Fed-BioMed has only `FedAvereage` but it is possible to create custom aggregator classes.\n",
    "\n",
    "You can see the dcurrent aggregator by running `exp.aggregator()`. It will return the aggregator object that will be used for aggregation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.aggregators.fedavg.FedAverage at 0x1036f4070>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.aggregator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we supposed that you have created your own aggergator, you can set that aggrator as follows, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.aggregators.fedavg.FedAverage at 0x134975790>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "exp.set_aggregator(aggregator=FedAverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also build your class and pass as an object in case of your aggregator class needs initialization paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avereage = FedAverage()\n",
    "exp.set_aggregator(aggregator=fed_avereage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Node Selection Strategy\n",
    "\n",
    "Node selection Strategy is also one of the required arguments for the experiment. It is used for selecting nodes before each round of training. Since the strategy will be used for selecting nodes, before setting strategy, training data should be already set. Then, stragety will be able to which nodes are current with their dataset. \n",
    "\n",
    "By default, `set_strategy(node_selection_strategy=None)` will use the default `DefaultStrategy` class. It is default strategy that selects all nodes avaible with their datasets at the moment. However, it also possbile to set different strategies. Currently, Fed-BioMed has only `DefaultStrategy` but it is possible to create custom strategy classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.strategies.default_strategy.DefaultStrategy at 0x1349d99d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_strategy(node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you directly pass `DefaultStrategy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.strategies.default_strategy.DefaultStrategy at 0x1349d9af0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "exp.set_strategy(node_selection_strategy=DefaultStrategy)\n",
    "\n",
    "# To make the strategy has been set\n",
    "exp.strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Round Limit\n",
    "\n",
    "Round limit is the limit that indicates max number of rounds of the training. By default it is `None` and it needs to be set before running your experiment. You can set the round limit with the method `set_round_limit`. Round limit can  be changed after runing several ruounds of training. You can always excute `exp.round_limit()` to see current round limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_round_limit(round_limit=2)\n",
    "exp.round_limit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Job to Manage Federeated Training Rounds\n",
    "\n",
    "Job is a class that manages federeated training rounds. Before setting job, stragety for selecting nodes, model and training data should be set. Therefore, please make sure that they all defined before setting job.  The method `set_job` creates the Job instance and it does not take any argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:14:42,625 fedbiomed DEBUG - torchnn saved model filename: /Users/sergencansiz/Documents/Inria/Fed-BioMed/fedbiomed/var/experiments/Experiment_0001/my_model_5018329c-fae2-4f09-9a71-952e0d165f42.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fedbiomed.researcher.job.Job at 0x134a926a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_job()\n",
    "exp.job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Check\n",
    "Now, let's if our experiment is ready for the training by running `exp.info()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments           Values\n",
      "------------------  ----------------------------------------\n",
      "Tags                ['#MNIST', '#dataset']\n",
      "Nodes filter        None\n",
      "Training Data       <fedbiomed.researcher.datasets.Federated\n",
      "                    DataSet object at 0x1349d9460>\n",
      "Aggregator          <fedbiomed.researcher.aggregators.fedavg\n",
      "                    .FedAverage object at 0x134975790>\n",
      "Strategy            <fedbiomed.researcher.strategies.default\n",
      "                    _strategy.DefaultStrategy object at 0x13\n",
      "                    49d9af0>\n",
      "Job                 <fedbiomed.researcher.job.Job object at\n",
      "                    0x134a926a0>\n",
      "Model Path          /Users/sergencansiz/Documents/Inria/Fed-\n",
      "                    BioMed/fedbiomed/var/tmp/tmp6rlwq56w/cla\n",
      "                    ss_export_mnist.py\n",
      "Model Class         MyTrainingPlan\n",
      "Model Arguments     {}\n",
      "Training Arguments  {'batch_size': 48, 'lr': 0.001, 'epochs'\n",
      "                    : 1, 'dry_run': False, 'batch_maxnum': 1\n",
      "                    00}\n",
      "Rounds already run  0\n",
      "Rounds total        2\n",
      "Experiment folder   Experiment_0001\n",
      "Experiment Path     /Users/sergencansiz/Documents/Inria/Fed-\n",
      "                    BioMed/fedbiomed/var/experiments/Experim\n",
      "                    ent_0001\n",
      "Breakpoint State    False\n",
      "Monitoring          None\n",
      "\n",
      "Experiment can be run now (fully defined)\n"
     ]
    }
   ],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the experiment is ready, you will see the message that says `Experiment can be run now (fully defined)` at the bottom of the output. So now, we can run the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing The Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:05:29,684 fedbiomed WARNING - Cannot run, please specify a number of `rounds` to run or set a `round_limit` to the experiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_rounds(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rounds that has ben run    : ' , exp.round_current())\n",
    "print('Round number for starting next round : ' , exp.round_current() + 1)\n",
    "print('Round Index                          : ' , list(range(exp.round_current())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring an Experiment Step by Step \n",
    "### Building Empty Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags =  ['#MNIST', '#dataset']\n",
    "from fedbiomed.researcher.requests import Requests\n",
    "reqs = Requests()\n",
    "training_data = reqs.search(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "#strategy= DefaultStrategy(training_data)\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "strategy = FedAverage()\n",
    "exp = Experiment(training_data=training_data, node_selection_strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "exp = Experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Tags \n",
    "\n",
    "Tags should list strings that contains tags or a string with single tag. \n",
    "\n",
    "---\n",
    "<div class=\"note\">\n",
    "    <p>If provided tags is not in correct type `.set_tags` will raise <code>TypeError</code></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"#MNIST\", \"#dataset\"]\n",
    "exp.set_tags(tags = tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Model Path and Model Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_model_path(model_path = model_file)\n",
    "exp.set_model_class(model_class = 'MyTrainingPlan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Model Arguments and Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100\n",
    "}\n",
    "\n",
    "exp.set_model_args(model_args = model_args)\n",
    "exp.set_training_args(training_args = training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `set_trainig_data` gets there arguments: \n",
    "\n",
    "- `tags` : List of tags as string for the search request. If it is not provided. The method will try to use `tags` attribute of the object. \n",
    "- `nodes`: List of node ids that a search request will be sent. If this argument is not provided search request will be sent to all active nodes.  \n",
    "- `training_data`: A dictionary or `FederatedDataset` object. If `training_data` provided search request with `tags` and `nodes` will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_training_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Job \n",
    "\n",
    "Setting job will prepare all neccessary assets to be able to run a round. Therefore, `Job` should be set before running the experiment.  \n",
    "\n",
    "To be able to set `Job`, you should be already set the arguments: `model_path`, `model_class`, `training_data`. Otherwiser `set_job()` will reaise an Exception. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_node_selection_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of The Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rounds              :', exp.rounds())\n",
    "print('Tags                :', exp.tags())\n",
    "print('Model Path          :', exp.model_path())\n",
    "print('Model Class         :', exp.model_class())\n",
    "print('Model Arguments     :', exp.model_args())\n",
    "print('Training Arguments  :', exp.training_args())\n",
    "print('Job                 :', exp.job())\n",
    "print('Training Data       :', exp.training_data())\n",
    "print('Job                 :', exp.job())\n",
    "print('Nodes               :', exp.nodes()) # Returns selected nodes after search request\n",
    "print('Aggregator          :', exp.aggregator())\n",
    "print('N.S. Stragety       :', exp.node_selection_strategy())\n",
    "print('Breakpoint State    :', exp.breakpoint())\n",
    "print('Exp  folder         :', exp.experimentation_folder())\n",
    "print('Exp  path           :', exp.experimentation_path())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rounds initial             : ' , exp.rounds())\n",
    "print('Number of rounds that has ben run    : ' , exp.round_current())\n",
    "print('Round number for starting next round : ' , exp.round_current() + 1)\n",
    "print('Round Indexes                        : ' , list(range(exp.round_current())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check current round, deaclare the the round that will be run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rounds initial             : ' , exp.rounds())\n",
    "print('Number of rounds that has ben run    : ' , exp.round_current())\n",
    "print('Round number for starting next round : ' , exp.round_current() + 1)\n",
    "print('Round Indexes                        : ' , list(range(exp.round_current())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running multiple rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting rounds to higher value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rounds = exp.rounds() + 1\n",
    "exp.set_rounds(new_rounds)\n",
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rounds initial             : ' , exp.rounds())\n",
    "print('Number of rounds that has ben run    : ' , exp.round_current())\n",
    "print('Round number for starting next round : ' , exp.round_current() + 1)\n",
    "print('Round Indexes                        : ' , list(range(exp.round_current())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = exp.round_current()\n",
    "\n",
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "for r in exp.training_replies().keys():\n",
    "    round_data = exp.training_replies()[r].data()\n",
    "    print('\\n\\t Round %s' % str(r+1))\n",
    "    for c in range(len(round_data)):\n",
    "        print(\"\\t\\t- {id} :\\\n",
    "        \\n\\t\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "        \\n\\t\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "        \\n\\t\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "            rtraining = round_data[c]['timing']['rtime_training'],\n",
    "            ptraining = round_data[c]['timing']['ptime_training'],\n",
    "            rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Same Experiment with Multple Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(rounds=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Experiment Parameters with Setters after all The Argument is Already Set\n",
    "If the `Job` is already initialize and the arguments related to model is modified, `Job` should reinitialize with the method `.set_job()`. This information is also given by Experiment after setting model file.  \n",
    "  \n",
    "    \n",
    "    \n",
    "<div class=\"note\">\n",
    "    <p>After runing the experiment changing the model might have some consequances.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_model_path(model_file)\n",
    "exp.set_model_class('MyTrainingPlan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Aggregator\n",
    "\n",
    "Aggregator should be instance of `fedbiomed.researcher.aggregators.aggregator.Aggregator`. Otherwise `set_aggregator` will raise an Expection. Aggregator should be passed as `Callable` class or alredy built object.\n",
    "\n",
    "Following cell will raise an Exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_aggregator('ThisIsNotAnAggregator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct usage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "# Can be passed as Callable class\n",
    "exp.set_aggregator(FedAverage)\n",
    "\n",
    "# Can be passed as already build class\n",
    "fedavg = FedAverage()\n",
    "exp.set_aggregator(fedavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available via `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params().keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params()[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params()[rounds - 1]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feel free to run other sample notebooks or try your own models :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
