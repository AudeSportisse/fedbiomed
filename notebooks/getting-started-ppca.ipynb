{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e87007",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher to train a federated ppca model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e17d2f",
   "metadata": {},
   "source": [
    "## Description of the exercise :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb782b14",
   "metadata": {},
   "source": [
    "Three datasets `n1.csv` , `n2.csv` and `n3.csv` will be generated randomly using 3-views PPCA from a 4-dimensional latent space, with views dimensions [15,8,10] and 2 groups. Henceforth, we will distribute the 3 dataset to 3 distinct nodes and use Fed-mv-PPCA. In each center we check the evolution of expected LL during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0bc07",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "We will generate three datasets using mv-PPCA.\n",
    "Then save them in a path of your choice on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sample_x_n(N, q, random_state=None):\n",
    "    return np.random.RandomState(random_state).randn(N,q)\n",
    "\n",
    "def generate_data(N_g, W, a_g, mu, sigma2, x_n, random_state=None):\n",
    "    rnd=np.random.RandomState(random_state)\n",
    "\n",
    "    N=N_g.sum()\n",
    "    d, q = W.shape\n",
    "    sigma=np.sqrt(sigma2)\n",
    "\n",
    "    return compute_mean_likelihood(N_g, W, a_g, mu, x_n) + sigma*rnd.randn(N,d)\n",
    "\n",
    "def compute_mean_likelihood(N_g, W, a_g, mu, x_n):\n",
    "    G=len(N_g)\n",
    "    N=N_g.sum()\n",
    "    d, q = W.shape\n",
    "\n",
    "    g_ind=np.concatenate((np.zeros(1, dtype=np.int64), np.cumsum(N_g)))\n",
    "\n",
    "\n",
    "    y_n=np.empty((N, d))\n",
    "\n",
    "    for g in range(G):\n",
    "        y_n[g_ind[g]:g_ind[g+1]]= np.einsum(\"dq,nq->nd\", W, x_n[g_ind[g]:g_ind[g+1]]+a_g[g]) + mu\n",
    "    y_n = pd.DataFrame(data=y_n,\n",
    "                     columns=[f'var_{i + 1}' for i in range(d)])\n",
    "\n",
    "    return y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ab247",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "D_i = [15, 8, 10]\n",
    "G = 2\n",
    "n_centers = 3\n",
    "testing_samples = 40\n",
    "\n",
    "q_gen, sigma2_gen1, sigma2_gen2, sigma2_gen3 = 4, 2, 1, 3\n",
    "\n",
    "W_gen1 = np.random.uniform(-10, 10, (D_i[0], q_gen))\n",
    "W_gen2 = np.random.uniform(-5, 5, (D_i[1], q_gen))\n",
    "W_gen3 = np.random.uniform(-15, 15, (D_i[2], q_gen))\n",
    "a_g_gen = np.concatenate((np.zeros((1, q_gen)), np.random.uniform(-10, 10, (G - 1, q_gen))))\n",
    "mu_gen1 = np.random.uniform(-10, 10, D_i[0])\n",
    "mu_gen2 = np.random.uniform(-5, 5, D_i[1])\n",
    "mu_gen3 = np.random.uniform(-15, 15, D_i[2])\n",
    "\n",
    "for i in range(n_centers):\n",
    "    N_g = np.array([np.random.randint(25,300),np.random.randint(25,300)])\n",
    "    g_ind = np.concatenate((np.zeros(1, dtype=np.int64), np.cumsum(N_g)))\n",
    "    N = N_g.sum()\n",
    "    x_n_gen = sample_x_n(N, q_gen, random_state=150)\n",
    "    y_t1 = generate_data(N_g, W_gen1, a_g_gen, mu_gen1, sigma2_gen1, x_n_gen, random_state=250)\n",
    "    y_t2 = generate_data(N_g, W_gen2, a_g_gen, mu_gen2, sigma2_gen2, x_n_gen, random_state=250)\n",
    "    y_t3 = generate_data(N_g, W_gen3, a_g_gen, mu_gen3, sigma2_gen3, x_n_gen, random_state=250)\n",
    "\n",
    "    gr = [0 for _ in range(N_g[0])]+[1 for _ in range(N_g[1])]\n",
    "    gr = pd.Series(gr)\n",
    "\n",
    "    t_i = pd.concat((y_t1, y_t2, y_t3, gr), axis=1)\n",
    "    np.savetxt('== Local path to node' + str(i+1) + '.csv',t_i,delimiter=',')\n",
    "               \n",
    "N_test = np.array([testing_samples//2,testing_samples//2])\n",
    "g_ind = np.concatenate((np.zeros(1, dtype=np.int64), np.cumsum(N_test)))\n",
    "N = N_test.sum()\n",
    "x_n_gen = sample_x_n(N, q_gen, random_state=150)\n",
    "y_t1 = generate_data(N_test, W_gen1, a_g_gen, mu_gen1, sigma2_gen1, x_n_gen, random_state=250)\n",
    "y_t2 = generate_data(N_test, W_gen2, a_g_gen, mu_gen2, sigma2_gen2, x_n_gen, random_state=250)\n",
    "y_t3 = generate_data(N_test, W_gen3, a_g_gen, mu_gen3, sigma2_gen3, x_n_gen, random_state=250)\n",
    "\n",
    "gr = [0 for _ in range(N_test[0])]+[1 for _ in range(N_test[1])]\n",
    "gr = pd.Series(gr)\n",
    "\n",
    "t_test = pd.concat((y_t1, y_t2, y_t3, gr), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f160e",
   "metadata": {},
   "source": [
    "## Start the network and setting the client up\n",
    "Before running this notebook:\n",
    "1. You should start the network from fedbiomed-network, as detailed in :\n",
    "https://gitlab.inria.fr/fedbiomed/fedbiomed\n",
    "\n",
    "2. You need to configure at least 2 nodes: <br/>\n",
    "* **Node 1 :** `./scripts/fedbiomed_run node add`\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset (you can write 'sk' always and it will be good)\n",
    "  * Pick the .csv file you stored the couple X[0],y[0].\n",
    "  * Check that your data has been added in node 1 by executing `./scripts/fedbiomed_run node list`\n",
    "  * Run the node using `./scripts/fedbiomed_run node start`. <br/>\n",
    "\n",
    "* **Node 2 :** Open a second terminal and run ./scripts/fedbiomed_run node add config n2.ini\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset (you can write 'sk' always and it will be good)\n",
    "  * Pick the .csv file you stored the couple X[1],y[1].\n",
    "  * Check that your data has been added in node 2 by executing `./scripts/fedbiomed_run node config n2.ini list`\n",
    "  * Run the node using `./scripts/fedbiomed_run node config n2.ini start`.\n",
    "  \n",
    "* **Node 3 :** Open a third terminal and run ./scripts/fedbiomed_run node add config n3.ini\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset (you can write 'sk' always and it will be good)\n",
    "  * Pick the .csv file you stored the couple X[2],y[2].\n",
    "  * Check that your data has been added in node 2 by executing `./scripts/fedbiomed_run node config n3.ini list`\n",
    "  * Run the node using `./scripts/fedbiomed_run node config n3.ini start `.\n",
    "\n",
    " Wait until you get `Connected with result code 0`. it means node is online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade4cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c80070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fedbiomed.researcher.environ import TMP_DIR\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=TMP_DIR+'/')\n",
    "model_file = tmp_dir_model.name + '/ppca_id.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9aaa87",
   "metadata": {},
   "source": [
    "Hereafter the template of the class you should provide to Fedbiomed :\n",
    "\n",
    "**__init__** : we add here the needed sklearn libraries\n",
    "       \n",
    "**training_data** : you must return here the (X,y) that must be of the same type of \n",
    "your method partial_fit parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10cc76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /Users/balelli/ownCloud/INRIA_EPIONE/FedBioMed/fedbiomed/var/tmp/tmp97bticuo/ppca_id.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "from fedbiomed.common.ppca import PpcaPlan\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class IID_MV_PPCA(PpcaPlan):\n",
    "    def __init__(self, kwargs):\n",
    "        super(IID_MV_PPCA, self).__init__(kwargs)\n",
    "        #self.add_dependency([\"from sklearn.linear_model import SGDRegressor\"])\n",
    "    \n",
    "    def training_data(self):\n",
    "        \"\"\"\n",
    "            Perform in this method all data reading and data transformations you need.\n",
    "            At the end you should provide a couple (X,y,ViewsX), where X is the training dataset, \n",
    "            y the corresponding labels, ViewsX a list, with len(ViewsX)=K, containing 1 at position i \n",
    "            if the center dispose of data for the i-th view 0 otherwise.\n",
    "            :raise NotImplementedError if developer do not implement this method.\n",
    "        \"\"\"\n",
    "        dataset = pd.read_csv(self.dataset_path,header=None,delimiter=',')\n",
    "        X = dataset.iloc[:,:-1].values\n",
    "        y = dataset[dataset.columns[-1]]\n",
    "        return (X,y.values,[1,1,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cda129",
   "metadata": {},
   "source": [
    "**model_args** is a dictionary containing the mv-ppca model arguments: the total number of views across all datasets, the dimension of each view and the latent space size.\n",
    "\n",
    "**training_args** contains here the number of local iterations for EM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05aa5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {'tot_views':3, 'dim_views': [15, 8, 10] , 'n_components': 4}\n",
    "\n",
    "training_args = {'n_iterations': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1a1341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 16:50:41,041 fedbiomed INFO - Messaging researcher_30571cfd-7c42-4eb6-a9bc-207d0727a7e4 successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x15299b5b0>\n",
      "2021-10-05 16:50:41,097 fedbiomed INFO - Searching for clients with data tags: ['ppca_data']\n",
      "2021-10-05 16:50:41,118 fedbiomed INFO - message received:{'researcher_id': 'researcher_30571cfd-7c42-4eb6-a9bc-207d0727a7e4', 'success': True, 'databases': [{'name': 'ppca_data', 'data_type': 'csv', 'tags': ['ppca_data'], 'description': 'ppca_data', 'shape': [214, 33], 'dataset_id': 'dataset_808bb2d1-ada4-4b91-bdec-29e515b4960d'}], 'count': 1, 'client_id': 'client_72ed9e37-49e2-4eff-8db6-30257bd5f5e9', 'command': 'search'}\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.mlaggregator import MLaggregator\n",
    "\n",
    "tags =  ['ppca_data']\n",
    "rounds = 5\n",
    "\n",
    "# select nodes participing to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 #clients=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='IID_MV_PPCA',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=MLaggregator(),\n",
    "                 client_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 16:50:51,752 fedbiomed INFO - Sampled clients in round 0 ['client_72ed9e37-49e2-4eff-8db6-30257bd5f5e9']\n",
      "2021-10-05 16:50:51,753 fedbiomed INFO - Send message to client client_72ed9e37-49e2-4eff-8db6-30257bd5f5e9 - {'researcher_id': 'researcher_30571cfd-7c42-4eb6-a9bc-207d0727a7e4', 'job_id': '28b8ad51-e069-4fe9-9e93-b63eb746721b', 'training_args': {'n_iterations': 15}, 'model_args': {'tot_views': 3, 'dim_views': [15, 8, 10], 'n_components': 4}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/10/05/my_model_1b802b6a-abab-4b99-b926-643d57d99e79.py', 'params_url': 'http://localhost:8844/media/uploads/2021/10/05/my_model_b1dff4c4-c8f2-49df-b6f1-1a9f17263ea2.pt', 'model_class': 'IID_MV_PPCA', 'training_data': {'client_72ed9e37-49e2-4eff-8db6-30257bd5f5e9': ['dataset_808bb2d1-ada4-4b91-bdec-29e515b4960d']}}\n",
      "2021-10-05 16:50:51,754 fedbiomed DEBUG - researcher_30571cfd-7c42-4eb6-a9bc-207d0727a7e4\n",
      "2021-10-05 16:50:52,056 fedbiomed INFO - message received:{'researcher_id': 'researcher_30571cfd-7c42-4eb6-a9bc-207d0727a7e4', 'job_id': '28b8ad51-e069-4fe9-9e93-b63eb746721b', 'success': False, 'client_id': 'client_72ed9e37-49e2-4eff-8db6-30257bd5f5e9', 'dataset_id': '', 'params_url': '', 'timing': {}, 'msg': \"Cannot instantiate model object: name 'PpcaPlan' is not defined\", 'command': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# start federated training\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2a782",
   "metadata": {},
   "source": [
    "## Lets build now a dataset test, **A** is the linear transformation that has been used to build the csv file training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5\n",
    "testing_samples = 40\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "\n",
    "def test_data():\n",
    "    X_test = rng.randn(testing_samples, n_features).reshape([testing_samples, n_features])\n",
    "    y_test = X_test.dot(A) + rng.randn(testing_samples).reshape([testing_samples,1])\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6d380",
   "metadata": {},
   "source": [
    "The MSE should be decreasing at each iteration with the federated parameters.\n",
    "\n",
    "For that, we are exporting `exp.aggregated_params` containing models parameters collected at the end of each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_error = []\n",
    "\n",
    "for i in range(rounds):\n",
    "    fed_model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "    fed_model.coef_ = exp.aggregated_params[i]['params']['coef_'].copy()\n",
    "    fed_model.intercept_ = exp.aggregated_params[i]['params']['intercept_'].copy()  \n",
    "    mse = np.mean((fed_model.predict(X_test).ravel() - y_test.ravel())**2)\n",
    "    print('MSE ', mse)\n",
    "    testing_error.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8cf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
